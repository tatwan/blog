{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "Skeleton Code . The code below provides a skeleton for the model building &amp; training component of your project. You can add/remove/build on code however you see fit, this is meant as a starting point. . #collapse_shpw import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import os from glob import glob %matplotlib inline import matplotlib.pyplot as plt ##Import any other stats/DL/ML packages you may need here. E.g. Keras, scikit-learn, etc. ## General libraries import seaborn as sns from itertools import chain import pydicom from random import sample ## Scikit-Learn from skimage.io import imread, imshow from skimage import io from sklearn.model_selection import train_test_split from sklearn.metrics import f1_score, confusion_matrix, auc, roc_auc_score, roc_curve, accuracy_score, precision_recall_curve, average_precision_score ## Keras from keras.preprocessing.image import ImageDataGenerator from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D from keras.models import Sequential, Model, model_from_json from keras.optimizers import Adam from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau from keras.applications.vgg16 import VGG16 . Using TensorFlow backend. . Do some early processing of your metadata for easier model training: . ## Below is some helper code to read all of your full image filepaths into a dataframe for easier manipulation ## Load the NIH data to all_xray_df all_xray_df = pd.read_csv(&#39;/data/Data_Entry_2017.csv&#39;) all_image_paths = {os.path.basename(x): x for x in glob(os.path.join(&#39;/data&#39;,&#39;images*&#39;, &#39;*&#39;, &#39;*.png&#39;))} print(&#39;Scans found:&#39;, len(all_image_paths), &#39;, Total Headers&#39;, all_xray_df.shape[0]) all_xray_df[&#39;path&#39;] = all_xray_df[&#39;Image Index&#39;].map(all_image_paths.get) all_xray_df.sample(3) . Scans found: 112120 , Total Headers 112120 . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImage[Width Height] OriginalImagePixelSpacing[x y] Unnamed: 11 path . 43068 00011121_010.png | No Finding | 10 | 11121 | 49 | F | PA | 2750 | 2991 | 0.143 | 0.143 | NaN | /data/images_005/images/00011121_010.png | . 95937 00025250_001.png | Cardiomegaly | 1 | 25250 | 48 | F | PA | 2992 | 2991 | 0.143 | 0.143 | NaN | /data/images_011/images/00025250_001.png | . 40119 00010475_021.png | Effusion | 21 | 10475 | 64 | F | AP | 2500 | 2048 | 0.168 | 0.168 | NaN | /data/images_005/images/00010475_021.png | . all_xray_df.columns . Index([&#39;Image Index&#39;, &#39;Finding Labels&#39;, &#39;Follow-up #&#39;, &#39;Patient ID&#39;, &#39;Patient Age&#39;, &#39;Patient Gender&#39;, &#39;View Position&#39;, &#39;OriginalImage[Width&#39;, &#39;Height]&#39;, &#39;OriginalImagePixelSpacing[x&#39;, &#39;y]&#39;, &#39;Unnamed: 11&#39;, &#39;path&#39;], dtype=&#39;object&#39;) . ## Here you may want to create some extra columns in your table with binary indicators of certain diseases ## rather than working directly with the &#39;Finding Labels&#39; column # Todo all_labels = list(set(list(chain.from_iterable([i.split(&#39;|&#39;) for i in all_xray_df[&#39;Finding Labels&#39;]])))) for c_label in all_labels: all_xray_df[c_label] = all_xray_df[&#39;Finding Labels&#39;].map(lambda finding: 1.0 if c_label in finding else 0) all_xray_df.sample(3) . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImage[Width Height] OriginalImagePixelSpacing[x ... Emphysema Nodule Edema Effusion Pleural_Thickening Consolidation Mass Atelectasis No Finding Infiltration . 24116 00006332_005.png | No Finding | 5 | 6332 | 47 | F | PA | 2048 | 2500 | 0.171 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 70065 00017247_005.png | No Finding | 5 | 17247 | 55 | F | PA | 2578 | 2657 | 0.143 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 27807 00007239_001.png | No Finding | 1 | 7239 | 52 | F | AP | 2500 | 2048 | 0.171 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 3 rows × 28 columns . all_xray_df.columns . Index([&#39;Image Index&#39;, &#39;Finding Labels&#39;, &#39;Follow-up #&#39;, &#39;Patient ID&#39;, &#39;Patient Age&#39;, &#39;Patient Gender&#39;, &#39;View Position&#39;, &#39;OriginalImage[Width&#39;, &#39;Height]&#39;, &#39;OriginalImagePixelSpacing[x&#39;, &#39;y]&#39;, &#39;Unnamed: 11&#39;, &#39;path&#39;, &#39;Hernia&#39;, &#39;Cardiomegaly&#39;, &#39;Fibrosis&#39;, &#39;Pneumothorax&#39;, &#39;Pneumonia&#39;, &#39;Emphysema&#39;, &#39;Nodule&#39;, &#39;Edema&#39;, &#39;Effusion&#39;, &#39;Pleural_Thickening&#39;, &#39;Consolidation&#39;, &#39;Mass&#39;, &#39;Atelectasis&#39;, &#39;No Finding&#39;, &#39;Infiltration&#39;], dtype=&#39;object&#39;) . all_xray_df.hist(bins=50, figsize=(20,15)) plt.show() . /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:298: MatplotlibDeprecationWarning: The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead. layout[ax.rowNum, ax.colNum] = ax.get_visible() /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:298: MatplotlibDeprecationWarning: The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead. layout[ax.rowNum, ax.colNum] = ax.get_visible() /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:304: MatplotlibDeprecationWarning: The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead. if not layout[ax.rowNum + 1, ax.colNum]: /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:304: MatplotlibDeprecationWarning: The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead. if not layout[ax.rowNum + 1, ax.colNum]: . print(all_xray_df[&#39;Patient Gender&#39;].value_counts(normalize=True)) all_xray_df[&#39;Patient Gender&#39;].hist() plt.show() . M 0.56493 F 0.43507 Name: Patient Gender, dtype: float64 . all_xray_df.drop(columns=[&#39;Unnamed: 11&#39;], inplace=True) . ## Here we can create a new column called &#39;pneumonia_class&#39; that will allow us to look at ## images with or without pneumonia for binary classification # Todo # since we already have a column for Pneumonia (binary 0,1) we can repurpose it and just rename it all_xray_df = all_xray_df.rename(columns={&#39;Pneumonia&#39;: &#39;pneumonia_class&#39;}) . labels = all_xray_df.columns[13:] labels . Index([&#39;Cardiomegaly&#39;, &#39;Fibrosis&#39;, &#39;Pneumothorax&#39;, &#39;pneumonia_class&#39;, &#39;Emphysema&#39;, &#39;Nodule&#39;, &#39;Edema&#39;, &#39;Effusion&#39;, &#39;Pleural_Thickening&#39;, &#39;Consolidation&#39;, &#39;Mass&#39;, &#39;Atelectasis&#39;, &#39;No Finding&#39;, &#39;Infiltration&#39;], dtype=&#39;object&#39;) . plt.figure(figsize=(10,6)) vals = all_xray_df[labels].sum().nlargest(15).sort_values() colors = [&#39;#d62728&#39; if i ==&#39;pneumonia_class&#39; else &#39;#1f77b4&#39; for i in vals.index] ax = vals.plot(kind=&#39;barh&#39;, color=colors) ax.set(xlabel = &#39;Number of Images with Label&#39;) plt.show() . Create your training and testing data: . all_xray_df.shape . (112120, 27) . cols = [&#39;path&#39;, &#39;pneumonia_class&#39;, &#39;Patient Gender&#39;, &#39;Patient Age&#39;, &#39;View Position&#39;] dt = all_xray_df[cols] . def create_splits(data, test_size=0.2, strat=None): ## Either build your own or use a built-in library to split your original dataframe into two sets ## that can be used for training and testing your model ## It&#39;s important to consider here how balanced or imbalanced you want each of those sets to be ## for the presence of pneumonia # Todo train_data, val_data = train_test_split(data, test_size = test_size, stratify = data[strat], random_state=42) return train_data, val_data . train_set, val_set = create_splits(dt, 0.2, &#39;pneumonia_class&#39;) . Analysis on the Training and Validation Dataset to under data distribution . print(train_set[&#39;pneumonia_class&#39;].value_counts(normalize=True)) train_set[&#39;pneumonia_class&#39;].hist() plt.title(&#39;Training set class distribution&#39;) . 0.0 0.987235 1.0 0.012765 Name: pneumonia_class, dtype: float64 . Text(0.5, 1.0, &#39;Training set class distribution&#39;) . print(val_set[&#39;pneumonia_class&#39;].value_counts(normalize=True)) val_set[&#39;pneumonia_class&#39;].hist() plt.title(&#39;Validation set class distribution&#39;) . 0.0 0.987246 1.0 0.012754 Name: pneumonia_class, dtype: float64 . Text(0.5, 1.0, &#39;Validation set class distribution&#39;) . train_set[&#39;Patient Age&#39;].hist() plt.title(&#39;Traing set - Age Distribution&#39;) plt.show() . print(train_set[&#39;Patient Gender&#39;].value_counts(normalize=True)) train_set[&#39;Patient Gender&#39;].hist() plt.title(&#39;Traing set - Gender Distribution&#39;) plt.show() . M 0.564986 F 0.435014 Name: Patient Gender, dtype: float64 . val_set[&#39;Patient Age&#39;].hist() plt.title(&#39;Validation set - Age Distribution&#39;) plt.show() . print(val_set[&#39;Patient Gender&#39;].value_counts(normalize=True)) val_set[&#39;Patient Gender&#39;].hist() plt.title(&#39;Validation set - Gender Distribution&#39;) plt.show() . M 0.564707 F 0.435293 Name: Patient Gender, dtype: float64 . Research Papers and Articles regarding Imbalanced Classes in Deep Learning . Survey on deep learning with class imbalance - Springer | Solving Class Imbalance problem in CNN - Medium | Deep Over-sampling Framework for Classifying Imbalanced Data - Paper | SMOTE for Imbalanced Classification with Python | Note: From the research it seems a combination of undersampling and oversampling may produce the best results. This means undersampling the majority class which in our case is the Non-Penumonia and oversampling the minority class. Possibly in the future I will need to experiment further with these techniques. For now, I will just reduce the data from the majority class to bring them to a balance. . Handling Imbalance classes . Even though with Patient Gender there is a slight imbalance as well, I think it can be neglected for now. The current technique to balance Pneumonia and Non-Pneumonia classes will chunk out a lot of data already and I would like to preserve as much data as possible for training. . Training Data set . p_idx = train_set[train_set[&#39;pneumonia_class&#39;]==1].index.tolist() np_idx = train_set[train_set[&#39;pneumonia_class&#39;]==0].index.tolist() np_sample = sample(np_idx,len(p_idx)) train_df = train_set.loc[p_idx + np_sample] . train_df.shape . (2290, 5) . Validation Dataset . p_idx = val_set[val_set[&#39;pneumonia_class&#39;]==1].index.tolist() np_idx = val_set[val_set[&#39;pneumonia_class&#39;]==0].index.tolist() np_sample = sample(np_idx,len(p_idx)) val_df = val_set.loc[p_idx + np_sample] . Checking - analysis after reducing the majority non-pneumonia class . val_df.shape . (572, 5) . from collections import Counter . Counter(train_df.pneumonia_class) . Counter({1.0: 1145, 0.0: 1145}) . Counter(val_df.pneumonia_class) . Counter({1.0: 286, 0.0: 286}) . train_df[train_df.pneumonia_class == 1][&#39;Patient Gender&#39;].value_counts(normalize=True) . M 0.5869 F 0.4131 Name: Patient Gender, dtype: float64 . val_df[val_df.pneumonia_class == 1][&#39;Patient Gender&#39;].value_counts(normalize=True) . M 0.58042 F 0.41958 Name: Patient Gender, dtype: float64 . Library imblearn something to test in the future . # !pip install -U imbalanced-learn . # import imblearn # from imblearn.over_sampling import SMOTE # print(imblearn.__version__) . Now we can begin our model-building &amp; training . First suggestion: perform some image augmentation on your data . ## This is the image size that VGG16 takes as input IMG_SIZE = (224, 224) . def my_image_augmentation(horizontal_flip=False, vertical_flip=False, height_shift_range=0, width_shift_range=0, rotation_range=0, shear_range=0, zoom_range=0): ## recommendation here to implement a package like Keras&#39; ImageDataGenerator ## with some of the built-in augmentations ## keep an eye out for types of augmentation that are or are not appropriate for medical imaging data ## Also keep in mind what sort of augmentation is or is not appropriate for testing vs validation data ## STAND-OUT SUGGESTION: implement some of your own custom augmentation that&#39;s *not* ## built into something like a Keras package # Todo img_aug = ImageDataGenerator(rescale=1. / 255.0, horizontal_flip = horizontal_flip, vertical_flip = vertical_flip, height_shift_range= height_shift_range, width_shift_range=width_shift_range, rotation_range=rotation_range, shear_range = shear_range, zoom_range=zoom_range) return img_aug def make_train_gen(train_idg, train_df, x_col, y_col, target_size, batch_size): ## Create the actual generators using the output of my_image_augmentation for your training data ## Suggestion here to use the flow_from_dataframe library, e.g.: # my_train = my_image_augmentation(horizontal_flip = True, # vertical_flip = False, # height_shift_range= 0.1, # width_shift_range=0.1, # rotation_range=20, # shear_range = 0.1, # zoom_range=0.1) train_gen = train_idg.flow_from_dataframe(dataframe=train_df, directory=None, x_col = x_col, y_col = y_col, class_mode = &#39;binary&#39;, target_size = target_size, batch_size = batch_size ) # Todo return train_gen def make_val_gen(val_idg, val_df, x_col, y_col, target_size, batch_size): # my_val_idg = my_image_augmentation() val_gen = val_idg.flow_from_dataframe(dataframe = val_df, directory=None, x_col = x_col, y_col = y_col, class_mode = &#39;binary&#39;, target_size = target_size, batch_size = batch_size) # Todo return val_gen . Note: Due to error requiring that the classes should be string since the class_mode is set to binary . train_df[&#39;pneumonia_class&#39;] = train_df[&#39;pneumonia_class&#39;].astype(&#39;str&#39;) val_df[&#39;pneumonia_class&#39;] = val_df[&#39;pneumonia_class&#39;].astype(&#39;str&#39;) . train_idg = my_image_augmentation(True, False, 0.1, 0.1, 20, 0.1, 0.1) val_idg = my_image_augmentation() . train_gen = make_train_gen(train_idg=train_idg, train_df=train_df, x_col=&#39;path&#39;, y_col=&#39;pneumonia_class&#39;, target_size=IMG_SIZE, batch_size=22) val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;pneumonia_class&#39;, IMG_SIZE, 22) . Found 2290 validated image filenames belonging to 2 classes. Found 572 validated image filenames belonging to 2 classes. . ## May want to pull a single large batch of random validation data for testing after each epoch: valX, valY = val_gen.next() . ## May want to look at some examples of our augmented training data. ## This is helpful for understanding the extent to which data is being manipulated prior to training, ## and can be compared with how the raw data look prior to augmentation t_x, t_y = next(train_gen) fig, m_axs = plt.subplots(4, 4, figsize = (16, 16)) for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()): c_ax.imshow(c_x[:,:,0], cmap = &#39;bone&#39;) if c_y == 1: c_ax.set_title(&#39;Pneumonia&#39;) else: c_ax.set_title(&#39;No Pneumonia&#39;) c_ax.axis(&#39;off&#39;) . Build your model: . Recommendation here to use a pre-trained network downloaded from Keras for fine-tuning . model = VGG16(include_top=True, weights=&#39;imagenet&#39;) . Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5 553467904/553467096 [==============================] - 30s 0us/step . # model.summary() . def load_pretrained_model(): model = VGG16(include_top=True, weights=&#39;imagenet&#39;) transfer_layer = model.get_layer(&#39;block5_pool&#39;) vgg_model = Model(inputs = model.input, outputs = transfer_layer.output) # Todo for layer in vgg_model.layers[0:-2]: layer.trainable = False return vgg_model . vgg_model = load_pretrained_model() . vgg_model.summary() . Model: &#34;model_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) (None, 224, 224, 3) 0 _________________________________________________________________ block1_conv1 (Conv2D) (None, 224, 224, 64) 1792 _________________________________________________________________ block1_conv2 (Conv2D) (None, 224, 224, 64) 36928 _________________________________________________________________ block1_pool (MaxPooling2D) (None, 112, 112, 64) 0 _________________________________________________________________ block2_conv1 (Conv2D) (None, 112, 112, 128) 73856 _________________________________________________________________ block2_conv2 (Conv2D) (None, 112, 112, 128) 147584 _________________________________________________________________ block2_pool (MaxPooling2D) (None, 56, 56, 128) 0 _________________________________________________________________ block3_conv1 (Conv2D) (None, 56, 56, 256) 295168 _________________________________________________________________ block3_conv2 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_conv3 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_pool (MaxPooling2D) (None, 28, 28, 256) 0 _________________________________________________________________ block4_conv1 (Conv2D) (None, 28, 28, 512) 1180160 _________________________________________________________________ block4_conv2 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_conv3 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_pool (MaxPooling2D) (None, 14, 14, 512) 0 _________________________________________________________________ block5_conv1 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv2 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv3 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_pool (MaxPooling2D) (None, 7, 7, 512) 0 ================================================================= Total params: 14,714,688 Trainable params: 2,359,808 Non-trainable params: 12,354,880 _________________________________________________________________ . def build_my_model(pre_trained): my_model = Sequential() # Add the convolutional part of the VGG16 model from above. my_model.add(vgg_model) my_model.add(Flatten()) # Flatten the output of the VGG16 model because it is from a # convolutional layer. my_model.add(Dense(1024, activation=&#39;relu&#39;)) my_model.add(Dropout(0.5)) my_model.add(Dense(512, activation=&#39;relu&#39;)) my_model.add(Dropout(0.5)) my_model.add(Dense(256, activation=&#39;relu&#39;)) my_model.add(Dropout(0.5)) # Final output layer # Add a dense (aka. fully-connected) layer. # This is for combining features that the VGG16 model has # recognized in the image. my_model.add(Dense(1, activation=&#39;sigmoid&#39;)) ## Set our optimizer, loss function, and learning rate (you can change the learning rate here if you&#39;d like) ## but otherwise this cell can be run as is return my_model . model = build_my_model(vgg_model) . optimizer = Adam(lr=0.001) loss = &#39;binary_crossentropy&#39; metrics = [&#39;binary_accuracy&#39;] model.compile(optimizer=optimizer, loss=loss, metrics=metrics) . model.summary() . Model: &#34;sequential_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= model_2 (Model) (None, 7, 7, 512) 14714688 _________________________________________________________________ flatten_2 (Flatten) (None, 25088) 0 _________________________________________________________________ dense_5 (Dense) (None, 1024) 25691136 _________________________________________________________________ dropout_4 (Dropout) (None, 1024) 0 _________________________________________________________________ dense_6 (Dense) (None, 512) 524800 _________________________________________________________________ dropout_5 (Dropout) (None, 512) 0 _________________________________________________________________ dense_7 (Dense) (None, 256) 131328 _________________________________________________________________ dropout_6 (Dropout) (None, 256) 0 _________________________________________________________________ dense_8 (Dense) (None, 1) 257 ================================================================= Total params: 41,062,209 Trainable params: 28,707,329 Non-trainable params: 12,354,880 _________________________________________________________________ . ## Below is some helper code that will allow you to add checkpoints to your model, ## This will save the &#39;best&#39; version of your model by comparing it to previous epochs of training ## Note that you need to choose which metric to monitor for your model&#39;s &#39;best&#39; performance if using this code. ## The &#39;patience&#39; parameter is set to 10, meaning that your model will train for ten epochs without seeing ## improvement before quitting # Todo weight_path=&quot;{}_my_model.best.hdf5&quot;.format(&#39;xray_class&#39;) checkpoint = ModelCheckpoint(weight_path, monitor= &#39;val_loss&#39;, verbose=1, save_best_only=True, mode= &#39;min&#39;, save_weights_only = True) early = EarlyStopping(monitor= &#39;val_loss&#39;, mode= &#39;min&#39;, patience=10) callbacks_list = [checkpoint, early] . Start training! . history = model.fit_generator(train_gen, validation_data=[valX, valY], epochs=30, callbacks=callbacks_list ) . Epoch 1/30 105/105 [==============================] - 61s 583ms/step - loss: 0.7943 - binary_accuracy: 0.5288 - val_loss: 0.6789 - val_binary_accuracy: 0.5455 Epoch 00001: val_loss improved from inf to 0.67891, saving model to xray_class_my_model.best.hdf5 Epoch 2/30 105/105 [==============================] - 60s 574ms/step - loss: 0.6889 - binary_accuracy: 0.5520 - val_loss: 0.6646 - val_binary_accuracy: 0.5909 Epoch 00002: val_loss improved from 0.67891 to 0.66465, saving model to xray_class_my_model.best.hdf5 Epoch 3/30 105/105 [==============================] - 59s 565ms/step - loss: 0.6838 - binary_accuracy: 0.5699 - val_loss: 0.6628 - val_binary_accuracy: 0.5909 Epoch 00003: val_loss improved from 0.66465 to 0.66279, saving model to xray_class_my_model.best.hdf5 Epoch 4/30 105/105 [==============================] - 60s 568ms/step - loss: 0.6803 - binary_accuracy: 0.5952 - val_loss: 0.6143 - val_binary_accuracy: 0.7273 Epoch 00004: val_loss improved from 0.66279 to 0.61426, saving model to xray_class_my_model.best.hdf5 Epoch 5/30 105/105 [==============================] - 59s 563ms/step - loss: 0.6693 - binary_accuracy: 0.5873 - val_loss: 0.5985 - val_binary_accuracy: 0.7273 Epoch 00005: val_loss improved from 0.61426 to 0.59854, saving model to xray_class_my_model.best.hdf5 Epoch 6/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6665 - binary_accuracy: 0.6175 - val_loss: 0.6186 - val_binary_accuracy: 0.7273 Epoch 00006: val_loss did not improve from 0.59854 Epoch 7/30 105/105 [==============================] - 58s 556ms/step - loss: 0.6719 - binary_accuracy: 0.6140 - val_loss: 0.5687 - val_binary_accuracy: 0.7273 Epoch 00007: val_loss improved from 0.59854 to 0.56874, saving model to xray_class_my_model.best.hdf5 Epoch 8/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6708 - binary_accuracy: 0.6057 - val_loss: 0.6142 - val_binary_accuracy: 0.6818 Epoch 00008: val_loss did not improve from 0.56874 Epoch 9/30 105/105 [==============================] - 58s 551ms/step - loss: 0.6607 - binary_accuracy: 0.6258 - val_loss: 0.5588 - val_binary_accuracy: 0.7727 Epoch 00009: val_loss improved from 0.56874 to 0.55877, saving model to xray_class_my_model.best.hdf5 Epoch 10/30 105/105 [==============================] - 58s 549ms/step - loss: 0.6539 - binary_accuracy: 0.6240 - val_loss: 0.5495 - val_binary_accuracy: 0.7273 Epoch 00010: val_loss improved from 0.55877 to 0.54947, saving model to xray_class_my_model.best.hdf5 Epoch 11/30 105/105 [==============================] - 58s 554ms/step - loss: 0.6606 - binary_accuracy: 0.6236 - val_loss: 0.5813 - val_binary_accuracy: 0.7273 Epoch 00011: val_loss did not improve from 0.54947 Epoch 12/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6545 - binary_accuracy: 0.6166 - val_loss: 0.5925 - val_binary_accuracy: 0.6818 Epoch 00012: val_loss did not improve from 0.54947 Epoch 13/30 105/105 [==============================] - 58s 549ms/step - loss: 0.6539 - binary_accuracy: 0.6367 - val_loss: 0.5246 - val_binary_accuracy: 0.6818 Epoch 00013: val_loss improved from 0.54947 to 0.52456, saving model to xray_class_my_model.best.hdf5 Epoch 14/30 105/105 [==============================] - 57s 545ms/step - loss: 0.6495 - binary_accuracy: 0.6253 - val_loss: 0.6258 - val_binary_accuracy: 0.6818 Epoch 00014: val_loss did not improve from 0.52456 Epoch 15/30 105/105 [==============================] - 58s 554ms/step - loss: 0.6595 - binary_accuracy: 0.6349 - val_loss: 0.5774 - val_binary_accuracy: 0.7273 Epoch 00015: val_loss did not improve from 0.52456 Epoch 16/30 105/105 [==============================] - 59s 558ms/step - loss: 0.6533 - binary_accuracy: 0.6336 - val_loss: 0.5992 - val_binary_accuracy: 0.6818 Epoch 00016: val_loss did not improve from 0.52456 Epoch 17/30 105/105 [==============================] - 59s 559ms/step - loss: 0.6502 - binary_accuracy: 0.6367 - val_loss: 0.5655 - val_binary_accuracy: 0.8182 Epoch 00017: val_loss did not improve from 0.52456 Epoch 18/30 105/105 [==============================] - 59s 565ms/step - loss: 0.6403 - binary_accuracy: 0.6393 - val_loss: 0.5355 - val_binary_accuracy: 0.7727 Epoch 00018: val_loss did not improve from 0.52456 Epoch 19/30 105/105 [==============================] - 57s 540ms/step - loss: 0.6455 - binary_accuracy: 0.6362 - val_loss: 0.4997 - val_binary_accuracy: 0.7727 Epoch 00019: val_loss improved from 0.52456 to 0.49972, saving model to xray_class_my_model.best.hdf5 Epoch 20/30 105/105 [==============================] - 58s 550ms/step - loss: 0.6529 - binary_accuracy: 0.6393 - val_loss: 0.5674 - val_binary_accuracy: 0.8182 Epoch 00020: val_loss did not improve from 0.49972 Epoch 21/30 105/105 [==============================] - 58s 551ms/step - loss: 0.6495 - binary_accuracy: 0.6415 - val_loss: 0.5950 - val_binary_accuracy: 0.7727 Epoch 00021: val_loss did not improve from 0.49972 Epoch 22/30 105/105 [==============================] - 58s 550ms/step - loss: 0.6488 - binary_accuracy: 0.6332 - val_loss: 0.5701 - val_binary_accuracy: 0.7273 Epoch 00022: val_loss did not improve from 0.49972 Epoch 23/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6316 - binary_accuracy: 0.6594 - val_loss: 0.5483 - val_binary_accuracy: 0.7727 Epoch 00023: val_loss did not improve from 0.49972 Epoch 24/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6314 - binary_accuracy: 0.6524 - val_loss: 0.5416 - val_binary_accuracy: 0.7273 Epoch 00024: val_loss did not improve from 0.49972 Epoch 25/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6361 - binary_accuracy: 0.6502 - val_loss: 0.5378 - val_binary_accuracy: 0.8182 Epoch 00025: val_loss did not improve from 0.49972 Epoch 26/30 105/105 [==============================] - 58s 551ms/step - loss: 0.6384 - binary_accuracy: 0.6498 - val_loss: 0.5757 - val_binary_accuracy: 0.7273 Epoch 00026: val_loss did not improve from 0.49972 Epoch 27/30 105/105 [==============================] - 58s 548ms/step - loss: 0.6410 - binary_accuracy: 0.6467 - val_loss: 0.5184 - val_binary_accuracy: 0.8182 Epoch 00027: val_loss did not improve from 0.49972 Epoch 28/30 105/105 [==============================] - 58s 552ms/step - loss: 0.6353 - binary_accuracy: 0.6520 - val_loss: 0.5618 - val_binary_accuracy: 0.6364 Epoch 00028: val_loss did not improve from 0.49972 Epoch 29/30 105/105 [==============================] - 58s 550ms/step - loss: 0.6420 - binary_accuracy: 0.6533 - val_loss: 0.5467 - val_binary_accuracy: 0.7727 Epoch 00029: val_loss did not improve from 0.49972 . history.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_binary_accuracy&#39;, &#39;loss&#39;, &#39;binary_accuracy&#39;]) . After training for some time, look at the performance of your model by plotting some performance statistics: . Note, these figures will come in handy for your FDA documentation later in the project . !ls . &#39;Build and train model.ipynb&#39; test2.dcm EDA.ipynb test3.dcm FDA_Submission_Template.md test4.dcm Inference.ipynb test5.dcm my_model.json test6.dcm sample_labels.csv xray_class_my_model.best.hdf5 test1.dcm . ## After training, make some predictions to assess your model&#39;s overall performance ## Note that detecting pneumonia is hard even for trained expert radiologists, ## so there is no need to make the model perfect. model.load_weights(weight_path) pred_Y = model.predict(valX, batch_size = 32, verbose = True) . Create a binary output instead of just probability using a standard 0.5 threshold for now . pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] . def plot_auc(t_y, p_y): ## Hint: can use scikit-learn&#39;s built in functions here like roc_curve # Todo fig, c_ax = plt.subplots(1,1, figsize = (9, 9)) fpr, tpr, thresholds = roc_curve(t_y, p_y) c_ax.plot(fpr, tpr, label = &#39;%s (AUC:%0.2f)&#39; % (&#39;Pneumonia&#39;, auc(fpr, tpr))) c_ax.legend() c_ax.set_xlabel(&#39;False Positive Rate&#39;) c_ax.set_ylabel(&#39;True Positive Rate&#39;) return ## what other performance statistics do you want to include here besides AUC? # def ... # Todo def plot_pr(t_y, p_y): fig, c_ax = plt.subplots(1,1, figsize = (9, 9)) precision, recall, thresholds = precision_recall_curve(t_y, p_y) c_ax.plot(precision, recall, label = &#39;%s (AP Score:%0.2f)&#39; % (&#39;Pneumonia&#39;, average_precision_score(t_y,p_y))) c_ax.legend() c_ax.set_xlabel(&#39;Recall&#39;) c_ax.set_ylabel(&#39;Precision&#39;) #Also consider plotting the history of your model training: def plot_history(history, kind): &#39;&#39;&#39; kind: either &quot;accuracy&quot; or &quot;loss&quot; &#39;&#39;&#39; plt.figure(figsize = (9, 9)) kind = &#39;binary_accuracy&#39; if kind == &#39;accuracy&#39; else kind plt.plot(history.history[f&#39;val_{kind}&#39;], label=f&#39;validation {kind}&#39;) plt.plot(history.history[f&#39;{kind}&#39;], label=f&#39;training {kind}&#39;) plt.title(f&#39;Validation/Training {kind}&#39;) plt.ylabel(&#39;EPOCHS&#39;) plt.legend() plt.show() return . plot_auc(valY, pred_Y) . ## plot figures plot_history(history, &#39;accuracy&#39;) # Todo . plot_history(history, &#39;loss&#39;) . Once you feel you are done training, you&#39;ll need to decide the proper classification threshold that optimizes your model&#39;s performance for a given metric (e.g. accuracy, F1, precision, etc. You decide) . confusion_matrix(pred_Y_binary, valY) . array([[10, 4], [ 1, 7]]) . tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() . accuracy_score(pred_Y_binary, valY) f1_score(pred_Y_binary, valY) sens = tp/(tp+fn) spec = tn/(tn+fp) spec . 0.7142857142857143 . precision, recall, thresholds = precision_recall_curve(valY, pred_Y) . ## Find the threshold that optimize your model&#39;s performance, ## and use that threshold to make binary classification. Make sure you take all your metrics into consideration. # Todo . val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;pneumonia_class&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() . Found 572 validated image filenames belonging to 2 classes. . pred_Y = model.predict(valX, batch_size = 32, verbose = True) . 100/100 [==============================] - 1s 10ms/step . ## Let&#39;s look at some examples of true vs. predicted with our best model: # Todo fig, m_axs = plt.subplots(10, 10, figsize = (16, 16)) i = 0 for (c_x, c_y, c_ax) in zip(valX[0:100], valY[0:100], m_axs.flatten()): c_ax.imshow(c_x[:,:,0], cmap = &#39;bone&#39;) if c_y == 1: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;1, 1&#39;) else: c_ax.set_title(&#39;1, 0&#39;, color=&#39;red&#39;) else: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;0, 1&#39;, color=&#39;red&#39;) else: c_ax.set_title(&#39;0, 0&#39;) c_ax.axis(&#39;off&#39;) i=i+1 . pred_Y_binary = pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] confusion_matrix(pred_Y_binary, valY) . array([[33, 17], [13, 37]]) . acc = accuracy_score(pred_Y_binary, valY) f1 = f1_score(pred_Y_binary, valY) sens = tp/(tp+fn) spec = tn/(tn+fp) spec . 0.7142857142857143 . plot_auc(valY, pred_Y) . plot_pr(valY, pred_Y) . ## Just save model architecture to a .json: model_json = model.to_json() with open(&quot;my_model.json&quot;, &quot;w&quot;) as json_file: json_file.write(model_json) . !ls . &#39;Build and train model.ipynb&#39; test2.dcm EDA.ipynb test3.dcm FDA_Submission_Template.md test4.dcm Inference.ipynb test5.dcm my_model.json test6.dcm sample_labels.csv xray_class_my_model.best.hdf5 test1.dcm . Using saved model for further analysis and testing . json_file = open(&#39;my_model.json&#39;, &#39;r&#39;) loaded_model_json = json_file.read() json_file.close() loaded_model = model_from_json(loaded_model_json) # load weights into new model loaded_model.load_weights(&quot;xray_class_my_model.best.hdf5&quot;) print(&quot;Loaded model from disk&quot;) . Loaded model from disk . loaded_model.summary() . Model: &#34;sequential_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= model_2 (Model) (None, 7, 7, 512) 14714688 _________________________________________________________________ flatten_2 (Flatten) (None, 25088) 0 _________________________________________________________________ dense_5 (Dense) (None, 1024) 25691136 _________________________________________________________________ dropout_4 (Dropout) (None, 1024) 0 _________________________________________________________________ dense_6 (Dense) (None, 512) 524800 _________________________________________________________________ dropout_5 (Dropout) (None, 512) 0 _________________________________________________________________ dense_7 (Dense) (None, 256) 131328 _________________________________________________________________ dropout_6 (Dropout) (None, 256) 0 _________________________________________________________________ dense_8 (Dense) (None, 1) 257 ================================================================= Total params: 41,062,209 Trainable params: 28,707,329 Non-trainable params: 12,354,880 _________________________________________________________________ . val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;pneumonia_class&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() pred_Y = loaded_model.predict(valX, batch_size = 32, verbose = True) . Found 572 validated image filenames belonging to 2 classes. 100/100 [==============================] - 55s 553ms/step . fig, m_axs = plt.subplots(10, 10, figsize = (16, 16)) i = 0 for (c_x, c_y, c_ax) in zip(valX[0:100], valY[0:100], m_axs.flatten()): c_ax.imshow(c_x[:,:,0], cmap = &#39;bone&#39;) if c_y == 1: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;1, 1&#39;) else: c_ax.set_title(&#39;1, 0&#39;, color=&#39;red&#39;) else: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;0, 1&#39;, color=&#39;red&#39;) else: c_ax.set_title(&#39;0, 0&#39;) c_ax.axis(&#39;off&#39;) i=i+1 . # Test for different threshold levels # using colors just to make it easir to read and spot numbers for t in [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] print(f&#39;when threshold at {t} CF:&#39;) print(confusion_matrix(pred_Y_binary, valY)) tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() print(f&#39; x1b[34maccuracy x1b[0m= x1b[31m{accuracy_score(pred_Y_binary, valY)} x1b[0m&#39;) print(f&#39;F1 Score = {f1_score(pred_Y_binary, valY)}&#39;) print(f&#39; x1b[34mSensitivity Score x1b[0m= x1b[31m{tp/(tp+fn)} x1b[0m&#39;) print(f&#39; x1b[34mSpecificity Score x1b[0m= x1b[31m{tn/(tn+fp)} x1b[0m&#39;) print(&#39;-&#39;) . when threshold at 0.4 CF: [[33 21] [21 25]] accuracy = 0.58 F1 Score = 0.5434782608695652 Sensitivity Score = 0.5434782608695652 Specificity Score = 0.6111111111111112 - when threshold at 0.5 CF: [[43 25] [11 21]] accuracy = 0.64 F1 Score = 0.5384615384615383 Sensitivity Score = 0.65625 Specificity Score = 0.6323529411764706 - when threshold at 0.6 CF: [[48 31] [ 6 15]] accuracy = 0.63 F1 Score = 0.4477611940298507 Sensitivity Score = 0.7142857142857143 Specificity Score = 0.6075949367088608 - when threshold at 0.7 CF: [[49 39] [ 5 7]] accuracy = 0.56 F1 Score = 0.2413793103448276 Sensitivity Score = 0.5833333333333334 Specificity Score = 0.5568181818181818 - when threshold at 0.8 CF: [[51 41] [ 3 5]] accuracy = 0.56 F1 Score = 0.18518518518518517 Sensitivity Score = 0.625 Specificity Score = 0.5543478260869565 - when threshold at 0.9 CF: [[52 43] [ 2 3]] accuracy = 0.55 F1 Score = 0.11764705882352941 Sensitivity Score = 0.6 Specificity Score = 0.5473684210526316 - . # Test for different threshold levels # using colors just to make it easir to read and spot numbers thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] sens = [] spec = [] for t in thresholds: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() sens.append(tp/(tp+fn)) spec.append(tn/(tn+fp)) plt.figure(figsize=(10,6)) plt.plot(thresholds, sens, label=&#39;Sensitivity&#39;) plt.plot(thresholds, spec, label=&#39;Specificity&#39;) plt.xlabel(&#39;Threshold Value&#39;) plt.ylabel(&#39;Score&#39;) plt.legend() plt.show() . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars if __name__ == &#39;__main__&#39;: .",
            "url": "http://tarekatwan.com/blog/fastpages/jupyter/2020/06/01/Working-with-DICOM-in-healtcare-using-python.html",
            "relUrl": "/fastpages/jupyter/2020/06/01/Working-with-DICOM-in-healtcare-using-python.html",
            "date": " • Jun 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "http://tarekatwan.com/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Linear Separability",
            "content": "Linear vs Non-Linear Classification . Two subsets are said to be linearly separable if there exists a hyperplane that separates the elements of each set in a way that all elements of one set resides on the opposite side of the hyperplane from the other set. In 2D plotting, we can depict this through a separation line, and in 3D plotting through a hyperplane. . By definition Linear Separability is defined: . Two sets $H = { H^1, cdots,H^h } subseteq mathbb{R}^d$ and $M = { M^1, cdots,M^m } subseteq mathbb{R}^d$ are said to be linearly separable if $ exists a in mathbb{R}^n$, $b in mathbb{R} : H subseteq { x in mathbb{R}^n : a^T x &gt; b }$ and $M subseteq { x in mathbb{R}^n : a^Tx leq b }$ 1 . In simple words, the expression above states that H and M are linearly separable if there exists a hyperplane that completely separates the elements of [latex]H [/latex] and elements of $M$. . Image source from Sebastian Raschka 1 . In the figure above, (A) shows a linear classification problem and (B) shows a non-linear classification problem. In (A) our decision boundary is a linear one that completely separates the blue dots from the green dots. In this scenario several linear classifiers can be implemented. . In (B) our decision boundary is non-linear and we would be using non-linear kernel functions and other non-linear classification algorithms and techniques. . Generally speaking, in Machine Learning and before running any type of classifier, it is important to understand the data we are dealing with to determine which algorithm to start with, and which parameters we need to adjust that are suitable for the task. This brings us to the topic of linear separability and understanding if our problem is linear or non-linear. . As states above, there are several classification algorithms that are designed to separate the data by constructing a linear decision boundary (hyperplane) to divide the classes and with that comes the assumption: that the data is linearly separable. Now, in real world scenarios things are not that easy and data in many cases may not be linearly separable and thus non-linear techniques are applied. Without digging too deep, the decision of linear vs non-linear techniques is a decision the data scientist need to make based on what they know in terms of the end goal, what they are willing to accept in terms of error, the balance between model complexity and generalization, bias-variance tradeoff ..etc. . This post was inspired by research papers on the topic of linear separability including The Linear Separability Problem: Some Testing Method 2, 3 . My goal in this post is to apply and test few techniques in python and demonstrate how they can be implemented. Some of those techniques for testing linear separability are: . Domain Knowledge and Expertise | Data Visualization | Computational Geometry (Convex Hulls) | Linear Programming | Machine Learning: * Perceptron * Support Vector Machine | . Domain Knowledge/Expertise . It should be a no-brainer that the first step should always be to seek insight from analysts and other data scientists who are already dealing with the data and familiar with it. It is critical before embarking on any data discovery journey to always start by asking questions to better understand the purpose of the task (your goal) and gain early insight into the data from the domain experts (business data users , data/business analysts or data scientists) that are closer to the data and deal with it daily. . Getting our data . For the other four (4) approaches listed above, we will explore these concepts using the classic Iris data set and implement some of the theories behind testing for linear separability using Python. . Since this is a well known data set we know in advance which classes are linearly separable (domain knowledge/past experiences coming into play here).For our analysis we will use this knowledge to confirm our findings. . The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. . Let’s get things ready first by importing the necessary libraries and loading our data. . import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn import datasets data = datasets.load_iris() #create a DataFrame df = pd.DataFrame(data.data, columns=data.feature_names) df[&#39;Target&#39;] = pd.DataFrame(data.target) df.head() .   sepal Length (cm) sepal width (cm) petal length (cm) petal width (cm) Target . 0 | 5.1 | 3.5 | 1.4 | 0.2 | 0 | . 1 | 4.9 | 3.0 | 1.4 | 0.2 | 0 | . 2 | 4.7 | 3.2 | 1.3 | 0.2 | 0 | . 3 | 4.6 | 3.1 | 1.5 | 0.2 | 0 | . 4 | 5.0 | 3.6 | 1.4 | 0.2 | 0 | . Data Visiualization . The simplest and quickest method is to visualize the data. This approach may not be feasible or as straight forward if the number of features is large, making it hard to plot in 2D . In such a case, we can use a Pair Plot approach, and pandas gives us a great option to do so with scatter_matrix: . from pandas.tools.plotting import scatter_matrix scatter_matrix(df.iloc[:,0:4], figsize=(15,11)) . . The scatter matrix above is a pair-wise scatter plot for all features in the data set (we have four features so we get a 4x4 matrix). The scatter matrix provides insight into how these variables are correlated. Let’s expand upon this by creating a scatter plot for the Petal Length vs Petal Width from the scatter matrix. . plt.clf() plt.figure(figsize=(10,6)) plt.scatter(df.iloc[:,2], df.iloc[:,3]) plt.title(&#39;Petal Width vs Petal Length&#39;) plt.xlabel(data.feature_names[2]) plt.ylabel(data.feature_names[3]) plt.show() . . It’s still not that helpful. Let’s color each class and add a legend so we can understand what the plot is trying to convey in terms of data distribution per class and determine if the classes can be linearly separable visually. . Let’s update our code: . plt.clf() plt.figure(figsize = (10, 6)) names = data.target_names colors = [&#39;b&#39;,&#39;r&#39;,&#39;g&#39;] label = (data.target).astype(np.int) plt.title(&#39;Petal Width vs Petal Length&#39;) plt.xlabel(data.feature_names[2]) plt.ylabel(data.feature_names[3]) for i in range(len(names)): bucket = df[df[&#39;Target&#39;] == i] bucket = bucket.iloc[:,[2,3]].values plt.scatter(bucket[:, 0], bucket[:, 1], label=names[i]) plt.legend() plt.show() . . Much better. We just plotted the entire data set, all 150 points. There are 50 data points per class. And Yes, at first glance we can see that the blue dots (Setosa class) can be easily separated by drawing a line and segregate it from the rest of the classes. But what about the other two classes? . Let’s examine another approach to be more certain. . Computational Geometry . In this approach we will use a Convex Hull to check whether a particular class is linearly separable or not from the rest. In simplest terms, the convex hull represents the outer boundaries of a group of data points (classes) which is why sometimes it’s called the convex envelope. . The logic when using convex hulls when testing for linear separability is pretty straight forward which can be stated as: . Two classes X and Y are LS (Linearly Separable) if the intersection of the convex hulls of X and Y is empty, and NLS (Not Linearly Separable) with a non-empty intersection. . A quick way to see how this works is to visualize the data points with the convex hulls for each class. We will plot the hull boundaries to examine the intersections visually. We will be using the Scipy library to help us compute the convex hull. For more information please refer to Scipy documentation. . Let’s update the previous code to include convex hulls. . from scipy.spatial import ConvexHull plt.clf() plt.figure(figsize = (10, 6)) names = data.target_names label = (data.target).astype(np.int) colors = [&#39;b&#39;,&#39;r&#39;,&#39;g&#39;] plt.title(&#39;Petal Width vs Petal Length&#39;) plt.xlabel(data.feature_names[2]) plt.ylabel(data.feature_names[3]) for i in range(len(names)): bucket = df[df[&#39;Target&#39;] == i] bucket = bucket.iloc[:,[2,3]].values hull = ConvexHull(bucket) plt.scatter(bucket[:, 0], bucket[:, 1], label=names[i]) for j in hull.simplices: plt.plot(bucket[j,0], bucket[j,1], colors[i]) plt.legend() plt.show() . And our output should look like this: . . It is more obvious now, visually at least, that Setosa is a linearly separable class form the other two. In other words, we can easily draw a straight line to separate Setosa from non-Setosa (Setosas vs. everything else). Both Versicolor and Virginica classes are not linearly separable because we can see there is indeed an intersection. . Linear Programming . By definition Linear Separability is defined: . Two sets $H = { H^1, cdots,H^h } subseteq mathbb{R}^d$ and $M = { M^1, cdots,M^m } subseteq mathbb{R}^d$ are said to be linearly separable if $ exists a in mathbb{R}^n$, $b in mathbb{R} : H subseteq { x in mathbb{R}^n : a^T x gt; b }$ and $M subseteq { x in mathbb{R}^n : a^Tx leq b }$ 3 . In simple words, the expression above states that H and M are linearly separable if there exists a hyperplane that completely separates the elements of $H$ and elements of $M$. . $H$ and $M$ are linearly separable if the optimal value of Linear Program $(LP)$ is $0$ . Here is a great post that implements this in R which I followed as an inspiration for this section on linear programming with python: Testing for Linear Separability with LP in R 4. . Below is the code in python using scipy linprog(method=&#39;simplex&#39;) to solve our linear programming problem. If we examine the output, using LP (Linear Programming) method we can conclude that it is possible to have a hyperplane that linearly separates Setosa from the rest of the classes, which is the only linearly separable class from the rest. . If the problem is solvable, the Scipy output will provide us with additional information: . Returns   . success: bool | True or False (True if a solution was found) | . status: int | 0 : Optimization terminated successfully, 1 : Iteration limit reached, 2 : Problem appears to be infeasible, 3 : Problem appears to be unbounded | . message : str | Describing the status | . x: ndarray | The independent variable vector which optimizes the linear programming problem. | . slack: ndarray | The values of the slack variables. Each slack variable corresponds to an inequality constraint. If the slack is zero, then the corresponding constraint is active. | . nit : int | The number of iterations performed. | . fun : float | Value of the objective function | . For our example, I am only looking at the status/success to determine if a solution was found or not. . from scipy.optimize import linprog dic = {0: &#39;setosa&#39;, 1: &#39;versicolor&#39;, 2: &#39;verginica&#39;} for i in dic.keys(): df[&quot;newTarget&quot;] = np.where(df[&#39;Target&#39;] == i, 1 , -1) from sklearn.preprocessing import StandardScaler sc = StandardScaler() tmp = df.iloc[:,[2,3]].values tmp = sc.fit_transform(tmp) xx = np.array(df.newTarget.values.reshape(-1,1) * tmp) t = np.where(df[&#39;Target&#39;] == i, 1 , -1) #2-D array which, when matrix-multiplied by x, gives the values of #the upper-bound inequality constraints at x. A_ub = np.append(xx, t.reshape(-1,1), 1) #1-D array of values representing the upper-bound of each #inequality constraint (row) in A_ub. b_ub = np.repeat(-1, A_ub.shape[0]).reshape(-1,1) # Coefficients of the linear objective function to be minimized. c_obj = np.repeat(1, A_ub.shape[1]) res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, options={&quot;disp&quot;: False}) if res.success: print(&#39;There is linear separability between {} and the rest&#39;.format(dic[i])) else: print(&#39;No linear separability between {} and the rest&#39;.format(dic[i])) . &gt;&gt;&gt;output There is linear separability between setosa and the rest No linear separability between versicolor and the rest No linear separability between verginica and the rest . Machine Learning . In this section we will examine two classifiers for the purpose of testing for linear separability: the Perceptron (simplest form of Neural Networks) and Support Vector Machines (part of a class known as Kernel Methods) . Single Layer Perceptron . The perceptron is an algorithm used for binary classification and belongs to a class of linear classifiers. In binary classification, we are trying to separate data into two buckets: either you are in Buket A or Bucket B. This can be stated even simpler: either you are in Bucket A or not in Bucket A (assuming we have only two classes) and hence the name binary classification. {1if w . x + b&gt;00otherwise large begin{cases} displaystyle 1 &amp; text {if w . x + b} &gt; {0} 0 &amp; text {otherwise} end{cases}⎩⎪⎨⎪⎧​10​if w . x + b&gt;0otherwise​ . A single layer perceptron will only converge if the input vectors are linearly separable. In this state, all input vectors would be classified correctly indicating linear separability. It will not converge if they are not linearly separable. In other words, it will not classify correctly if the data set is not linearly separable. For our testing purpose, this is exactly what we need. . We will apply it on the entire data instead of splitting to test/train since our intent is to test for linear separability among the classes and not to build a model for future predictions. . We will use Scikit-Learn and pick the Perceptron as our linear model selection. Before that, let’s do some basic data preprocessing tasks: . # Data Preprocessing x = df.iloc[:, [2,3]].values # we are picking Setosa to be 1 and all other classes will be 0 y = (data.target == 0).astype(np.int) #Perform feature scaling from sklearn.preprocessing import StandardScaler sc= StandardScaler() x = sc.fit_transform(x) . Now, let’s build our classifier: . from sklearn.linear_model import Perceptron perceptron = Perceptron(random_state = 0) perceptron.fit(x, y) predicted = perceptron.predict(x) . To get a better intuition on the results we will plot the confusion matrix and decision boundary. . from sklearn.metrics import confusion_matrix cm = confusion_matrix(y, predicted) plt.clf() plt.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Wistia) classNames = [&#39;Negative&#39;,&#39;Positive&#39;] plt.title(&#39;Perceptron Confusion Matrix - Entire Data&#39;) plt.ylabel(&#39;True label&#39;) plt.xlabel(&#39;Predicted label&#39;) tick_marks = np.arange(len(classNames)) plt.xticks(tick_marks, classNames, rotation=45) plt.yticks(tick_marks, classNames) s = [[&#39;TN&#39;,&#39;FP&#39;], [&#39;FN&#39;, &#39;TP&#39;]] for i in range(2): for j in range(2): plt.text(j,i, str(s[i][j])+&quot; = &quot;+str(cm[i][j])) plt.show() . . Now, let’s draw our decision boundary: . from matplotlib.colors import ListedColormap plt.clf() X_set, y_set = x, y X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01)) plt.contourf(X1, X2, perceptron.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap((&#39;navajowhite&#39;, &#39;darkkhaki&#39;))) plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap((&#39;red&#39;, &#39;green&#39;))(i), label = j) plt.title(&#39;Perceptron Classifier (Decision boundary for Setosa vs the rest)&#39;) plt.xlabel(&#39;Petal Length&#39;) plt.ylabel(&#39;Petal Width&#39;) plt.legend() plt.show() . . We can see that our Perceptron did converge and was able to classify Setosa from Non-Setosa with perfect accuracy because indeed the data is linearly separable. This would not be the case if the data was not linearly separable. So, let’s try it on another class. . Outputs below are for Versicolor class: . . Support Vector Machines . Now, let’s examine another approach using Support Vector Machines (SVM) with a linear kernel. In order to test for Linear Separability we will pick a hard-margin (for maximum distance as opposed to soft-margin) SVM with a linear kernel. Now, if the intent was to train a model our choices would be completely different. But, since we are testing for linear separability, we want a rigid test that would fail (or produce erroneous results if not converging) to help us better assess the data at hand. . Image source Wikipedia: Maximum-margin hyperplane 5 . Now, let’s code: . from sklearn.svm import SVC svm = SVC(C=1.0, kernel=&#39;linear&#39;, random_state=0) svm.fit(x, y) predicted = svm.predict(x) cm = confusion_matrix(y, predicted) plt.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Wistia) classNames = [&#39;Negative&#39;,&#39;Positive&#39;] plt.title(&#39;SVM Linear Kernel Confusion Matrix - Setosa&#39;) plt.ylabel(&#39;True label&#39;) plt.xlabel(&#39;Predicted label&#39;) tick_marks = np.arange(len(classNames)) plt.xticks(tick_marks, classNames, rotation=45) plt.yticks(tick_marks, classNames) s = [[&#39;TN&#39;,&#39;FP&#39;], [&#39;FN&#39;, &#39;TP&#39;]] for i in range(2): for j in range(2): plt.text(j,i, str(s[i][j])+&quot; = &quot;+str(cm[i][j])) . Here are the plots for the confusion matrix and decision boundary: . . Perfect separartion/classification indicating a linear separability. . Now, let’s examin and rerun the test against Versicolor class and we get the plots below. Interesting enough, we don’t see a decision boundary and the confusion matrix indicates the classifier is not doing a good job at all. . . Now, for fun and to demonstrate how powerful SVMs can be let’s apply a non-linear kernel. In this case we will apply a Gaussian Radial Basis Function known as RBF Kernel. A slight change to the code above and we get completely different results: . x = df.iloc[:, [2,3]].values y = (data.target == 1).astype(np.int) # we are picking Versicolor to be 1 and all other classes will be 0 from sklearn.preprocessing import StandardScaler sc = StandardScaler() x = sc.fit_transform(x) from sklearn.svm import SVC svm = SVC(kernel=&#39;rbf&#39;, random_state=0) svm.fit(x, y) predicted = svm.predict(x) cm = confusion_matrix(y, predicted) plt.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Wistia) classNames = [&#39;Negative&#39;,&#39;Positive&#39;] plt.title(&#39;SVM RBF Confusion Matrix - Versicolor&#39;) plt.ylabel(&#39;True label&#39;) plt.xlabel(&#39;Predicted label&#39;) tick_marks = np.arange(len(classNames)) plt.xticks(tick_marks, classNames, rotation=45) plt.yticks(tick_marks, classNames) s = [[&#39;TN&#39;,&#39;FP&#39;], [&#39;FN&#39;, &#39;TP&#39;]] for i in range(2): for j in range(2): plt.text(j,i, str(s[i][j])+&quot; = &quot;+str(cm[i][j])) . . Hope this helps. . References: . The Linear Separability Problem: Some Testing Methods http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.6481&amp;rep=rep1&amp;type=pdf &#8617; . | A Simple Algorithm for Linear Separability Test http://mllab.csa.iisc.ernet.in/downloads/Labtalk/talk30_01_08/lin_sep_test.pdf &#8617; . | Convex Optimization, Linear Programming: http://www.stat.cmu.edu/~ryantibs/convexopt-F13/scribes/lec2.pdf &#8617; &#8617;2 . | Test for Linear Separability with Linear Programming in R https://www.joyofdata.de/blog/testing-linear-separability-linear-programming-r-glpk/ &#8617; . | Support Vector Machine https://en.wikipedia.org/wiki/Support_vector_machine &#8617; . |",
            "url": "http://tarekatwan.com/blog/markdown/2017/12/31/linear-separability.html",
            "relUrl": "/markdown/2017/12/31/linear-separability.html",
            "date": " • Dec 31, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This blog belongs to Tarek Atwan. I bring over 15 years of experience in Data Analytics, Business Intelligence, and Product Development. . I am passionate about Coding, Machine Learning, Artificial Intelligence, Emerging Technologies, Cloud Computing, Web Development and Mobile Development. I enjoy coding in Python, Julia, R, and JavaScript. .",
          "url": "http://tarekatwan.com/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "http://tarekatwan.com/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}