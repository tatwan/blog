{
  
    
        "post0": {
            "title": "AI for Healthcare (Part 3)",
            "content": "import numpy as np import pandas as pd import pydicom %matplotlib inline import matplotlib.pyplot as plt import keras from keras.preprocessing.image import ImageDataGenerator from keras.models import model_from_json import glob from skimage.transform import resize . !ls | grep .dcm . test1.dcm test2.dcm test3.dcm test4.dcm test5.dcm test6.dcm . test_dicoms = glob.glob(&#39;*.dcm&#39;) test_dicoms . [&#39;test2.dcm&#39;, &#39;test5.dcm&#39;, &#39;test1.dcm&#39;, &#39;test4.dcm&#39;, &#39;test6.dcm&#39;, &#39;test3.dcm&#39;] . a = pydicom.dcmread(test_dicoms[0]) . for i in test_dicoms: ds = pydicom.dcmread(i) print(ds.StudyDescription, ds.Modality, ds.PatientPosition) . Cardiomegaly DX AP No Finding CT PA No Finding DX PA No Finding DX PA No Finding DX XX Effusion DX AP . In the check_dicom function, you need to check for image position, image type(modality), and body part on ALL .dcm files so that you can know which files are valid to be used for your algorithm (as a hint 3 of the files should not be useable). . Suggestion:- In your cell block where you show the probabilities of the presence of Pneumonia presence instead of showing 1 you can print Pneumonia present and instead of 0 print Pneumonia absent so that the reader may easily understand the output of your results. . # This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array # of just the imaging data def check_dicom(filename): # todo print(&#39;Load file {} ...&#39;.format(filename)) ds = pydicom.dcmread(filename) # if ds.Modality == &#39;DX&#39; and ds.PatientPosition in [&#39;AP&#39;, &#39;PA&#39;] and ds.StudyDescription not in [&#39;Cardiomegaly&#39;]: if ds.Modality == &#39;DX&#39; and ds.PatientPosition in [&#39;AP&#39;, &#39;PA&#39;]: img = ds.pixel_array return img else: print(f&#39;{filename} not suitable&#39;) # This function takes the numpy array output by check_dicom and # runs the appropriate pre-processing needed for our model input def preprocess_image(img,img_size): # todo # proc_img = (img - img_mean)/img_std # proc_img = resize(proc_img, img_size) idg = ImageDataGenerator() img = resize(img, IMG_SIZE) proc_img = idg.flow( img, y=None, batch_size=32, shuffle=True, sample_weight=None, seed=None, save_to_dir=None, save_prefix=&quot;&quot;, save_format=&quot;png&quot;, subset=None,) return proc_img # This function loads in our trained model w/ weights and compiles it def load_model(model_path, weight_path): # todo json_file = open(model_path, &#39;r&#39;) loaded_model_json = json_file.read() json_file.close() loaded_model = model_from_json(loaded_model_json) # load weights into new model loaded_model.load_weights(weight_path) print(&quot;Loaded model from disk&quot;) return loaded_model # This function uses our device&#39;s threshold parameters to predict whether or not # the image shows the presence of pneumonia using our trained model def predict_image(model, img, thresh): # todo prediction_prob = model.predict(img, verbose = True) prediction = [&#39;Pneumoinia Present&#39; if i[0] &gt; thresh else &#39;Pneumoinia Abscent&#39; for i in prediction_prob] return prediction_prob,prediction . plt.imshow(check_dicom(&#39;test1.dcm&#39;), cmap=&#39;gray&#39;) . Load file test1.dcm ... . &lt;matplotlib.image.AxesImage at 0x7fab6bf97c10&gt; . plt.imshow(check_dicom(&#39;test4.dcm&#39;), cmap=&#39;gray&#39;) . Load file test4.dcm ... . &lt;matplotlib.image.AxesImage at 0x7fab6bf1e8d0&gt; . test_dicoms = [&#39;test1.dcm&#39;,&#39;test2.dcm&#39;,&#39;test3.dcm&#39;,&#39;test4.dcm&#39;,&#39;test5.dcm&#39;,&#39;test6.dcm&#39;] model_path = &#39;my_model.json&#39; weight_path = &#39;xray_class_my_model.best.hdf5&#39; IMG_SIZE=(1,224,224,3) # This might be different if you did not use vgg16 # img_mean = # img_std = # loads the std dev image value they used during training preprocessing my_model = load_model(model_path, weight_path) thresh = 0.5 X = [] # use the .dcm files to test your prediction for i in test_dicoms: img = np.array([]) img = check_dicom(i) if img is None: continue img_proc = preprocess_image(img,IMG_SIZE) X.append(img_proc) pred_proba, pred = predict_image(my_model,img_proc,thresh) print(pred_proba, pred) . Loaded model from disk Load file test1.dcm ... 1/1 [==============================] - 1s 1s/step [[0.43534777]] [&#39;Pneumoinia Abscent&#39;] Load file test2.dcm ... 1/1 [==============================] - 1s 553ms/step [[0.4329888]] [&#39;Pneumoinia Abscent&#39;] Load file test3.dcm ... 1/1 [==============================] - 1s 567ms/step [[0.4371698]] [&#39;Pneumoinia Abscent&#39;] Load file test4.dcm ... 1/1 [==============================] - 1s 609ms/step [[0.43534777]] [&#39;Pneumoinia Abscent&#39;] Load file test5.dcm ... test5.dcm not suitable Load file test6.dcm ... test6.dcm not suitable . # Using the Second Model test_dicoms = [&#39;test1.dcm&#39;,&#39;test2.dcm&#39;,&#39;test3.dcm&#39;,&#39;test4.dcm&#39;,&#39;test5.dcm&#39;,&#39;test6.dcm&#39;] model_path = &#39;my_model2.json&#39; weight_path = &#39;xray_class_my_model2.best.hdf5&#39; IMG_SIZE=(1,224,224,3) # This might be different if you did not use vgg16 # img_mean = # img_std = # loads the std dev image value they used during training preprocessing my_model = load_model(model_path, weight_path) thresh = 0.5 X = [] # use the .dcm files to test your prediction for i in test_dicoms: img = np.array([]) img = check_dicom(i) if img is None: continue img_proc = preprocess_image(img,IMG_SIZE) X.append(img_proc) pred_proba, pred = predict_image(my_model,img_proc,thresh) print(pred_proba, pred) . Loaded model from disk Load file test1.dcm ... 1/1 [==============================] - 1s 945ms/step [[0.49144208]] [&#39;Pneumoinia Abscent&#39;] Load file test2.dcm ... 1/1 [==============================] - 1s 557ms/step [[0.48717716]] [&#39;Pneumoinia Abscent&#39;] Load file test3.dcm ... 1/1 [==============================] - 1s 569ms/step [[0.4967311]] [&#39;Pneumoinia Abscent&#39;] Load file test4.dcm ... 1/1 [==============================] - 1s 559ms/step [[0.49144208]] [&#39;Pneumoinia Abscent&#39;] Load file test5.dcm ... test5.dcm not suitable Load file test6.dcm ... test6.dcm not suitable .",
            "url": "http://tarekatwan.com/blog/jupyter/dicom/python/eda/2020/05/21/part-3-inference-DICOM.html",
            "relUrl": "/jupyter/dicom/python/eda/2020/05/21/part-3-inference-DICOM.html",
            "date": " • May 21, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "AI for Healthcare (Part 2)",
            "content": "Load libraries . The code below provides a skeleton for the model building &amp; training component of your project. You can add/remove/build on code however you see fit, this is meant as a starting point. . import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import os from glob import glob %matplotlib inline import matplotlib.pyplot as plt ## General libraries import seaborn as sns from itertools import chain import pydicom from random import sample ## Scikit-Learn from skimage.io import imread, imshow from skimage import io from sklearn.model_selection import train_test_split from sklearn.metrics import f1_score, confusion_matrix, auc, roc_auc_score, roc_curve, accuracy_score, precision_recall_curve, average_precision_score ## Keras from keras.preprocessing.image import ImageDataGenerator from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D from keras.models import Sequential, Model, model_from_json from keras.optimizers import Adam from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau from keras.applications.vgg16 import VGG16 . Using TensorFlow backend. . Do some early processing of your metadata for easier model training: . ## Load the NIH data to all_xray_df all_xray_df = pd.read_csv(&#39;/data/Data_Entry_2017.csv&#39;) all_image_paths = {os.path.basename(x): x for x in glob(os.path.join(&#39;/data&#39;,&#39;images*&#39;, &#39;*&#39;, &#39;*.png&#39;))} print(&#39;Scans found:&#39;, len(all_image_paths), &#39;, Total Headers&#39;, all_xray_df.shape[0]) all_xray_df[&#39;path&#39;] = all_xray_df[&#39;Image Index&#39;].map(all_image_paths.get) all_xray_df.sample(3) . Scans found: 112120 , Total Headers 112120 . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImage[Width Height] OriginalImagePixelSpacing[x y] Unnamed: 11 path . 53332 00013467_020.png | Consolidation | 20 | 13467 | 32 | M | AP | 2500 | 2048 | 0.168 | 0.168 | NaN | /data/images_006/images/00013467_020.png | . 50286 00012722_001.png | Effusion | 1 | 12722 | 63 | M | PA | 2978 | 2898 | 0.143 | 0.143 | NaN | /data/images_006/images/00012722_001.png | . 6270 00001695_001.png | No Finding | 1 | 1695 | 59 | M | PA | 2500 | 2048 | 0.168 | 0.168 | NaN | /data/images_002/images/00001695_001.png | . all_xray_df.columns . Index([&#39;Image Index&#39;, &#39;Finding Labels&#39;, &#39;Follow-up #&#39;, &#39;Patient ID&#39;, &#39;Patient Age&#39;, &#39;Patient Gender&#39;, &#39;View Position&#39;, &#39;OriginalImage[Width&#39;, &#39;Height]&#39;, &#39;OriginalImagePixelSpacing[x&#39;, &#39;y]&#39;, &#39;Unnamed: 11&#39;, &#39;path&#39;], dtype=&#39;object&#39;) . Data Preprocessing - Reference EDA notebook . Create column for every disease | Remove Unnamed: 11 column | Remove Patient Age outlier data for ages above 100. Mostly these are ages 150-413 which don&#39;t make sense and obviously data entry error | Remove images for Mass and Infiltration based on the Analysis in EDA notebook showing similarity in Pixel Density Distribution with Pneumonia cases. | . ## Here you may want to create some extra columns in your table with binary indicators of certain diseases ## rather than working directly with the &#39;Finding Labels&#39; column # Todo all_labels = list(set(list(chain.from_iterable([i.split(&#39;|&#39;) for i in all_xray_df[&#39;Finding Labels&#39;]])))) for c_label in all_labels: all_xray_df[c_label] = all_xray_df[&#39;Finding Labels&#39;].map(lambda finding: 1.0 if c_label in finding else 0) all_xray_df.sample(3) . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImage[Width Height] OriginalImagePixelSpacing[x ... No Finding Edema Mass Pneumothorax Atelectasis Nodule Fibrosis Hernia Cardiomegaly Emphysema . 87568 00021626_012.png | Mass | 12 | 21626 | 55 | F | AP | 2500 | 2048 | 0.168 | ... | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 84734 00020864_000.png | Infiltration | 0 | 20864 | 43 | M | PA | 2992 | 2991 | 0.143 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 93132 00023272_001.png | No Finding | 1 | 23272 | 47 | M | AP | 3056 | 2544 | 0.139 | ... | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 rows × 28 columns . all_xray_df.drop(columns=[&#39;Unnamed: 11&#39;], inplace=True) . Remove Outliers in Patient Age . idx = all_xray_df[all_xray_df[&#39;Patient Age&#39;] &gt; 100].index.tolist() all_xray_df.drop(index=idx, inplace=True) . # Check number of Pneumonia cases sum(all_xray_df[&#39;Pneumonia&#39;] == 1) . 1430 . all_labels . [&#39;Pneumonia&#39;, &#39;Effusion&#39;, &#39;Infiltration&#39;, &#39;Consolidation&#39;, &#39;Pleural_Thickening&#39;, &#39;No Finding&#39;, &#39;Edema&#39;, &#39;Mass&#39;, &#39;Pneumothorax&#39;, &#39;Atelectasis&#39;, &#39;Nodule&#39;, &#39;Fibrosis&#39;, &#39;Hernia&#39;, &#39;Cardiomegaly&#39;, &#39;Emphysema&#39;] . Remove images/rows for Diseases in [Mass, Infiltration] . all_xray_df.shape . (112104, 27) . # First round will use this xray_df = all_xray_df[(all_xray_df[&#39;Mass&#39;] == 0) &amp; (all_xray_df[&#39;Infiltration&#39;] == 0)] xray_df.drop(columns=[&#39;Mass&#39;, &#39;Infiltration&#39;], inplace=True) . /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy errors=errors, . xray_df.shape . (87591, 25) . sum(xray_df[&#39;Pneumonia&#39;] == 1) . 788 . sum(xray_df[&#39;Pneumonia&#39;] == 0) . 86803 . # Second round will use this instead xray_df = all_xray_df.copy() . xray_df.shape . (112104, 27) . sum(xray_df[&#39;Pneumonia&#39;] == 1) . 1430 . sum(xray_df[&#39;Pneumonia&#39;] == 0) . 110674 . Quick Data Check . Deep analysis is done in the EDA Notebook | . plt.figure(figsize=(10,6)) vals = all_xray_df[all_labels].sum().nlargest(15).sort_values() colors = [&#39;#d62728&#39; if i ==&#39;Pneumonia&#39; else &#39;#1f77b4&#39; for i in vals.index] ax = vals.plot(kind=&#39;barh&#39;, color=colors) ax.set(xlabel = &#39;Number of Images with Label&#39;) ax.set(title=&#39;Total data distribution between findings&#39;) plt.show() . plt.figure(figsize=(10,6)) vals = xray_df[xray_df.columns[12:].tolist()].sum().nlargest(15).sort_values() colors = [&#39;#d62728&#39; if i ==&#39;Pneumonia&#39; else &#39;#1f77b4&#39; for i in vals.index] ax = vals.plot(kind=&#39;barh&#39;, color=colors) ax.set(xlabel = &#39;Number of Images with Label&#39;) ax.set(title=&#39;Data istribution between findings (Mass and Infiltration removed)&#39;) plt.show() . Check on few data distributions before we split the data . xray_df[&#39;Patient Gender&#39;].value_counts(normalize=True) . M 0.560423 F 0.439577 Name: Patient Gender, dtype: float64 . First Round - after removing Mass and Infiltration . print(f&quot;Total Pneumonia cases: {sum(xray_df[&#39;Pneumonia&#39;] == 1)}&quot;) print(f&quot;Total Clear cases: {sum(xray_df[&#39;No Finding&#39;] == 1)}&quot;) print(f&quot;Total Records: {len(xray_df)}&quot;) print(&quot;--&quot;) print(f&quot;Percent Pneumonia caes: {sum(xray_df[&#39;Pneumonia&#39;] == 1)/len(xray_df)}&quot;) . Total Pneumonia cases: 788 Total Clear cases: 60353 Total Records: 87591 -- Percent Pneumonia caes: 0.008996358073318035 . Second Round - Wihtout removing Mass and Infiltration . print(f&quot;Total Pneumonia cases: {sum(xray_df[&#39;Pneumonia&#39;] == 1)}&quot;) print(f&quot;Total Clear cases: {sum(xray_df[&#39;No Finding&#39;] == 1)}&quot;) print(f&quot;Total Records: {len(xray_df)}&quot;) print(&quot;--&quot;) print(f&quot;Percent Pneumonia caes: {sum(xray_df[&#39;Pneumonia&#39;] == 1)/len(xray_df)}&quot;) . Total Pneumonia cases: 1430 Total Clear cases: 60353 Total Records: 112104 -- Percent Pneumonia caes: 0.012756012274316705 . Create your training and testing data: . cols = [&#39;path&#39;, &#39;Pneumonia&#39;, &#39;Patient Gender&#39;, &#39;Patient Age&#39;, &#39;View Position&#39;] dt = xray_df[cols] . def create_splits(data, test_size=0.2, strat=None): ## Either build your own or use a built-in library to split your original dataframe into two sets ## that can be used for training and testing your model ## It&#39;s important to consider here how balanced or imbalanced you want each of those sets to be ## for the presence of pneumonia # Todo train_data, val_data = train_test_split(data, test_size = test_size, stratify = data[strat], random_state=42) return train_data, val_data . # Pass our parameters to the function train_set, val_set = create_splits(dt, 0.2, &#39;Pneumonia&#39;) . train_size = len(train_set) val_size = len(val_set) print(f&quot;Training: {sum(train_set[&#39;Pneumonia&#39;] == 1)/train_size}, {sum(train_set[&#39;Pneumonia&#39;] == 0)/train_size}&quot;) print(f&quot;Validation:, {sum(val_set[&#39;Pneumonia&#39;] == 1)/val_size}, {sum(val_set[&#39;Pneumonia&#39;] == 0)/val_size} &quot;) . Training: 0.012756040721206917, 0.987243959278793 Validation:, 0.01275589848802462, 0.9872441015119754 . Research Papers and Articles regarding Imbalanced Classes in Deep Learning . Survey on deep learning with class imbalance - Springer | Solving Class Imbalance problem in CNN - Medium | Deep Over-sampling Framework for Classifying Imbalanced Data - Paper | SMOTE for Imbalanced Classification with Python | Note: From the research it seems a combination of undersampling and oversampling may produce the best results. This means undersampling the majority class which in our case is the Non-Penumonia and oversampling the minority class. Possibly in the future I will need to experiment further with these techniques. For now, I will just reduce the data from the majority class to bring them to a balance. . Handling Imbalance classes . Even though with Patient Gender there is a slight imbalance as well, I think it can be neglected for now. The current technique to balance Pneumonia and Non-Pneumonia classes will chunk out a lot of data already and I would like to preserve as much data as possible for training. . (1) Training Set 50/50 split . p_idx = train_set[train_set[&#39;Pneumonia&#39;]==1].index.tolist() np_idx = train_set[train_set[&#39;Pneumonia&#39;]==0].index.tolist() np_sample = sample(np_idx,len(p_idx)) train_df = train_set.loc[p_idx + np_sample] . train_df.shape . (2288, 5) . Let&#39;s check the data distribution between Positive and Negative . train_size = len(train_df) print(f&quot;Training: {sum(train_df[&#39;Pneumonia&#39;] == 1)/train_size}, {sum(train_df[&#39;Pneumonia&#39;] == 0)/train_size}&quot;) . Training: 0.5, 0.5 . (2) Validation Set 25/75 split . p_idx = val_set[val_set[&#39;Pneumonia&#39;]==1].index.tolist() np_idx = val_set[val_set[&#39;Pneumonia&#39;]==0].index.tolist() np_sample = sample(np_idx,len(p_idx)*3) val_df = val_set.loc[p_idx + np_sample] . val_df . path Pneumonia Patient Gender Patient Age View Position . 77329 /data/images_009/images/00018996_002.png | 1.0 | M | 22 | AP | . 57152 /data/images_007/images/00014197_002.png | 1.0 | M | 58 | AP | . 106986 /data/images_012/images/00028874_003.png | 1.0 | F | 68 | AP | . 64071 /data/images_007/images/00015809_023.png | 1.0 | F | 38 | AP | . 42455 /data/images_005/images/00010924_003.png | 1.0 | F | 62 | PA | . ... ... | ... | ... | ... | ... | . 97576 /data/images_011/images/00025754_012.png | 0.0 | M | 67 | AP | . 90305 /data/images_010/images/00022454_009.png | 0.0 | F | 54 | PA | . 103513 /data/images_011/images/00027627_002.png | 0.0 | F | 68 | PA | . 95363 /data/images_011/images/00025071_001.png | 0.0 | M | 55 | PA | . 35314 /data/images_005/images/00009324_001.png | 0.0 | M | 26 | AP | . 1144 rows × 5 columns . val_df.shape . (1144, 5) . val_size = len(val_df) print(f&quot;Training: {sum(val_df[&#39;Pneumonia&#39;] == 1)/val_size}, {sum(val_df[&#39;Pneumonia&#39;] == 0)/val_size}&quot;) . Training: 0.25, 0.75 . Checking - analysis after reducing the majority non-pneumonia class . from collections import Counter . Counter(train_df.Pneumonia) . Counter({1.0: 1144, 0.0: 1144}) . Counter(val_df.Pneumonia) . Counter({1.0: 286, 0.0: 858}) . train_df[train_df.Pneumonia == 1][&#39;Patient Gender&#39;].value_counts(normalize=True) . M 0.583916 F 0.416084 Name: Patient Gender, dtype: float64 . val_df[val_df.Pneumonia == 1][&#39;Patient Gender&#39;].value_counts(normalize=True) . M 0.590909 F 0.409091 Name: Patient Gender, dtype: float64 . Library imblearn to investigate and revisit in the future . # !pip install -U imbalanced-learn . # import imblearn # from imblearn.over_sampling import SMOTE # print(imblearn.__version__) . Now we can begin our model-building &amp; training . First suggestion: perform some image augmentation on your data . ## This is the image size that VGG16 takes as input IMG_SIZE = (224, 224) . def my_image_augmentation(horizontal_flip=False, vertical_flip=False, height_shift_range=0, width_shift_range=0, rotation_range=0, shear_range=0, zoom_range=0): ## recommendation here to implement a package like Keras&#39; ImageDataGenerator ## with some of the built-in augmentations ## keep an eye out for types of augmentation that are or are not appropriate for medical imaging data ## Also keep in mind what sort of augmentation is or is not appropriate for testing vs validation data ## STAND-OUT SUGGESTION: implement some of your own custom augmentation that&#39;s *not* ## built into something like a Keras package # Todo img_aug = ImageDataGenerator(rescale=1. / 255.0, horizontal_flip = horizontal_flip, vertical_flip = vertical_flip, height_shift_range= height_shift_range, width_shift_range=width_shift_range, rotation_range=rotation_range, shear_range = shear_range, zoom_range=zoom_range) return img_aug def make_train_gen(train_idg, train_df, x_col, y_col, target_size, batch_size): ## Create the actual generators using the output of my_image_augmentation for your training data ## Suggestion here to use the flow_from_dataframe library, e.g.: # my_train = my_image_augmentation(horizontal_flip = True, # vertical_flip = False, # height_shift_range= 0.1, # width_shift_range=0.1, # rotation_range=20, # shear_range = 0.1, # zoom_range=0.1) train_gen = train_idg.flow_from_dataframe(dataframe=train_df, directory=None, x_col = x_col, y_col = y_col, class_mode = &#39;binary&#39;, target_size = target_size, batch_size = batch_size ) # Todo return train_gen def make_val_gen(val_idg, val_df, x_col, y_col, target_size, batch_size): # my_val_idg = my_image_augmentation() val_gen = val_idg.flow_from_dataframe(dataframe = val_df, directory=None, x_col = x_col, y_col = y_col, class_mode = &#39;binary&#39;, target_size = target_size, batch_size = batch_size) # Todo return val_gen . Note: Due to error requiring that the classes should be string since the class_mode is set to binary . train_df[&#39;Pneumonia&#39;] = train_df[&#39;Pneumonia&#39;].astype(&#39;str&#39;) val_df[&#39;Pneumonia&#39;] = val_df[&#39;Pneumonia&#39;].astype(&#39;str&#39;) . train_idg = my_image_augmentation(True, False, 0.1, 0.1, 20, 0.1, 0.1) val_idg = my_image_augmentation() . train_gen = make_train_gen(train_idg=train_idg, train_df=train_df, x_col=&#39;path&#39;, y_col=&#39;Pneumonia&#39;, target_size=IMG_SIZE, batch_size=22) val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;Pneumonia&#39;, IMG_SIZE, 22) . Found 2288 validated image filenames belonging to 2 classes. Found 1144 validated image filenames belonging to 2 classes. . ## May want to pull a single large batch of random validation data for testing after each epoch: valX, valY = val_gen.next() . ## May want to look at some examples of our augmented training data. ## This is helpful for understanding the extent to which data is being manipulated prior to training, ## and can be compared with how the raw data look prior to augmentation t_x, t_y = next(train_gen) fig, m_axs = plt.subplots(4, 4, figsize = (16, 16)) for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()): c_ax.imshow(c_x[:,:,0], cmap = &#39;bone&#39;) if c_y == 1: c_ax.set_title(&#39;Pneumonia&#39;) else: c_ax.set_title(&#39;No Pneumonia&#39;) c_ax.axis(&#39;off&#39;) . Build your model: . Recommendation here to use a pre-trained network downloaded from Keras for fine-tuning . model = VGG16(include_top=True, weights=&#39;imagenet&#39;) . Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5 553467904/553467096 [==============================] - 7s 0us/step . model.summary() . Model: &#34;vgg16&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) (None, 224, 224, 3) 0 _________________________________________________________________ block1_conv1 (Conv2D) (None, 224, 224, 64) 1792 _________________________________________________________________ block1_conv2 (Conv2D) (None, 224, 224, 64) 36928 _________________________________________________________________ block1_pool (MaxPooling2D) (None, 112, 112, 64) 0 _________________________________________________________________ block2_conv1 (Conv2D) (None, 112, 112, 128) 73856 _________________________________________________________________ block2_conv2 (Conv2D) (None, 112, 112, 128) 147584 _________________________________________________________________ block2_pool (MaxPooling2D) (None, 56, 56, 128) 0 _________________________________________________________________ block3_conv1 (Conv2D) (None, 56, 56, 256) 295168 _________________________________________________________________ block3_conv2 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_conv3 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_pool (MaxPooling2D) (None, 28, 28, 256) 0 _________________________________________________________________ block4_conv1 (Conv2D) (None, 28, 28, 512) 1180160 _________________________________________________________________ block4_conv2 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_conv3 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_pool (MaxPooling2D) (None, 14, 14, 512) 0 _________________________________________________________________ block5_conv1 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv2 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv3 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_pool (MaxPooling2D) (None, 7, 7, 512) 0 _________________________________________________________________ flatten (Flatten) (None, 25088) 0 _________________________________________________________________ fc1 (Dense) (None, 4096) 102764544 _________________________________________________________________ fc2 (Dense) (None, 4096) 16781312 _________________________________________________________________ predictions (Dense) (None, 1000) 4097000 ================================================================= Total params: 138,357,544 Trainable params: 138,357,544 Non-trainable params: 0 _________________________________________________________________ . def load_pretrained_model(): model = VGG16(include_top=True, weights=&#39;imagenet&#39;) transfer_layer = model.get_layer(&#39;block5_pool&#39;) vgg_model = Model(inputs = model.input, outputs = transfer_layer.output) # Todo for layer in vgg_model.layers[0:-2]: layer.trainable = False return vgg_model . vgg_model = load_pretrained_model() . vgg_model.summary() . Model: &#34;model_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) (None, 224, 224, 3) 0 _________________________________________________________________ block1_conv1 (Conv2D) (None, 224, 224, 64) 1792 _________________________________________________________________ block1_conv2 (Conv2D) (None, 224, 224, 64) 36928 _________________________________________________________________ block1_pool (MaxPooling2D) (None, 112, 112, 64) 0 _________________________________________________________________ block2_conv1 (Conv2D) (None, 112, 112, 128) 73856 _________________________________________________________________ block2_conv2 (Conv2D) (None, 112, 112, 128) 147584 _________________________________________________________________ block2_pool (MaxPooling2D) (None, 56, 56, 128) 0 _________________________________________________________________ block3_conv1 (Conv2D) (None, 56, 56, 256) 295168 _________________________________________________________________ block3_conv2 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_conv3 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_pool (MaxPooling2D) (None, 28, 28, 256) 0 _________________________________________________________________ block4_conv1 (Conv2D) (None, 28, 28, 512) 1180160 _________________________________________________________________ block4_conv2 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_conv3 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_pool (MaxPooling2D) (None, 14, 14, 512) 0 _________________________________________________________________ block5_conv1 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv2 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv3 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_pool (MaxPooling2D) (None, 7, 7, 512) 0 ================================================================= Total params: 14,714,688 Trainable params: 2,359,808 Non-trainable params: 12,354,880 _________________________________________________________________ . def build_my_model(pre_trained): my_model = Sequential() # Add the convolutional part of the VGG16 model from above. my_model.add(vgg_model) my_model.add(Flatten()) # Flatten the output of the VGG16 model because it is from a # convolutional layer. my_model.add(Dense(1024, activation=&#39;relu&#39;)) my_model.add(Dropout(0.5)) my_model.add(Dense(512, activation=&#39;relu&#39;)) my_model.add(Dropout(0.5)) my_model.add(Dense(256, activation=&#39;relu&#39;)) my_model.add(Dropout(0.5)) # Final output layer # Add a dense (aka. fully-connected) layer. # This is for combining features that the VGG16 model has # recognized in the image. my_model.add(Dense(1, activation=&#39;sigmoid&#39;)) ## Set our optimizer, loss function, and learning rate (you can change the learning rate here if you&#39;d like) ## but otherwise this cell can be run as is return my_model . model = build_my_model(vgg_model) . optimizer = Adam(lr=0.001) loss = &#39;binary_crossentropy&#39; metrics = [&#39;binary_accuracy&#39;] model.compile(optimizer=optimizer, loss=loss, metrics=metrics) . model.summary() . Model: &#34;sequential_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= model_2 (Model) (None, 7, 7, 512) 14714688 _________________________________________________________________ flatten_2 (Flatten) (None, 25088) 0 _________________________________________________________________ dense_5 (Dense) (None, 1024) 25691136 _________________________________________________________________ dropout_4 (Dropout) (None, 1024) 0 _________________________________________________________________ dense_6 (Dense) (None, 512) 524800 _________________________________________________________________ dropout_5 (Dropout) (None, 512) 0 _________________________________________________________________ dense_7 (Dense) (None, 256) 131328 _________________________________________________________________ dropout_6 (Dropout) (None, 256) 0 _________________________________________________________________ dense_8 (Dense) (None, 1) 257 ================================================================= Total params: 41,062,209 Trainable params: 28,707,329 Non-trainable params: 12,354,880 _________________________________________________________________ . ## Below is some helper code that will allow you to add checkpoints to your model, ## This will save the &#39;best&#39; version of your model by comparing it to previous epochs of training ## Note that you need to choose which metric to monitor for your model&#39;s &#39;best&#39; performance if using this code. ## The &#39;patience&#39; parameter is set to 10, meaning that your model will train for ten epochs without seeing ## improvement before quitting # Todo weight_path=&quot;{}_my_model2.best.hdf5&quot;.format(&#39;xray_class&#39;) checkpoint = ModelCheckpoint(weight_path, monitor= &#39;val_loss&#39;, verbose=1, save_best_only=True, mode= &#39;min&#39;, save_weights_only = True) early = EarlyStopping(monitor= &#39;val_loss&#39;, mode= &#39;min&#39;, patience=10) callbacks_list = [checkpoint, early] . Training with data less Mass and Infiltration diseases . Later we will run it again below without removing for compairosn . Rerun cells after training but skipping the removal of these two diseases | . Start training! . history = model.fit_generator(train_gen, validation_data=[valX, valY], epochs=30, callbacks=callbacks_list ) . Epoch 1/30 58/58 [==============================] - 37s 645ms/step - loss: 0.8703 - binary_accuracy: 0.5087 - val_loss: 0.6810 - val_binary_accuracy: 0.6364 Epoch 00001: val_loss improved from inf to 0.68097, saving model to xray_class_my_model.best.hdf5 Epoch 2/30 58/58 [==============================] - 33s 569ms/step - loss: 0.6919 - binary_accuracy: 0.5135 - val_loss: 0.7292 - val_binary_accuracy: 0.3182 Epoch 00002: val_loss did not improve from 0.68097 Epoch 3/30 58/58 [==============================] - 33s 571ms/step - loss: 0.6929 - binary_accuracy: 0.5349 - val_loss: 0.7089 - val_binary_accuracy: 0.3636 Epoch 00003: val_loss did not improve from 0.68097 Epoch 4/30 58/58 [==============================] - 32s 559ms/step - loss: 0.6906 - binary_accuracy: 0.5349 - val_loss: 0.7905 - val_binary_accuracy: 0.3636 Epoch 00004: val_loss did not improve from 0.68097 Epoch 5/30 58/58 [==============================] - 33s 573ms/step - loss: 0.6904 - binary_accuracy: 0.5230 - val_loss: 0.6647 - val_binary_accuracy: 0.6364 Epoch 00005: val_loss improved from 0.68097 to 0.66472, saving model to xray_class_my_model.best.hdf5 Epoch 6/30 58/58 [==============================] - 33s 572ms/step - loss: 0.6939 - binary_accuracy: 0.5190 - val_loss: 0.7036 - val_binary_accuracy: 0.3182 Epoch 00006: val_loss did not improve from 0.66472 Epoch 7/30 58/58 [==============================] - 33s 563ms/step - loss: 0.6859 - binary_accuracy: 0.5381 - val_loss: 0.8723 - val_binary_accuracy: 0.3182 Epoch 00007: val_loss did not improve from 0.66472 Epoch 8/30 58/58 [==============================] - 34s 578ms/step - loss: 0.6943 - binary_accuracy: 0.5317 - val_loss: 0.7141 - val_binary_accuracy: 0.4091 Epoch 00008: val_loss did not improve from 0.66472 Epoch 9/30 58/58 [==============================] - 33s 571ms/step - loss: 0.6877 - binary_accuracy: 0.5214 - val_loss: 0.6806 - val_binary_accuracy: 0.5455 Epoch 00009: val_loss did not improve from 0.66472 Epoch 10/30 58/58 [==============================] - 33s 572ms/step - loss: 0.6825 - binary_accuracy: 0.5484 - val_loss: 0.6835 - val_binary_accuracy: 0.4091 Epoch 00010: val_loss did not improve from 0.66472 Epoch 11/30 58/58 [==============================] - 33s 571ms/step - loss: 0.6948 - binary_accuracy: 0.5349 - val_loss: 0.7128 - val_binary_accuracy: 0.3636 Epoch 00011: val_loss did not improve from 0.66472 Epoch 12/30 58/58 [==============================] - 33s 572ms/step - loss: 0.6943 - binary_accuracy: 0.4952 - val_loss: 0.6914 - val_binary_accuracy: 0.3182 Epoch 00012: val_loss did not improve from 0.66472 Epoch 13/30 58/58 [==============================] - 33s 566ms/step - loss: 0.6928 - binary_accuracy: 0.5190 - val_loss: 0.6955 - val_binary_accuracy: 0.5455 Epoch 00013: val_loss did not improve from 0.66472 Epoch 14/30 58/58 [==============================] - 33s 566ms/step - loss: 0.6896 - binary_accuracy: 0.5389 - val_loss: 0.6792 - val_binary_accuracy: 0.5909 Epoch 00014: val_loss did not improve from 0.66472 Epoch 15/30 58/58 [==============================] - 33s 569ms/step - loss: 0.6909 - binary_accuracy: 0.5619 - val_loss: 0.6724 - val_binary_accuracy: 0.6364 Epoch 00015: val_loss did not improve from 0.66472 . history.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_binary_accuracy&#39;, &#39;loss&#39;, &#39;binary_accuracy&#39;]) . After training for some time, look at the performance of your model by plotting some performance statistics: . Note, these figures will come in handy for your FDA documentation later in the project . !ls . &#39;Build and train model.ipynb&#39; test2.dcm EDA.ipynb test3.dcm FDA_Submission_Template.md test4.dcm grayrange.gif test5.dcm Inference.ipynb test6.dcm my_model.json Trial.ipynb sample_labels.csv xray_class_my_model.best.hdf5 test1.dcm . ## After training, make some predictions to assess your model&#39;s overall performance ## Note that detecting pneumonia is hard even for trained expert radiologists, ## so there is no need to make the model perfect. model.load_weights(weight_path) pred_Y = model.predict(valX, batch_size = 32, verbose = True) . 22/22 [==============================] - 0s 18ms/step . Create a binary output instead of just probability using a standard 0.5 threshold for now . pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] . def plot_auc(t_y, p_y): ## Hint: can use scikit-learn&#39;s built in functions here like roc_curve # Todo fig, c_ax = plt.subplots(1,1, figsize = (9, 9)) fpr, tpr, thresholds = roc_curve(t_y, p_y) c_ax.plot(fpr, tpr, label = &#39;%s (AUC:%0.2f)&#39; % (&#39;Pneumonia&#39;, auc(fpr, tpr))) c_ax.legend() c_ax.set_xlabel(&#39;False Positive Rate&#39;) c_ax.set_ylabel(&#39;True Positive Rate&#39;) return ## what other performance statistics do you want to include here besides AUC? # def ... # Todo def plot_pr(t_y, p_y): fig, c_ax = plt.subplots(1,1, figsize = (9, 9)) precision, recall, thresholds = precision_recall_curve(t_y, p_y) c_ax.plot(precision, recall, label = &#39;%s (AP Score:%0.2f)&#39; % (&#39;Pneumonia&#39;, average_precision_score(t_y,p_y))) c_ax.legend() c_ax.set_xlabel(&#39;Recall&#39;) c_ax.set_ylabel(&#39;Precision&#39;) #Also consider plotting the history of your model training: def plot_history(history, kind): &#39;&#39;&#39; kind: either &quot;accuracy&quot; or &quot;loss&quot; &#39;&#39;&#39; plt.figure(figsize = (9, 9)) kind = &#39;binary_accuracy&#39; if kind == &#39;accuracy&#39; else kind plt.plot(history.history[f&#39;val_{kind}&#39;], label=f&#39;validation {kind}&#39;) plt.plot(history.history[f&#39;{kind}&#39;], label=f&#39;training {kind}&#39;) plt.title(f&#39;Validation/Training {kind}&#39;) plt.ylabel(&#39;EPOCHS&#39;) plt.legend() plt.show() return . plot_auc(valY, pred_Y) . ## plot figures plot_history(history, &#39;accuracy&#39;) # Todo . plot_history(history, &#39;loss&#39;) . Once you feel you are done training, you&#39;ll need to decide the proper classification threshold that optimizes your model&#39;s performance for a given metric (e.g. accuracy, F1, precision, etc. You decide) . confusion_matrix(pred_Y_binary, valY) . array([[13, 6], [ 2, 1]]) . tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() . accuracy_score(pred_Y_binary, valY) f1_score(pred_Y_binary, valY) sens = tp/(tp+fn) spec = tn/(tn+fp) spec . 0.6842105263157895 . precision, recall, thresholds = precision_recall_curve(valY, pred_Y) . ## Find the threshold that optimize your model&#39;s performance, ## and use that threshold to make binary classification. Make sure you take all your metrics into consideration. # Todo . val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;Pneumonia&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() . Found 632 validated image filenames belonging to 2 classes. . pred_Y = model.predict(valX, batch_size = 32, verbose = True) . 100/100 [==============================] - 5s 48ms/step . ## Let&#39;s look at some examples of true vs. predicted with our best model: # Todo fig, m_axs = plt.subplots(10, 10, figsize = (16, 16)) i = 0 for (c_x, c_y, c_ax) in zip(valX[0:100], valY[0:100], m_axs.flatten()): c_ax.imshow(c_x[:,:,0], cmap = &#39;bone&#39;) if c_y == 1: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;1, 1&#39;) else: c_ax.set_title(&#39;1, 0&#39;, color=&#39;red&#39;) else: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;0, 1&#39;, color=&#39;red&#39;) else: c_ax.set_title(&#39;0, 0&#39;) c_ax.axis(&#39;off&#39;) i=i+1 . pred_Y_binary = pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] confusion_matrix(pred_Y_binary, valY) . array([[71, 21], [ 5, 3]]) . acc = accuracy_score(pred_Y_binary, valY) f1 = f1_score(pred_Y_binary, valY) sens = tp/(tp+fn) spec = tn/(tn+fp) spec . 0.6842105263157895 . plot_auc(valY, pred_Y) . plot_pr(valY, pred_Y) . ## Just save model architecture to a .json: model_json = model.to_json() with open(&quot;my_model.json&quot;, &quot;w&quot;) as json_file: json_file.write(model_json) . !ls . &#39;Build and train model.ipynb&#39; test2.dcm EDA.ipynb test3.dcm FDA_Submission_Template.md test4.dcm grayrange.gif test5.dcm Inference.ipynb test6.dcm my_model.json Trial.ipynb sample_labels.csv xray_class_my_model.best.hdf5 test1.dcm . Using saved model for further analysis and testing . json_file = open(&#39;my_model.json&#39;, &#39;r&#39;) loaded_model_json = json_file.read() json_file.close() loaded_model = model_from_json(loaded_model_json) # load weights into new model loaded_model.load_weights(&quot;xray_class_my_model.best.hdf5&quot;) print(&quot;Loaded model from disk&quot;) . Loaded model from disk . loaded_model.summary() . Model: &#34;sequential_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= model_1 (Model) (None, 7, 7, 512) 14714688 _________________________________________________________________ flatten_1 (Flatten) (None, 25088) 0 _________________________________________________________________ dense_1 (Dense) (None, 1024) 25691136 _________________________________________________________________ dropout_1 (Dropout) (None, 1024) 0 _________________________________________________________________ dense_2 (Dense) (None, 512) 524800 _________________________________________________________________ dropout_2 (Dropout) (None, 512) 0 _________________________________________________________________ dense_3 (Dense) (None, 256) 131328 _________________________________________________________________ dropout_3 (Dropout) (None, 256) 0 _________________________________________________________________ dense_4 (Dense) (None, 1) 257 ================================================================= Total params: 41,062,209 Trainable params: 28,707,329 Non-trainable params: 12,354,880 _________________________________________________________________ . val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;Pneumonia&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() pred_Y = loaded_model.predict(valX, batch_size = 32, verbose = True) . Found 1144 validated image filenames belonging to 2 classes. 100/100 [==============================] - 58s 582ms/step . fig, m_axs = plt.subplots(10, 10, figsize = (16, 16)) i = 0 for (c_x, c_y, c_ax) in zip(valX[0:100], valY[0:100], m_axs.flatten()): c_ax.imshow(c_x[:,:,0], cmap = &#39;bone&#39;) if c_y == 1: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;1, 1&#39;) else: c_ax.set_title(&#39;1, 0&#39;, color=&#39;red&#39;) else: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;0, 1&#39;, color=&#39;red&#39;) else: c_ax.set_title(&#39;0, 0&#39;) c_ax.axis(&#39;off&#39;) i=i+1 . # Test for different threshold levels # using colors just to make it easir to read and spot numbers for t in [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] print(f&#39;when threshold at {t} CF:&#39;) print(confusion_matrix(pred_Y_binary, valY)) tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() print(f&#39; x1b[34maccuracy x1b[0m= x1b[31m{accuracy_score(pred_Y_binary, valY)} x1b[0m&#39;) print(f&#39;F1 Score = {f1_score(pred_Y_binary, valY)}&#39;) print(f&#39; x1b[34mSensitivity Score x1b[0m= x1b[31m{tp/(tp+fn)} x1b[0m&#39;) print(f&#39; x1b[34mSpecificity Score x1b[0m= x1b[31m{tn/(tn+fp)} x1b[0m&#39;) print(&#39;-&#39;) . when threshold at 0.4 CF: [[ 1 1] [72 26]] accuracy = 0.27 F1 Score = 0.41600000000000004 Sensitivity Score = 0.2653061224489796 Specificity Score = 0.5 - when threshold at 0.5 CF: [[59 25] [14 2]] accuracy = 0.61 F1 Score = 0.09302325581395349 Sensitivity Score = 0.125 Specificity Score = 0.7023809523809523 - when threshold at 0.6 CF: [[73 27] [ 0 0]] accuracy = 0.73 F1 Score = 0.0 Sensitivity Score = nan Specificity Score = 0.73 - when threshold at 0.7 CF: [[73 27] [ 0 0]] accuracy = 0.73 F1 Score = 0.0 Sensitivity Score = nan Specificity Score = 0.73 - when threshold at 0.8 CF: [[73 27] [ 0 0]] accuracy = 0.73 F1 Score = 0.0 Sensitivity Score = nan Specificity Score = 0.73 - when threshold at 0.9 CF: [[73 27] [ 0 0]] accuracy = 0.73 F1 Score = 0.0 Sensitivity Score = nan Specificity Score = 0.73 - . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in long_scalars # Remove the CWD from sys.path while we load stuff. . # Test for different threshold levels # using colors just to make it easir to read and spot numbers thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] sens = [] spec = [] for t in thresholds: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() sens.append(tp/(tp+fn)) spec.append(tn/(tn+fp)) plt.figure(figsize=(10,6)) plt.plot(thresholds, sens, label=&#39;Sensitivity&#39;) plt.plot(thresholds, spec, label=&#39;Specificity&#39;) plt.xlabel(&#39;Threshold Value&#39;) plt.ylabel(&#39;Score&#39;) plt.legend() plt.show() . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in long_scalars # Remove the CWD from sys.path while we load stuff. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars if __name__ == &#39;__main__&#39;: . thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] fscore = [] for t in thresholds: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] fscore.append(f1_score(valY, pred_Y_binary)) plt.figure(figsize=(10,6)) plt.plot(thresholds, fscore, label=&#39;f1 score&#39;) plt.xlabel(&#39;Threshold Value&#39;) plt.ylabel(&#39;Score&#39;) plt.title(&#39;F1 Score vs Threshold&#39;) plt.legend() plt.show() . # Test for different threshold levels # using colors just to make it easir to read and spot numbers thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] prec = [] recall = [] for t in thresholds: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() prec.append(tp/(tp+fp)) recall.append(tp/(tp+fn)) plt.figure(figsize=(10,6)) plt.plot(thresholds, prec, label=&#39;Precision&#39;) plt.plot(thresholds, recall, label=&#39;Recall&#39;) plt.xlabel(&#39;Threshold Value&#39;) plt.ylabel(&#39;Score&#39;) plt.title(&#39;Precision and Recall vs Threshold &#39;) plt.legend() plt.show() . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in long_scalars # Remove the CWD from sys.path while we load stuff. . 2. Redo Training . This time without removing diseases . history = model.fit_generator(train_gen, validation_data=[valX, valY], epochs=30, callbacks=callbacks_list ) . Epoch 1/30 104/104 [==============================] - 65s 625ms/step - loss: 0.6983 - binary_accuracy: 0.5184 - val_loss: 0.6378 - val_binary_accuracy: 0.6818 Epoch 00001: val_loss improved from inf to 0.63784, saving model to xray_class_my_model2.best.hdf5 Epoch 2/30 104/104 [==============================] - 60s 578ms/step - loss: 0.6882 - binary_accuracy: 0.5472 - val_loss: 0.6362 - val_binary_accuracy: 0.5455 Epoch 00002: val_loss improved from 0.63784 to 0.63619, saving model to xray_class_my_model2.best.hdf5 Epoch 3/30 104/104 [==============================] - 60s 577ms/step - loss: 0.6862 - binary_accuracy: 0.5590 - val_loss: 0.6303 - val_binary_accuracy: 0.5000 Epoch 00003: val_loss improved from 0.63619 to 0.63032, saving model to xray_class_my_model2.best.hdf5 Epoch 4/30 104/104 [==============================] - 60s 574ms/step - loss: 0.6821 - binary_accuracy: 0.5629 - val_loss: 0.7177 - val_binary_accuracy: 0.2727 Epoch 00004: val_loss did not improve from 0.63032 Epoch 5/30 104/104 [==============================] - 61s 587ms/step - loss: 0.6770 - binary_accuracy: 0.5909 - val_loss: 0.6853 - val_binary_accuracy: 0.4545 Epoch 00005: val_loss did not improve from 0.63032 Epoch 6/30 104/104 [==============================] - 60s 572ms/step - loss: 0.6769 - binary_accuracy: 0.5795 - val_loss: 0.7305 - val_binary_accuracy: 0.2273 Epoch 00006: val_loss did not improve from 0.63032 Epoch 7/30 104/104 [==============================] - 59s 570ms/step - loss: 0.6777 - binary_accuracy: 0.5826 - val_loss: 0.6393 - val_binary_accuracy: 0.5000 Epoch 00007: val_loss did not improve from 0.63032 Epoch 8/30 104/104 [==============================] - 60s 574ms/step - loss: 0.6753 - binary_accuracy: 0.5743 - val_loss: 0.6945 - val_binary_accuracy: 0.4091 Epoch 00008: val_loss did not improve from 0.63032 Epoch 9/30 104/104 [==============================] - 59s 571ms/step - loss: 0.6718 - binary_accuracy: 0.6023 - val_loss: 0.6987 - val_binary_accuracy: 0.4091 Epoch 00009: val_loss did not improve from 0.63032 Epoch 10/30 104/104 [==============================] - 60s 575ms/step - loss: 0.6603 - binary_accuracy: 0.6058 - val_loss: 0.7548 - val_binary_accuracy: 0.3636 Epoch 00010: val_loss did not improve from 0.63032 Epoch 11/30 104/104 [==============================] - 60s 580ms/step - loss: 0.6691 - binary_accuracy: 0.5957 - val_loss: 0.7652 - val_binary_accuracy: 0.3182 Epoch 00011: val_loss did not improve from 0.63032 Epoch 12/30 104/104 [==============================] - 60s 573ms/step - loss: 0.6628 - binary_accuracy: 0.6031 - val_loss: 0.7235 - val_binary_accuracy: 0.3636 Epoch 00012: val_loss did not improve from 0.63032 Epoch 13/30 104/104 [==============================] - 60s 577ms/step - loss: 0.6698 - binary_accuracy: 0.5988 - val_loss: 0.7546 - val_binary_accuracy: 0.2273 Epoch 00013: val_loss did not improve from 0.63032 . ## After training, make some predictions to assess your model&#39;s overall performance ## Note that detecting pneumonia is hard even for trained expert radiologists, ## so there is no need to make the model perfect. model.load_weights(weight_path) pred_Y = model.predict(valX, batch_size = 32, verbose = True) . 22/22 [==============================] - 0s 15ms/step . Create a binary output instead of just probability using a standard 0.5 threshold for now . pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] . def plot_auc(t_y, p_y): ## Hint: can use scikit-learn&#39;s built in functions here like roc_curve # Todo fig, c_ax = plt.subplots(1,1, figsize = (9, 9)) fpr, tpr, thresholds = roc_curve(t_y, p_y) c_ax.plot(fpr, tpr, label = &#39;%s (AUC:%0.2f)&#39; % (&#39;Pneumonia&#39;, auc(fpr, tpr))) c_ax.legend() c_ax.set_xlabel(&#39;False Positive Rate&#39;) c_ax.set_ylabel(&#39;True Positive Rate&#39;) return ## what other performance statistics do you want to include here besides AUC? # def ... # Todo def plot_pr(t_y, p_y): fig, c_ax = plt.subplots(1,1, figsize = (9, 9)) precision, recall, thresholds = precision_recall_curve(t_y, p_y) c_ax.plot(precision, recall, label = &#39;%s (AP Score:%0.2f)&#39; % (&#39;Pneumonia&#39;, average_precision_score(t_y,p_y))) c_ax.legend() c_ax.set_xlabel(&#39;Recall&#39;) c_ax.set_ylabel(&#39;Precision&#39;) #Also consider plotting the history of your model training: def plot_history(history, kind): &#39;&#39;&#39; kind: either &quot;accuracy&quot; or &quot;loss&quot; &#39;&#39;&#39; plt.figure(figsize = (9, 9)) kind = &#39;binary_accuracy&#39; if kind == &#39;accuracy&#39; else kind plt.plot(history.history[f&#39;val_{kind}&#39;], label=f&#39;validation {kind}&#39;) plt.plot(history.history[f&#39;{kind}&#39;], label=f&#39;training {kind}&#39;) plt.title(f&#39;Validation/Training {kind}&#39;) plt.ylabel(&#39;EPOCHS&#39;) plt.legend() plt.show() return . plot_auc(valY, pred_Y) . ## plot figures plot_history(history, &#39;accuracy&#39;) # Todo . plot_history(history, &#39;loss&#39;) . Once you feel you are done training, you&#39;ll need to decide the proper classification threshold that optimizes your model&#39;s performance for a given metric (e.g. accuracy, F1, precision, etc. You decide) . confusion_matrix(pred_Y_binary, valY) . array([[9, 2], [9, 2]]) . tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() . precision, recall, thresholds = precision_recall_curve(valY, pred_Y) . val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;Pneumonia&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() . Found 1144 validated image filenames belonging to 2 classes. . pred_Y = model.predict(valX, batch_size = 32, verbose = True) . 100/100 [==============================] - 1s 9ms/step . pred_Y_binary = pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] confusion_matrix(pred_Y_binary, valY) . array([[45, 10], [32, 13]]) . acc = accuracy_score(pred_Y_binary, valY) f1 = f1_score(pred_Y_binary, valY) sens = tp/(tp+fn) spec = tn/(tn+fp) spec . 0.8181818181818182 . plot_auc(valY, pred_Y) . plot_pr(valY, pred_Y) . ## Just save model architecture to a .json: model_json = model.to_json() with open(&quot;my_model2.json&quot;, &quot;w&quot;) as json_file: json_file.write(model_json) . json_file = open(&#39;my_model2.json&#39;, &#39;r&#39;) loaded_model_json = json_file.read() json_file.close() loaded_model = model_from_json(loaded_model_json) # load weights into new model loaded_model.load_weights(&quot;xray_class_my_model2.best.hdf5&quot;) print(&quot;Loaded model from disk&quot;) . Loaded model from disk . val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;Pneumonia&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() pred_Y = loaded_model.predict(valX, batch_size = 32, verbose = True) . Found 1144 validated image filenames belonging to 2 classes. 100/100 [==============================] - 58s 584ms/step . # Test for different threshold levels # using colors just to make it easir to read and spot numbers for t in [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] print(f&#39;when threshold at {t} CF:&#39;) print(confusion_matrix(pred_Y_binary, valY)) tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() print(f&#39; x1b[34maccuracy x1b[0m= x1b[31m{accuracy_score(pred_Y_binary, valY)} x1b[0m&#39;) print(f&#39;F1 Score = {f1_score(pred_Y_binary, valY)}&#39;) print(f&#39; x1b[34mSensitivity Score x1b[0m= x1b[31m{tp/(tp+fn)} x1b[0m&#39;) print(f&#39; x1b[34mSpecificity Score x1b[0m= x1b[31m{tn/(tn+fp)} x1b[0m&#39;) print(&#39;-&#39;) . when threshold at 0.4 CF: [[32 5] [47 16]] accuracy = 0.48 F1 Score = 0.38095238095238093 Sensitivity Score = 0.25396825396825395 Specificity Score = 0.8648648648648649 - when threshold at 0.5 CF: [[47 10] [32 11]] accuracy = 0.58 F1 Score = 0.34375 Sensitivity Score = 0.2558139534883721 Specificity Score = 0.8245614035087719 - when threshold at 0.6 CF: [[79 21] [ 0 0]] accuracy = 0.79 F1 Score = 0.0 Sensitivity Score = nan Specificity Score = 0.79 - when threshold at 0.7 CF: [[79 21] [ 0 0]] accuracy = 0.79 F1 Score = 0.0 Sensitivity Score = nan Specificity Score = 0.79 - when threshold at 0.8 CF: [[79 21] [ 0 0]] accuracy = 0.79 F1 Score = 0.0 Sensitivity Score = nan Specificity Score = 0.79 - when threshold at 0.9 CF: [[79 21] [ 0 0]] accuracy = 0.79 F1 Score = 0.0 Sensitivity Score = nan Specificity Score = 0.79 - . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in long_scalars # Remove the CWD from sys.path while we load stuff. . # Test for different threshold levels # using colors just to make it easir to read and spot numbers thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] sens = [] spec = [] for t in thresholds: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() sens.append(tp/(tp+fn)) spec.append(tn/(tn+fp)) plt.figure(figsize=(10,6)) plt.plot(thresholds, sens, label=&#39;Sensitivity&#39;) plt.plot(thresholds, spec, label=&#39;Specificity&#39;) plt.xlabel(&#39;Threshold Value&#39;) plt.ylabel(&#39;Score&#39;) plt.legend() plt.show() . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars if __name__ == &#39;__main__&#39;: . fscore = [] for t in thresholds: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] fscore.append(f1_score(valY, pred_Y_binary)) plt.figure(figsize=(10,6)) plt.plot(thresholds, fscore, label=&#39;f1 score&#39;) plt.xlabel(&#39;Threshold Value&#39;) plt.ylabel(&#39;Score&#39;) plt.title(&#39;F1 Score vs Threshold&#39;) plt.legend() plt.show() . # Test for different threshold levels # using colors just to make it easir to read and spot numbers thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] prec = [] recall = [] for t in thresholds: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() prec.append(tp/(tp+fp)) recall.append(tp/(tp+fn)) plt.figure(figsize=(10,6)) plt.plot(thresholds, prec, label=&#39;Precision&#39;) plt.plot(thresholds, recall, label=&#39;Recall&#39;) plt.xlabel(&#39;Threshold Value&#39;) plt.ylabel(&#39;Score&#39;) plt.title(&#39;Precision and Recall vs Threshold &#39;) plt.legend() plt.show() . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in long_scalars # Remove the CWD from sys.path while we load stuff. . Additional Testing . Test how the model scores when Pneumonia is existint with other diseases | . import random . p_t = all_xray_df[all_xray_df[&#39;Pneumonia&#39;] == 1] s = p_t[&#39;Finding Labels&#39;].unique().tolist() . p_t[&#39;Finding Labels&#39;].value_counts().nlargest(10) . Pneumonia 322 Infiltration|Pneumonia 199 Edema|Infiltration|Pneumonia 137 Atelectasis|Pneumonia 108 Edema|Pneumonia 83 Effusion|Pneumonia 53 Effusion|Infiltration|Pneumonia 42 Consolidation|Pneumonia 36 Atelectasis|Infiltration|Pneumonia 34 Atelectasis|Effusion|Pneumonia 23 Name: Finding Labels, dtype: int64 . cols = [&#39;Pneumonia&#39;, &#39;Infiltration|Pneumonia&#39;, &#39;Edema|Infiltration|Pneumonia&#39;, &#39;Atelectasis|Pneumonia&#39;, &#39;Edema|Pneumonia&#39;, &#39;Effusion|Pneumonia&#39;, &#39;Effusion|Infiltration|Pneumonia&#39;, &#39;Consolidation|Pneumonia&#39;, &#39;Atelectasis|Infiltration|Pneumonia&#39;] . for r in cols: idx = p_t[p_t[&#39;Finding Labels&#39;].isin([r])].index n_t = all_xray_df[all_xray_df[&#39;No Finding&#39;] == 1] idx2 = n_t.index idx2 = random.choices(idx2, k=(len(idx)*3)) idx = idx.union(idx2) val_df_2 = val_df[val_df.index.isin(idx)] try: val_gen = make_val_gen(val_idg, val_df_2, &#39;path&#39;, &#39;Pneumonia&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() pred_Y = loaded_model.predict(valX, batch_size = 32, verbose = True) pred_Y_binary = pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() prec = tp/(tp+fp) acc = accuracy_score(pred_Y_binary, valY) f1 = f1_score(pred_Y_binary, valY) sens = tp/(tp+fn) spec = tn/(tn+fp) print(f&#39;***************{r}***************&#39;) print(&#39;True Positive:&#39;, tp, end=(&#39;, &#39;)) print(&#39;True Negative:&#39;, tn, end=(&#39;, &#39;)) print(&#39;False Positive&#39;, fp, end=(&#39;, &#39;)) print(&#39;False Negative:&#39;, fn) print(&#39;Sensitivity:&#39;, sens, end=(&#39;, &#39;)) print(&#39;Specificity:&#39;, spec, end=(&#39;, &#39;)) print(&#39;Precision:&#39;, prec, end=(&#39;, &#39;)) print(&#39;F1 Score:&#39;, f1, end=(&#39;, &#39;)) except: continue . Found 77 validated image filenames belonging to 2 classes. 77/77 [==============================] - 45s 583ms/step ***************Pneumonia*************** True Positive: 35, True Negative: 2, False Positive 37, False Negative: 3 Sensitivity: 0.9210526315789473, Specificity: 0.05128205128205128, Precision: 0.4861111111111111, F1 Score: 0.6363636363636362, Found 50 validated image filenames belonging to 2 classes. 50/50 [==============================] - 29s 576ms/step ***************Infiltration|Pneumonia*************** True Positive: 25, True Negative: 2, False Positive 17, False Negative: 6 Sensitivity: 0.8064516129032258, Specificity: 0.10526315789473684, Precision: 0.5952380952380952, F1 Score: 0.684931506849315, Found 25 validated image filenames belonging to 2 classes. 25/25 [==============================] - 14s 575ms/step ***************Edema|Infiltration|Pneumonia*************** True Positive: 16, True Negative: 5, False Positive 4, False Negative: 0 Sensitivity: 1.0, Specificity: 0.5555555555555556, Precision: 0.8, F1 Score: 0.888888888888889, Found 23 validated image filenames belonging to 2 classes. 23/23 [==============================] - 13s 581ms/step ***************Atelectasis|Pneumonia*************** True Positive: 8, True Negative: 3, False Positive 10, False Negative: 2 Sensitivity: 0.8, Specificity: 0.23076923076923078, Precision: 0.4444444444444444, F1 Score: 0.5714285714285714, Found 21 validated image filenames belonging to 2 classes. 21/21 [==============================] - 12s 573ms/step ***************Edema|Pneumonia*************** True Positive: 14, True Negative: 3, False Positive 4, False Negative: 0 Sensitivity: 1.0, Specificity: 0.42857142857142855, Precision: 0.7777777777777778, F1 Score: 0.8750000000000001, Found 15 validated image filenames belonging to 2 classes. 15/15 [==============================] - 9s 578ms/step ***************Effusion|Infiltration|Pneumonia*************** True Positive: 9, True Negative: 2, False Positive 4, False Negative: 0 Sensitivity: 1.0, Specificity: 0.3333333333333333, Precision: 0.6923076923076923, F1 Score: 0.8181818181818181, . Just focusing on Sensitivity for now . sensitivity = {} precision = {} for r in s: idx = p_t[p_t[&#39;Finding Labels&#39;].isin([r])].index n_t = all_xray_df[all_xray_df[&#39;No Finding&#39;] == 1] idx2 = n_t.index idx2 = random.choices(idx2, k=(len(idx)*3)) idx = idx.union(idx2) val_df_2 = val_df[val_df.index.isin(idx)] try: val_gen = make_val_gen(val_idg, val_df_2, &#39;path&#39;, &#39;Pneumonia&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() pred_Y = loaded_model.predict(valX, batch_size = 32, verbose = True) pred_Y_binary = pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() sens = tp/(tp+fn) sensitivity[r] = sens prec = tp/(tp+fp) precision[r] = prec except: continue . Found 80 validated image filenames belonging to 2 classes. 80/80 [==============================] - 47s 590ms/step Found 6 validated image filenames belonging to 2 classes. 6/6 [==============================] - 3s 581ms/step Found 50 validated image filenames belonging to 2 classes. 50/50 [==============================] - 29s 586ms/step Found 5 validated image filenames belonging to 2 classes. 5/5 [==============================] - 3s 571ms/step Found 22 validated image filenames belonging to 2 classes. 22/22 [==============================] - 13s 582ms/step Found 4 validated image filenames belonging to 2 classes. 4/4 [==============================] - 2s 577ms/step Found 10 validated image filenames belonging to 2 classes. 10/10 [==============================] - 6s 585ms/step Found 5 validated image filenames belonging to 2 classes. 5/5 [==============================] - 3s 568ms/step Found 4 validated image filenames belonging to 2 classes. 4/4 [==============================] - 2s 582ms/step Found 3 validated image filenames belonging to 2 classes. 3/3 [==============================] - 2s 581ms/step Found 6 validated image filenames belonging to 2 classes. 6/6 [==============================] - 3s 576ms/step Found 3 validated image filenames belonging to 2 classes. 3/3 [==============================] - 2s 589ms/step Found 7 validated image filenames belonging to 2 classes. 7/7 [==============================] - 4s 582ms/step . sensitivity.keys() . dict_keys([&#39;Nodule|Pneumonia&#39;, &#39;Pneumonia&#39;, &#39;Atelectasis|Infiltration|Pneumonia&#39;, &#39;Infiltration|Pneumonia&#39;, &#39;Edema|Infiltration|Pneumonia&#39;, &#39;Edema|Effusion|Pneumonia&#39;, &#39;Edema|Effusion|Infiltration|Pneumonia&#39;, &#39;Effusion|Pneumonia&#39;, &#39;Effusion|Infiltration|Pneumonia&#39;, &#39;Edema|Pneumonia&#39;, &#39;Infiltration|Pleural_Thickening|Pneumonia&#39;, &#39;Atelectasis|Consolidation|Pneumonia&#39;]) . plt.figure(figsize=(12,9)) plt.title(&#39;Sensitivity Score&#39;) plt.bar(sensitivity.keys(), sensitivity.values()) plt.xticks(rotation=&#39;vertical&#39;) plt.xlabel(&#39;Finding&#39;) plt.ylabel(&#39;Score&#39;) . Text(0, 0.5, &#39;Score&#39;) . plt.figure(figsize=(12,9)) plt.title(&#39;Precision Score&#39;) plt.bar(precision.keys(), precision.values()) plt.xticks(rotation=&#39;vertical&#39;) plt.xlabel(&#39;Finding&#39;) plt.ylabel(&#39;Score&#39;) . Text(0, 0.5, &#39;Score&#39;) .",
            "url": "http://tarekatwan.com/blog/jupyter/dicom/python/tensorflow/eda/2020/05/21/part-2-train-model-DICOM.html",
            "relUrl": "/jupyter/dicom/python/tensorflow/eda/2020/05/21/part-2-train-model-DICOM.html",
            "date": " • May 21, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "AI for Healthcare (Part 1)",
            "content": "Exploratory Data Analysis in Healthcare - Working DICOM Data . import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import os from glob import glob %matplotlib inline import matplotlib.pyplot as plt import seaborn as sns from itertools import chain import pydicom #for working with DICOM files from skimage.io import imread, imshow from skimage import io . EDA is open-ended, and it is up to the analyst to decide on what different ways to slice and dice the data. A good starting point is to look at the requirements for the FDA documentation that we will need to produce as submit with our Machine Learning model. . This EDA will focus on investigating case of pneumonia and understand how data looks in the wild. E.g. what other types of diseases it&#39;s commonly found with, how often it is found, what ages it affects, etc. . Note that this NIH dataset was not specifically acquired for pneumonia. So, while this is a representation of &#39;pneumonia in the wild,&#39; the prevalence of pneumonia may be different if you were to take only chest x-rays that were acquired in an ER setting with suspicion of pneumonia. . Some of the EDA tasks we will perform may include investigating: . The patient demographic data such as gender, age, patient position,etc. (as it is available) | The x-ray views taken (i.e. view position) | The number of cases including: number of pneumonia cases, | number of non-pneumonia cases | . | The distribution of other diseases that are comorbid with pneumonia | Number of disease per patient | Pixel-level assessments of the imaging data for healthy &amp; disease states of interest (e.g. histograms of intensity values) and compare distributions across diseases. | . Data Understanding and Profiling . ## Load NIH data all_xray_df = pd.read_csv(&#39;/data/Data_Entry_2017.csv&#39;) all_xray_df.sample(3) ## We will use&#39;sample_labels.csv&#39; data for pixel level assessments sample_df = pd.read_csv(&#39;sample_labels.csv&#39;) sample_df.sample(5) . Let&#39;s look at the shape of our data: . print(all_xray_df.shape) print(sample_df.shape) . (112120, 12) (5606, 11) . all_xray_df.sample(3) . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImage[Width Height] OriginalImagePixelSpacing[x y] Unnamed: 11 . 48566 00012309_002.png | No Finding | 2 | 12309 | 49 | F | AP | 2500 | 2048 | 0.168 | 0.168 | NaN | . 14793 00003863_011.png | Atelectasis|Effusion | 11 | 3863 | 52 | M | PA | 2992 | 2989 | 0.143 | 0.143 | NaN | . 90097 00022407_001.png | Infiltration | 1 | 22407 | 61 | M | PA | 2992 | 2991 | 0.143 | 0.143 | NaN | . Explore all_xray_df dataframe . Look for null values (empty records) | Check data types | Examine how data is being distributed | Gain some intuititon and understanding on what the data is about | . all_xray_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 112120 entries, 0 to 112119 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 Image Index 112120 non-null object 1 Finding Labels 112120 non-null object 2 Follow-up # 112120 non-null int64 3 Patient ID 112120 non-null int64 4 Patient Age 112120 non-null int64 5 Patient Gender 112120 non-null object 6 View Position 112120 non-null object 7 OriginalImage[Width 112120 non-null int64 8 Height] 112120 non-null int64 9 OriginalImagePixelSpacing[x 112120 non-null float64 10 y] 112120 non-null float64 11 Unnamed: 11 0 non-null float64 dtypes: float64(3), int64(5), object(4) memory usage: 10.3+ MB . Noticed an empty column with no records Unnamed: 11. | Drop Unnamed: 11 column since it has no values. | . all_xray_df.drop(columns=[&#39;Unnamed: 11&#39;], inplace=True) all_xray_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 112120 entries, 0 to 112119 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 Image Index 112120 non-null object 1 Finding Labels 112120 non-null object 2 Follow-up # 112120 non-null int64 3 Patient ID 112120 non-null int64 4 Patient Age 112120 non-null int64 5 Patient Gender 112120 non-null object 6 View Position 112120 non-null object 7 OriginalImage[Width 112120 non-null int64 8 Height] 112120 non-null int64 9 OriginalImagePixelSpacing[x 112120 non-null float64 10 y] 112120 non-null float64 dtypes: float64(2), int64(5), object(4) memory usage: 9.4+ MB . all_xray_df.hist(bins=50, figsize=(20,15)) plt.show() . /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:298: MatplotlibDeprecationWarning: The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead. layout[ax.rowNum, ax.colNum] = ax.get_visible() /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:298: MatplotlibDeprecationWarning: The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead. layout[ax.rowNum, ax.colNum] = ax.get_visible() /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:304: MatplotlibDeprecationWarning: The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead. if not layout[ax.rowNum + 1, ax.colNum]: /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:304: MatplotlibDeprecationWarning: The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead. if not layout[ax.rowNum + 1, ax.colNum]: . In terms of Patient/X-Ray related type of attributes that are possibly more important to understand are &#39;Age&#39; , &#39;Gender&#39; and &#39;View Position&#39;. | Create a plotting function to use to further examine specific attributes/features | Adding to the plots is percent value counts for each category for each attribute/feature using value_counts() for categorical and min/max for continous. | . cols = [&#39;Patient Age&#39;, &#39;Patient Gender&#39;, &#39;View Position&#39;] # function for plotting def plot_hist(d, l): plt.figure(figsize=(6,6)) plt.title(f&#39;{l} distribution&#39;) plt.hist(d) plt.xlabel(l) plt.show() if l == &#39;Patient Age&#39;: print(f&#39;Values Range: nMin:{d.min()} nMax:{d.max()}&#39;) else: print(d.value_counts(normalize=True)) . Data distribution . for c in cols: plot_hist(all_xray_df[c], c) . Values Range: Min:1 Max:414 . M 0.56493 F 0.43507 Name: Patient Gender, dtype: float64 . PA 0.600339 AP 0.399661 Name: View Position, dtype: float64 . Patient Position We have two types of positions PA and AP . Patient Gender it&#39;s %56 Males and %43 Female. Not exactly a balanced distribution, but at the same time not extremely skewed to the point that it may cause concern undersampling or oversampling strategies. . Patient Age Note Max age we have 414 which is not a correct value. This hints that we have outliers in the data that could skew the results. . Remove Outliers . There are outliers in Patient Age indicating data entry problem. . Example: Patient Ages around 400 range does not make sense. But the fact they have been diagnosed already indicate that these are real patients, with diagnosis and a Patient ID. We will drop these records since they represent a small number around 16 records that will be dropped. . all_xray_df[all_xray_df[&#39;Patient Age&#39;] &gt; 100][&#39;Patient Age&#39;] . 20852 412 46965 414 48284 148 55742 148 58650 150 62929 149 74884 152 78795 151 84810 411 85404 412 86264 413 91369 412 95794 153 98495 154 101194 155 104590 155 Name: Patient Age, dtype: int64 . len(all_xray_df[all_xray_df[&#39;Patient Age&#39;] &gt; 100][&#39;Patient Age&#39;]) . 16 . all_xray_df[all_xray_df[&#39;Patient Age&#39;] &gt; 100][&#39;Patient Age&#39;].hist() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb6dba85f50&gt; . idx = all_xray_df[all_xray_df[&#39;Patient Age&#39;] &gt; 100].index.tolist() all_xray_df.drop(index=idx, inplace=True) . Now let&#39;s re-examine the Age distribution after we dropped the outlier records | . all_xray_df[all_xray_df[&#39;Patient Age&#39;] &lt; 100][&#39;Patient Age&#39;].hist() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb6db9bf5d0&gt; . # what is the current maximum age now? all_xray_df[all_xray_df[&#39;Patient Age&#39;] &lt; 100][&#39;Patient Age&#39;].max() . 95 . Data Transformation for Further Analysis . Finding Labels contains a bunch of diagnostic labels concatenated together via | pipes. This will make it hard to understand the relationship between different diagnostics, their distribution ..etc. | Below we will perform a transformation to split each diagnostic and pivot it from ROWS to COLUMNS, this way each diagnostic becomes a feature with 0 or 1 indicating no-presence or presence of the disease. | This technique is similar to Dummy Variables or OneHotEncoding | . # Different ways to do this: # option 1: np.unique(list(chain(*[i.split(&#39;|&#39;) for i in all_xray_df[&#39;Finding Labels&#39;]]))) # option 2: np.unique(list(chain.from_iterable([i.split(&#39;|&#39;) for i in all_xray_df[&#39;Finding Labels&#39;]]))) # option 3: list(set(list(chain.from_iterable([i.split(&#39;|&#39;) for i in all_xray_df[&#39;Finding Labels&#39;]])))) # chain vs chain.from_iterable approach # using list comprehension with chain all_labels = list(set(list(chain.from_iterable([i.split(&#39;|&#39;) for i in all_xray_df[&#39;Finding Labels&#39;]])))) all_labels . [&#39;Infiltration&#39;, &#39;Effusion&#39;, &#39;No Finding&#39;, &#39;Nodule&#39;, &#39;Pleural_Thickening&#39;, &#39;Pneumothorax&#39;, &#39;Hernia&#39;, &#39;Atelectasis&#39;, &#39;Emphysema&#39;, &#39;Pneumonia&#39;, &#39;Fibrosis&#39;, &#39;Mass&#39;, &#39;Consolidation&#39;, &#39;Edema&#39;, &#39;Cardiomegaly&#39;] . # Now, let&#39;s create the columns for each disease and check for presence or no presence for c_label in all_labels: all_xray_df[c_label] = all_xray_df[&#39;Finding Labels&#39;].map(lambda finding: 1.0 if c_label in finding else 0) all_xray_df.sample(3) . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImage[Width Height] OriginalImagePixelSpacing[x ... Pneumothorax Hernia Atelectasis Emphysema Pneumonia Fibrosis Mass Consolidation Edema Cardiomegaly . 23842 00006289_005.png | Pneumonia | 5 | 6289 | 59 | F | AP | 2500 | 2048 | 0.168 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 55702 00013935_004.png | Nodule | 4 | 13935 | 35 | F | PA | 2542 | 2605 | 0.143 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 76095 00018669_004.png | Atelectasis|Effusion|Infiltration | 4 | 18669 | 63 | M | AP | 3056 | 2544 | 0.139 | ... | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 rows × 26 columns . # check distribution for each disease (percent) and sort them (all_xray_df[all_labels].sum()/len(all_xray_df)).nlargest(20) . No Finding 0.538366 Infiltration 0.177433 Effusion 0.118783 Atelectasis 0.103101 Nodule 0.056474 Mass 0.051550 Pneumothorax 0.047286 Consolidation 0.041631 Pleural_Thickening 0.030186 Cardiomegaly 0.024763 Emphysema 0.022443 Edema 0.020535 Fibrosis 0.015040 Pneumonia 0.012756 Hernia 0.002025 dtype: float64 . Analysis from above data . Notice from above, around 54% of the records have No Findings, the remaining diseases correspond to the remaining 46% | Penumonia has a very low occurance around 1.2%. So, we need to pay attention when we train the data. Since it is a rare occurance in comparison, we need to watch for the imbalance of data. Additionally, for validation or testing we need to keep this in mind since this percentage represents real world expectation on how often this disease occurs. | . | . Examin Pneumonia specific data (where Pneumonia has been identified as a diagnostic) . Age distribution . ppage = all_xray_df[(all_xray_df[&#39;Pneumonia&#39;] == 1) &amp; (all_xray_df[&#39;Patient Age&#39;] &lt; 100)][&#39;Patient Age&#39;] ppage.hist() plt.title(&#39;Pneumonia - Patient Age Distribution&#39;) plt.xlabel(&#39;Patient Age&#39;) print(f&#39;Pneumonia Age range between {ppage.min()} and {ppage.max()}&#39;) print(f&quot;Population Age range between {all_xray_df[&#39;Patient Age&#39;].min()} and {all_xray_df[&#39;Patient Age&#39;].max()}&quot;) . Pneumonia Age range between 2 and 90 Population Age range between 1 and 95 . mppage = all_xray_df[(all_xray_df[&#39;Pneumonia&#39;] == 1) &amp; (all_xray_df[&#39;Patient Age&#39;] &lt; 100) &amp; (all_xray_df[&#39;Patient Gender&#39;] == &#39;M&#39;)][&#39;Patient Age&#39;] print(f&#39;Pneumonia Male Age range between {mppage.min()} and {mppage.max()}&#39;) mppage.hist() plt.title(&#39;Pneumonia Male Patients Age Distribution&#39;) plt.xlabel(&#39;Male Ages&#39;) plt.show() . Pneumonia Male Age range between 2 and 87 . fppage = all_xray_df[(all_xray_df[&#39;Pneumonia&#39;] == 1) &amp; (all_xray_df[&#39;Patient Age&#39;] &lt; 100) &amp; (all_xray_df[&#39;Patient Gender&#39;] == &#39;F&#39;)][&#39;Patient Age&#39;] print(f&#39;Pneumonia Female Age range between {fppage.min()} and {fppage.max()}&#39;) fppage.hist() plt.title(&#39;Pneumonia Female Patients Age Distribution&#39;) plt.xlabel(&#39;Female Ages&#39;) plt.show() . Pneumonia Female Age range between 3 and 90 . Pneumonia Cases Specific Analysis . Further examine the Data where Pneumonia is True (records that has Penumonia) . plt.figure(figsize=(12,7)) all_xray_df[all_labels].sum().sort_values(ascending=False).plot(kind=&#39;bar&#39;) plt.ylabel(&#39;Number of images with labels&#39;) plt.xlabel(&#39;Finding Label&#39;) plt.title(&#39;Number of cases/records per Diagnostic Label&#39;) plt.show() . plt.figure(figsize=(12,7)) (all_xray_df[all_labels].sum()/len(all_xray_df)).sort_values(ascending=False).plot(kind=&#39;bar&#39;) plt.ylabel(&#39;Number of images with labels&#39;) plt.xlabel(&#39;Finding Label&#39;) plt.title(&#39;Percent of cases/records per Diagnostic Label&#39;) plt.show() . d = (all_xray_df[all_labels].sum()*100/len(all_xray_df)).sort_values(ascending=False) v = (all_xray_df[all_labels].sum()*100/len(all_xray_df)).sort_values(ascending=False).values plt.figure(figsize=(12,7)) ax = d.plot(kind=&#39;barh&#39;) ax.set(ylabel=&#39;Number of images with labels&#39;) ax.set(xlabel=&#39;Finding Label&#39;) for i, v in enumerate(v): ax.text(v+0.5, i, str(round(v,2))+&#39;%&#39;, color=&#39;black&#39;) plt.show() . Let&#39;s ignore No Finding and focus on Diseases Only | . diagnostics = [&#39;Consolidation&#39;, &#39;Cardiomegaly&#39;, &#39;Atelectasis&#39;, &#39;Nodule&#39;, &#39;Edema&#39;, &#39;Emphysema&#39;, &#39;Hernia&#39;, &#39;Mass&#39;, &#39;Pleural_Thickening&#39;, &#39;Effusion&#39;, &#39;Pneumonia&#39;, &#39;Fibrosis&#39;, &#39;Pneumothorax&#39;, &#39;Infiltration&#39;] . d_df = all_xray_df[all_xray_df[&#39;Finding Labels&#39;] != &#39;No Finding&#39;] # or d_df = all_xray_df[all_xray_df[&#39;Pneumonia&#39;] == 1] d = (d_df[diagnostics].sum()*100/len(d_df)).sort_values(ascending=False) v = (d_df[diagnostics].sum()*100/len(d_df)).sort_values(ascending=False).values plt.figure(figsize=(12,7)) ax = d.plot(kind=&#39;barh&#39;) ax.set(xlabel=&#39;Percent of images with labels&#39;) ax.set(ylabel=&#39;Diseasee&#39;) ax.set(title=&#39;Diseases ONLY Distribution&#39;) for i, v in enumerate(v): ax.text(v+0.5, i, str(round(v,2))+&#39;%&#39;, color=&#39;black&#39;) plt.show() . Notice above: that of all the diseases, the majority %86.5 fall between the top 3 diseases Infiltration, Effusion, Atelectas | Pneumonia is around %2.8 | . Now let&#39;s shift our attention to Pneumonia and co-occurances | . d = d_df[diagnostics].sum().sort_values(ascending=False) v = d_df[diagnostics].sum().sort_values(ascending=False).values plt.figure(figsize=(12,7)) ax = d.plot(kind=&#39;barh&#39;) ax.set(title=&#39;Frequency Distribution Label wise of each disease that co occur with Pneumonia&#39;) ax.set(ylabel=&#39;Disease&#39;) ax.set(xlabel=&#39;Number of images with labels&#39;) for i, v in enumerate(v): ax.text(v+10, i, v, color=&#39;black&#39;) plt.show() . d_df = d_df[d_df[&#39;Pneumonia&#39;] == 1] d = (d_df[diagnostics].sum()*100/len(d_df)).sort_values(ascending=False) v = (d_df[diagnostics].sum()*100/len(d_df)).sort_values(ascending=False).values plt.figure(figsize=(12,7)) ax = d.plot(kind=&#39;barh&#39;) ax.set(xlabel=&#39;Percent of images with labels&#39;) ax.set(ylabel=&#39;Disease&#39;) ax.set(title=&#39;Frequency Distribution Label wise of each disease that co occur with Pneumonia&#39;) for i, v in enumerate(v): ax.text(v+0.5, i, str(round(v,2))+&#39;%&#39;, color=&#39;black&#39;) plt.show() . Note from above: The dominatint three diseases identified before Infiltration, Effusion, Atelectas are also amongst the top 5 co-occuring diseases with Pneumonia at %42.3, %18.7 and %18.3, with Infiltration dominating at %42.3 alone | . d = all_xray_df[all_xray_df[&#39;Pneumonia&#39;] == 1] (d[diagnostics].sum()*100/len(d)).sort_values(ascending=False) (d[diagnostics].sum()*100/len(d)).sort_values(ascending=False).values . array([100. , 42.30769231, 23.77622378, 18.74125874, 18.32167832, 8.6013986 , 4.96503497, 4.8951049 , 3.35664336, 2.86713287, 2.86713287, 1.60839161, 0.76923077, 0.20979021]) . look at how other data being distributed for Pneumonia cases | . d_df.shape . (1430, 26) . for c in cols: plot_hist(d_df[c], c) . Values Range: Min:2 Max:90 . M 0.585315 F 0.414685 Name: Patient Gender, dtype: float64 . AP 0.559441 PA 0.440559 Name: View Position, dtype: float64 . all_xray_df.columns . Index([&#39;Image Index&#39;, &#39;Finding Labels&#39;, &#39;Follow-up #&#39;, &#39;Patient ID&#39;, &#39;Patient Age&#39;, &#39;Patient Gender&#39;, &#39;View Position&#39;, &#39;OriginalImage[Width&#39;, &#39;Height]&#39;, &#39;OriginalImagePixelSpacing[x&#39;, &#39;y]&#39;, &#39;Infiltration&#39;, &#39;Effusion&#39;, &#39;No Finding&#39;, &#39;Nodule&#39;, &#39;Pleural_Thickening&#39;, &#39;Pneumothorax&#39;, &#39;Hernia&#39;, &#39;Atelectasis&#39;, &#39;Emphysema&#39;, &#39;Pneumonia&#39;, &#39;Fibrosis&#39;, &#39;Mass&#39;, &#39;Consolidation&#39;, &#39;Edema&#39;, &#39;Cardiomegaly&#39;], dtype=&#39;object&#39;) . Correlation (Pearson) . all_xray_df[diagnostics].corr() . Consolidation Cardiomegaly Atelectasis Nodule Edema Emphysema Hernia Mass Pleural_Thickening Effusion Pneumonia Fibrosis Pneumothorax Infiltration . Consolidation 1.000000 | 0.015355 | 0.108945 | 0.031812 | 0.020835 | -0.000526 | -0.005414 | 0.074610 | 0.028742 | 0.101130 | 0.025257 | 0.003233 | 0.000487 | 0.045931 | . Cardiomegaly 0.015355 | 1.000000 | 0.015817 | -0.012128 | 0.028331 | -0.007093 | 0.001761 | -0.010670 | 0.009126 | 0.130096 | 0.002859 | 0.004834 | -0.022249 | 0.014191 | . Atelectasis 0.108945 | 0.015817 | 1.000000 | -0.007972 | -0.003379 | 0.032598 | 0.010830 | 0.018995 | 0.025221 | 0.172462 | 0.029948 | 0.011128 | 0.031437 | 0.093157 | . Nodule 0.031812 | -0.012128 | -0.007972 | 1.000000 | 0.000271 | -0.007067 | -0.002424 | 0.101300 | 0.049663 | 0.019109 | -0.003705 | 0.022474 | 0.007579 | 0.042754 | . Edema 0.020835 | 0.028331 | -0.003379 | 0.000271 | 1.000000 | -0.009200 | -0.002325 | 0.002939 | -0.002018 | 0.062127 | 0.174110 | -0.013241 | -0.022479 | 0.094265 | . Emphysema -0.000526 | -0.007093 | 0.032598 | -0.007067 | -0.009200 | 1.000000 | -0.001466 | 0.023232 | 0.026416 | 0.011195 | -0.004880 | -0.000910 | 0.178194 | 0.000406 | . Hernia -0.005414 | 0.001761 | 0.010830 | -0.002424 | -0.002325 | -0.001466 | 1.000000 | 0.011934 | 0.001331 | -0.003658 | 0.000185 | 0.007477 | -0.001621 | -0.003780 | . Mass 0.074610 | -0.010670 | 0.018995 | 0.101300 | 0.002939 | 0.023232 | 0.011934 | 1.000000 | 0.065206 | 0.070770 | -0.000977 | 0.009972 | 0.029980 | 0.013898 | . Pleural_Thickening 0.028742 | 0.009126 | 0.025221 | 0.049663 | -0.002018 | 0.026416 | 0.001331 | 0.065206 | 1.000000 | 0.072037 | 0.002246 | 0.053590 | 0.031682 | 0.020411 | . Effusion 0.101130 | 0.130096 | 0.172462 | 0.019109 | 0.062127 | 0.011195 | -0.003658 | 0.070770 | 0.072037 | 1.000000 | 0.024112 | -0.002779 | 0.047587 | 0.118164 | . Pneumonia 0.025257 | 0.002859 | 0.029948 | -0.003705 | 0.174110 | -0.004880 | 0.000185 | -0.000977 | 0.002246 | 0.024112 | 1.000000 | -0.006862 | -0.009969 | 0.073088 | . Fibrosis 0.003233 | 0.004834 | 0.011128 | 0.022474 | -0.013241 | -0.000910 | 0.007477 | 0.009972 | 0.053590 | -0.002779 | -0.006862 | 1.000000 | 0.000095 | 0.008796 | . Pneumothorax 0.000487 | -0.022249 | 0.031437 | 0.007579 | -0.022479 | 0.178194 | -0.001621 | 0.029980 | 0.031682 | 0.047587 | -0.009969 | 0.000095 | 1.000000 | 0.000597 | . Infiltration 0.045931 | 0.014191 | 0.093157 | 0.042754 | 0.094265 | 0.000406 | -0.003780 | 0.013898 | 0.020411 | 0.118164 | 0.073088 | 0.008796 | 0.000597 | 1.000000 | . plt.figure(figsize=(12,9)) sns.heatmap(all_xray_df[diagnostics].corr(), cmap=&#39;Blues&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb6dc3bd610&gt; . Just looking at the heatmap above, for Pneumonia there is a stronger correlation with Edema and Infiltration cases. Seconday correlation would be Atelectasis and Consolidation cases. . Number of Pneumonia Cases compared to data population . print(f&#39;Number of Pneumonia cases : {len(d_df)}&#39;) print(f&#39;Number of non-Pneumonia cases : {len(all_xray_df)-len(d_df)}&#39;) print(f&#39;Penumonia/Total : {round(len(d_df)*100/len(all_xray_df),2)}%&#39; ) . Number of Pneumonia cases : 1430 Number of non-Pneumonia cases : 110674 Penumonia/Total : 1.28% . Number of Images/Records per Patient (top 30) . # Distribution of images per patient analysis plt.figure(figsize=(10,6)) all_xray_df.groupby(by=&#39;Patient ID&#39;)[&#39;Image Index&#39;].count().nlargest(30).plot(kind=&#39;bar&#39;) plt.ylabel(&#39;Number of Records per Patient&#39;) plt.title(&#39;Top 30 Patients with Largest Number of Records Example&#39;) plt.show() . # Distribution of images per patient analysis all_xray_df.groupby(by=&#39;Patient ID&#39;)[&#39;Image Index&#39;].count().nsmallest(10) . Patient ID 2 1 4 1 6 1 7 1 9 1 10 1 12 1 14 1 15 1 16 1 Name: Image Index, dtype: int64 . Common diseases associated with Pneumonia . plt.figure(figsize=(12,6)) d_df[&#39;Finding Labels&#39;].value_counts()[0:30].plot(kind=&#39;bar&#39;) plt.show() . non_p_labels =[i for i in all_labels if i !=&#39;Pneumonia&#39;] plt.figure(figsize=(12,6)) ax = d_df[non_p_labels].sum().nlargest(14).plot(kind=&#39;barh&#39;) . d_df[non_p_labels].sum().nlargest(20) . Infiltration 605.0 Edema 340.0 Effusion 268.0 Atelectasis 262.0 Consolidation 123.0 Mass 71.0 Nodule 70.0 Pleural_Thickening 48.0 Pneumothorax 41.0 Cardiomegaly 41.0 Emphysema 23.0 Fibrosis 11.0 Hernia 3.0 No Finding 0.0 dtype: float64 . # total cases with Pneumonia and Other Conditions total_cases_with_Pneumonia = d_df[non_p_labels].sum().sum() total_cases_with_Pneumonia . 1906.0 . Number of Diseases per Patient (top 10) . diseases_per_patient = all_xray_df.groupby(by=&#39;Patient ID&#39;)[diagnostics].max().sum(axis=1) diseases_per_patient.nlargest(10) . Patient ID 12021 13.0 14022 13.0 16778 13.0 26451 13.0 1836 12.0 10092 12.0 12094 12.0 12834 12.0 13111 12.0 21201 12.0 dtype: float64 . Examine Images from data/images_001/images - Pick bottom 5 example . # 5 random images img_list = !ls /data/images_001/images |sort -R |tail -5 img_list . [&#39;00000632_000.png&#39;, &#39;00000499_000.png&#39;, &#39;00001294_000.png&#39;, &#39;00000491_022.png&#39;, &#39;00000627_018.png&#39;] . for img in img_list: imr = imread(f&#39;/data/images_001/images/{img}&#39;) imshow(imr, cmap=&#39;gray&#39;) plt.show() . sample_df for image analysis . sample_df.head() . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImageWidth OriginalImageHeight OriginalImagePixelSpacing_x OriginalImagePixelSpacing_y . 0 00000013_005.png | Emphysema|Infiltration|Pleural_Thickening|Pneu... | 5 | 13 | 060Y | M | AP | 3056 | 2544 | 0.139 | 0.139 | . 1 00000013_026.png | Cardiomegaly|Emphysema | 26 | 13 | 057Y | M | AP | 2500 | 2048 | 0.168 | 0.168 | . 2 00000017_001.png | No Finding | 1 | 17 | 077Y | M | AP | 2500 | 2048 | 0.168 | 0.168 | . 3 00000030_001.png | Atelectasis | 1 | 30 | 079Y | M | PA | 2992 | 2991 | 0.143 | 0.143 | . 4 00000032_001.png | Cardiomegaly|Edema|Effusion | 1 | 32 | 055Y | F | AP | 2500 | 2048 | 0.168 | 0.168 | . Examine DCOM files in the parent folder . dcoms = !ls | grep .dcm dcoms . [&#39;test1.dcm&#39;, &#39;test2.dcm&#39;, &#39;test3.dcm&#39;, &#39;test4.dcm&#39;, &#39;test5.dcm&#39;, &#39;test6.dcm&#39;] . View images and intensity distribution . for dcom in dcoms: fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2) dcm = pydicom.dcmread(dcom) img = (dcm.pixel_array - np.mean(dcm.pixel_array))/np.std(dcm.pixel_array) ax1.imshow(dcm.pixel_array,cmap=&#39;gray&#39;) ax2.hist(img.ravel(), bins = 256) plt.show() . Examin Images based on sample_df data set (labeled data) . # Add file path to images data_sample_path = {os.path.basename(x): x for x in glob(os.path.join(&#39;/data&#39;,&#39;images*&#39;,&#39;*&#39;,&#39;*.png&#39;))} sample_df[&#39;path&#39;] = sample_df[&#39;Image Index&#39;].map(data_sample_path.get) sample_df.head() . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImageWidth OriginalImageHeight OriginalImagePixelSpacing_x OriginalImagePixelSpacing_y path . 0 00000013_005.png | Emphysema|Infiltration|Pleural_Thickening|Pneu... | 5 | 13 | 060Y | M | AP | 3056 | 2544 | 0.139 | 0.139 | /data/images_001/images/00000013_005.png | . 1 00000013_026.png | Cardiomegaly|Emphysema | 26 | 13 | 057Y | M | AP | 2500 | 2048 | 0.168 | 0.168 | /data/images_001/images/00000013_026.png | . 2 00000017_001.png | No Finding | 1 | 17 | 077Y | M | AP | 2500 | 2048 | 0.168 | 0.168 | /data/images_001/images/00000017_001.png | . 3 00000030_001.png | Atelectasis | 1 | 30 | 079Y | M | PA | 2992 | 2991 | 0.143 | 0.143 | /data/images_001/images/00000030_001.png | . 4 00000032_001.png | Cardiomegaly|Edema|Effusion | 1 | 32 | 055Y | F | AP | 2500 | 2048 | 0.168 | 0.168 | /data/images_001/images/00000032_001.png | . # test imshow(sample_df[&#39;path&#39;][0]) . &lt;matplotlib.image.AxesImage at 0x7fb6d52aacd0&gt; . Data Transformation . Make simnilar transformation that we made for the all_xray_df | . sample_all_labels = list(set(list(chain.from_iterable([i.split(&#39;|&#39;) for i in sample_df[&#39;Finding Labels&#39;]])))) for c_label in sample_all_labels: sample_df[c_label] = sample_df[&#39;Finding Labels&#39;].map(lambda finding: 1.0 if c_label in finding else 0) sample_df.head() . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImageWidth OriginalImageHeight OriginalImagePixelSpacing_x ... Pneumothorax Hernia Atelectasis Emphysema Pneumonia Fibrosis Mass Consolidation Edema Cardiomegaly . 0 00000013_005.png | Emphysema|Infiltration|Pleural_Thickening|Pneu... | 5 | 13 | 060Y | M | AP | 3056 | 2544 | 0.139 | ... | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1 00000013_026.png | Cardiomegaly|Emphysema | 26 | 13 | 057Y | M | AP | 2500 | 2048 | 0.168 | ... | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | . 2 00000017_001.png | No Finding | 1 | 17 | 077Y | M | AP | 2500 | 2048 | 0.168 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 00000030_001.png | Atelectasis | 1 | 30 | 079Y | M | PA | 2992 | 2991 | 0.143 | ... | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 00000032_001.png | Cardiomegaly|Edema|Effusion | 1 | 32 | 055Y | F | AP | 2500 | 2048 | 0.168 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 1.0 | . 5 rows × 27 columns . # split data: Pneumonia Only sample_df_p = sample_df[sample_df[&#39;Pneumonia&#39;] == 1] # sample_df_p = sample_df[sample_df[&#39;Finding Labels&#39;] == &#39;Pneumonia&#39;] . Lets now look at only Pneumonia images and pixel distribution . # Only Pneumonia for d in sample_df_p.head(5)[&#39;path&#39;]: fig, (ax1, ax2) = plt.subplots(1, 2) img = io.imread(d) ax1.imshow(img, cmap=&#39;gray&#39;) img = (img-np.mean(img)) / np.std(img) ax2.hist(img.ravel(), bins = 256) plt.show() . Lets now look at No Findings images and pixel distribution . # Non Pneumonia sample_df_nop = sample_df[sample_df[&#39;No Finding&#39;] == 1] for d in sample_df_nop.head(5)[&#39;path&#39;]: fig, (ax1, ax2) = plt.subplots(1, 2) img = io.imread(d) ax1.imshow(img, cmap=&#39;gray&#39;) img = (img-np.mean(img)) / np.std(img) ax2.hist(img.ravel(), bins = 256) plt.show() . Pixel Intensity Distribution . Comparing Pneumonia with Non-Pneumonia (not normalized) . We will focus more on pixel distribution and not look at the X-ray images to get a larger view of the distribution | . # Same as above but more focused on intesnity distribution # Only Pneumonia for d in sample_df_p.head(5)[&#39;path&#39;]: plt.figure(figsize=(10,6)) img = io.imread(d) # img = (img-np.mean(img)) / np.std(img) # ax = plt.hist(img.ravel(), bins = 256) sns.distplot(img, bins=256, kde=True, rug=False) plt.title(f&#39;Pneumonia image {d}&#39;) plt.show() . # No Finding (Clear) for d in sample_df_nop.head(5)[&#39;path&#39;]: plt.figure(figsize=(10,6)) img = io.imread(d) # img = (img-np.mean(img)) / np.std(img) # ax = plt.hist(img.ravel(), bins = 256) sns.distplot(img, bins=256, kde=True, rug=False) plt.title(f&#39;Non-Pneumonia image {d}&#39;) plt.show() . From the Pixel Intesity Distribution charts above, the peak from values 0 to 40 represent black color, which is mainly the boundary/ackground color in the X-Rays. | Actual representation of the chest images, are more toward white/grayish color (lighter tones). | If we remove or ignore the values from 0-40 we will shift the focus on how the chest x-rays themeselves being represented. In other words, ignore the black boundaries/background color. | . Replotting above but this time ignoring black boundary . # Same as above but more focused on intesnity distribution # Only Pneumonia for d in sample_df_p.head(5)[&#39;path&#39;]: plt.figure(figsize=(10,6)) img = io.imread(d) img = img[img &gt; 40] # img = (img-np.mean(img)) / np.std(img) # ax = plt.hist(img.ravel(), bins = 256) sns.distplot(img, bins=256, kde=True, rug=False) plt.title(f&#39;Pneumonia image {d}&#39;) plt.show() . for d in sample_df_nop.head(5)[&#39;path&#39;]: plt.figure(figsize=(10,6)) img = io.imread(d) # img = (img-np.mean(img)) / np.std(img) # ax = plt.hist(img.ravel(), bins = 256) img = img[img &gt; 30] sns.distplot(img, bins=256, kde=True, rug=False) plt.title(f&#39;Non-Pneumonia image {d}&#39;) plt.show() . Pixel Intensity Distribution Analysis for Diseases . Now let&#39;s examine the similarity and differences between Pneumonia and other diseases | Will do this for 5 groups, picking one picture for each diseas as representation and then plot them. | . coll = [] for i in range(5): l = {} for label in all_labels: l[label] = sample_df[sample_df[label] == 1][&#39;path&#39;].iloc[i] coll.append(l) . coll[0] . {&#39;Infiltration&#39;: &#39;/data/images_001/images/00000013_005.png&#39;, &#39;Effusion&#39;: &#39;/data/images_001/images/00000032_001.png&#39;, &#39;No Finding&#39;: &#39;/data/images_001/images/00000017_001.png&#39;, &#39;Nodule&#39;: &#39;/data/images_001/images/00000061_025.png&#39;, &#39;Pleural_Thickening&#39;: &#39;/data/images_001/images/00000013_005.png&#39;, &#39;Pneumothorax&#39;: &#39;/data/images_001/images/00000013_005.png&#39;, &#39;Hernia&#39;: &#39;/data/images_004/images/00006624_002.png&#39;, &#39;Atelectasis&#39;: &#39;/data/images_001/images/00000030_001.png&#39;, &#39;Emphysema&#39;: &#39;/data/images_001/images/00000013_005.png&#39;, &#39;Pneumonia&#39;: &#39;/data/images_002/images/00001373_010.png&#39;, &#39;Fibrosis&#39;: &#39;/data/images_001/images/00000181_001.png&#39;, &#39;Mass&#39;: &#39;/data/images_001/images/00000040_003.png&#39;, &#39;Consolidation&#39;: &#39;/data/images_001/images/00000040_003.png&#39;, &#39;Edema&#39;: &#39;/data/images_001/images/00000032_001.png&#39;, &#39;Cardiomegaly&#39;: &#39;/data/images_001/images/00000013_026.png&#39;} . difference = {} fig, axes = plt.subplots(4, 4, figsize = (16, 16)) fig.suptitle(&#39;Distributions of Pixel Intensity&#39;) p = io.imread(coll[0][&#39;Pneumonia&#39;]) p = p[p &gt; 40] pneumonia = np.array(p.ravel()) for ax, label, path in zip(axes.flatten(), coll[0].keys(), coll[0].values()): img2 = io.imread(path) img2 = img2[img2 &gt; 40] img2 = img2.ravel() sns.distplot(img2, ax=ax, bins=256) # diff = abs(pneumonia_arr-np.array(img2)).sum() # difference[label] = diff # ax.set(title=f&#39;{label} - {diff}&#39;) if label == &#39;Pneumonia&#39;: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;, color=&quot;red&quot;) else: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;) . Examinig above, the closest three diseases in terms of shape, mean and std (spread), is Edeam, Mass and nodule | . # {k: v for k, v in sorted(difference.items(), key=lambda item: item[1])} . difference = {} fig, axes = plt.subplots(4, 4, figsize = (16, 16)) fig.suptitle(&#39;Distributions of Pixel Intensity&#39;) p = io.imread(coll[1][&#39;Pneumonia&#39;]) p = p[p &gt; 40] pneumonia = np.array(p.ravel()) for ax, label, path in zip(axes.flatten(), coll[1].keys(), coll[1].values()): img2 = io.imread(path) img2 = img2[img2 &gt; 40] img2 = img2.ravel() sns.distplot(img2, ax=ax, bins=256) # diff = abs(pneumonia_arr-np.array(img2)).sum() # difference[label] = diff # ax.set(title=f&#39;{label} - {diff}&#39;) if label == &#39;Pneumonia&#39;: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;, color=&quot;red&quot;) else: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;) . Examinig above, the closest three diseases in terms of shape, mean and std (spread), are Edema, Fibrosis and Infiltration | . # {k: v for k, v in sorted(difference.items(), key=lambda item: item[1])} . difference = {} fig, axes = plt.subplots(4, 4, figsize = (16, 16)) fig.suptitle(&#39;Distributions of Pixel Intensity&#39;) p = io.imread(coll[2][&#39;Pneumonia&#39;]) p = p[p &gt; 40] pneumonia = np.array(p.ravel()) for ax, label, path in zip(axes.flatten(), coll[2].keys(), coll[2].values()): img2 = io.imread(path) img2 = img2[img2 &gt; 40] img2 = img2.ravel() sns.distplot(img2, ax=ax, bins=256) # diff = abs(pneumonia_arr-np.array(img2)).sum() # difference[label] = diff # ax.set(title=f&#39;{label} - {diff}&#39;) if label == &#39;Pneumonia&#39;: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;, color=&quot;red&quot;) else: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;) . Examinig above, the closest three diseases in terms of shape, mean and std (spread), are Nodule, Mass and Infiltration | . # {k: v for k, v in sorted(difference.items(), key=lambda item: item[1])} . difference = {} fig, axes = plt.subplots(4, 4, figsize = (16, 16)) fig.suptitle(&#39;Distributions of Pixel Intensity&#39;) p = io.imread(coll[3][&#39;Pneumonia&#39;]) p = p[p &gt; 40] pneumonia = np.array(p.ravel()) for ax, label, path in zip(axes.flatten(), coll[3].keys(), coll[3].values()): img2 = io.imread(path) img2 = img2[img2 &gt; 40] img2 = img2.ravel() sns.distplot(img2, ax=ax, bins=256) # diff = abs(pneumonia_arr-np.array(img2)).sum() # difference[label] = diff # ax.set(title=f&#39;{label} - {diff}&#39;) if label == &#39;Pneumonia&#39;: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;, color=&quot;red&quot;) else: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;) . Examinig above, the closest two diseases in terms of shape, mean and std (spread), are Mass and Infiltration | . # {k: v for k, v in sorted(difference.items(), key=lambda item: item[1])} . difference = {} fig, axes = plt.subplots(4, 4, figsize = (16, 16)) fig.suptitle(&#39;Distributions of Pixel Intensity&#39;) pneumonia = io.imread(coll[0][&#39;Pneumonia&#39;]).ravel() p = io.imread(coll[4][&#39;Pneumonia&#39;]) p = p[p &gt; 40] pneumonia = np.array(p.ravel()) for ax, label, path in zip(axes.flatten(), coll[4].keys(), coll[4].values()): img2 = io.imread(path) img2 = img2[img2 &gt; 40] img2 = img2.ravel() sns.distplot(img2, ax=ax, bins=256) # diff = abs(np.array(pneumonia)-np.array(img2)).sum() # difference[label] = diff if label == &#39;Pneumonia&#39;: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;, color=&quot;red&quot;) else: ax.set_title(f&#39;{label} , m: {round(img2.mean(),2)} s: {round(img2.std(),2)}&#39;) . Examinig above, the closest two diseases in terms of shape, mean and std (spread), is Mass and Infiltration | .",
            "url": "http://tarekatwan.com/blog/jupyter/dicom/python/eda/2020/05/21/part-1-EDA-DICOM.html",
            "relUrl": "/jupyter/dicom/python/eda/2020/05/21/part-1-EDA-DICOM.html",
            "date": " • May 21, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "MicroStrategy API with R",
            "content": "MicroStrategy REST API with R . . MicroStrategy Reference Material: . MicroStrategy RESTful API Interactive (your Local Demo): http://yourmstrEnv.com/MicroStrategyLibrary/api-docs/ | MicroStrategy RESTful API Interactive (external demo) | MicroStrategy REST API Online Documentation | . Additional Resources/Inspirations: . MicroStrategy Sample API Python Example by Robert Prochowicz | Machine Learning with Python On-Demand Video with Scott Rigney | . R Library References: . httr | jsonlite | . List of Code Examples : . login() | sessionValidate() | userInfo() | listProjcets() | getLibrary() | searchObjects() | cubeObjects() | Logout User() | —- WIP to be added —– . Cube Instance | Get Cube Data | Create Cube | Write/publish a Cube | Import httr and jsonlite libraries . library(httr) library(jsonlite) . Set Parameters . Create the necessary varibales such as username, password, projectid and baseURL . username &lt;- &#39;Administrator&#39; password &lt;- &#39;&#39; baseURL &lt;- &quot;http://youMstrEnv/MicroStrategyLibrary/api/&quot; projectId &lt;- &#39;B19DEDCC11D4E0EFC000EB9495D0F44F&#39; . . Authentication: Returns authToken &amp; SessionId . Top . Implementation Notes (source: MicroStrategy Documentation): Authenticate a user and create an HTTP session on the web server where the user’s MicroStrategy sessions are stored. This request returns an authorization token (X-MSTR-AuthToken) which will be submitted with subsequent requests. The body of the request contains the information needed to create the session. The loginMode parameter in the body specifies the authentication mode to use. You can authenticate with one of the following authentication modes: Standard (1), Anonymous (8), or LDAP (16). Authentication modes can be enabled through the System Administration REST APIs, if they are supported by the deployment. If you are not able to authenticate using any of the authentication modes, please contact your administrator to determine current support or currently enabled authentication modes. . login &lt;- function(baseURL, username, password) { d &lt;- list(username = username, password = password, loginMode = &#39;1&#39;) r &lt;- POST(paste(base_url , &#39;auth/login&#39;, sep = &#39;&#39;), query = d) httpstats &lt;- http_status(r) httpheader &lt;- headers(r) httpcookies &lt;- cookies(r) if (http_status(r)$category == &#39;Success&#39;) { cat(&quot;Success&quot;) authToken &lt;- httpheader$&#39;x-mstr-authtoken&#39; sessionCoookies &lt;- httpcookies$value cat(&quot; nauthToken :&quot;, authToken) cat(&quot; nSessionCookie:&quot;, sessionCoookies) authList &lt;- list(&quot;authToken&quot;=authToken, &quot;sessionId&quot;=sessionCoookies) return(authList) } else { cat(httpstats$category, httpstats$reason, httpstats$message) } } . #return a list auth &lt;- login(baseURL, username, password) . Success authToken : k4vchhmjv7me39v9816gv3den2 SessionCookie: 18E1E53ADDBA549D077EACE563C208AB . . Test Session . Top . Implementation Notes (source: MicroStrategy Documentation): Get information about a configuration session. You obtain the authorization token needed to execute the request using POST /auth/login; you pass the authorization token in the request header. Each time you call this endpoint, both the HTTP and Intelligence Server session timeouts are reset. This request returns information about the authenticated user, locale, timeout duration, maximum number of concurrent searches, and limit on number of instances kept in memory. . sessionValidate &lt;- function(baseURL, auth){ r &lt;- GET(paste(base_url , &#39;sessions&#39;, sep = &#39;&#39;), add_headers(&#39;X-MSTR-AuthToken&#39;=auth$authToken, Accept = &#39;application/json&#39;, cookies=auth$sessionId)) httpstats &lt;- http_status(r) httpheader &lt;- headers(r) httpcookies &lt;- cookies(r) if (http_status(r)$category == &#39;Success&#39;) { print(toJSON(content(r))) } else { cat(httpstats$category, httpstats$reason, httpstats$message) } } . sessionValidate(baseURL, auth) . {&quot;locale&quot;:[1033],&quot;maxSearch&quot;:[3],&quot;workingSet&quot;:[10],&quot;timeout&quot;:[600],&quot;id&quot;:[&quot;54F3D26011D2896560009A8E67019608&quot;],&quot;fullName&quot;:[&quot;Administrator&quot;],&quot;initials&quot;:[&quot;A&quot;]} . . Get UserInfo . Top . userInfo &lt;- function(baseURL, auth){ r &lt;- GET(paste(baseURL , &#39;sessions/userInfo&#39;, sep = &#39;&#39;), add_headers(&#39;X-MSTR-AuthToken&#39;=auth$authToken, Accept = &#39;application/json&#39;, cookies=auth$sessionId)) httpstats &lt;- http_status(r) httpheader &lt;- headers(r) httpcookies &lt;- cookies(r) if (http_status(r)$category == &#39;Success&#39;) { a &lt;- data.frame(content(r)) return(a) } else { cat(httpstats$category, httpstats$reason, httpstats$message) } } . # Returns a data.frame object user &lt;- userInfo(baseURL, auth) user . metadataUseridfullNameinitials . TRUE | 54F3D26011D2896560009A8E67019608 | Administrator | A | . . Get Library for user . Top . Implementation Notes (source: MicroStrategy Documentation) Get the library for the authenticated user. You obtain the authorization token needed to execute the request using POST /auth/login; you pass the authorization token in the request header. . getLibrary &lt;- function(baseURL, auth, flag) { r &lt;- GET(paste(baseURL , &#39;library?outputFlag=&#39;, flag, sep = &#39;&#39;), add_headers(&#39;X-MSTR-AuthToken&#39;=auth$authToken, Accept = &#39;application/json&#39;, cookies=auth$sessionId)) httpstats &lt;- http_status(r) httpheader &lt;- headers(r) httpcookies &lt;- cookies(r) if (http_status(r)$category == &#39;Success&#39;) { a &lt;- fromJSON(toJSON(content(r)))[c(&#39;id&#39;, &#39;name&#39;, &#39;projectId&#39;, &#39;active&#39;,&#39;lastViewedTime&#39;)] if (flag == &#39;DEFAULT&#39;){ b &lt;- 0 for (i in fromJSON(toJSON(content(r)))[c(&#39;target&#39;)]){ b&lt;- (i[,&#39;id&#39;]) b &lt;- data.frame(matrix(b, byrow = T), stringsAsFactors=FALSE) colnames(b) &lt;- &quot;targetId&quot; } a$targetId &lt;- b$targetId } return(a) } else { cat(httpstats$category, httpstats$reason, httpstats$message) } } . # Return a data.frame object libraryInfo &lt;- getLibrary(baseURL, auth, &#39;DEFAULT&#39;) libraryInfo . idnameprojectIdactivelastViewedTimetargetId . 1B979449411E30E4E4502F918158EA40 | Category Analysis | B19DEDCC11D4E0EFC000EB9495D0F44F | TRUE | 2018-08-11T07:49:40.000+0000 | 512EDAA1487128DBBCA43E8525E10A11 | . 21A521BA4DB47ADAEBE19E9E9F7EC7D9 | Executive Business User Data Dossier | B19DEDCC11D4E0EFC000EB9495D0F44F | TRUE | 2018-08-10T19:36:00.000+0000 | FC6E8B6F4950540FC3595093E0FBA306 | . 80AFEAD447DE2430F7E41FBB1B1EFCBA | Category Breakdown Dossier | B19DEDCC11D4E0EFC000EB9495D0F44F | TRUE | 2018-08-10T21:36:32.000+0000 | 95005DFF4C4829CF5EE6E98877726566 | . . List of Projects . Top . Implementation Notes (Source: MicroStrategy Documentation) Get a list of projects which the authenticated user has access to. This returns the name, ID, description, alias, and status of each project; the status corresponds to values from EnumDSSXMLProjectStatus. You obtain the authorization token needed to execute the request using POST /auth/login; you pass the authorization token in the request header. . listProjects &lt;- function(baseURL, auth) { r &lt;- GET(paste(baseURL , &#39;projects&#39;, sep = &#39;&#39;), add_headers(&#39;X-MSTR-AuthToken&#39;=auth$authToken, Accept = &#39;application/json&#39;, cookies=auth$sessionId)) httpstats &lt;- http_status(r) httpheader &lt;- headers(r) httpcookies &lt;- cookies(r) if (http_status(r)$category == &#39;Success&#39;) { a &lt;- fromJSON(toJSON(content(r)))[c(&#39;id&#39;,&#39;name&#39;,&#39;description&#39;, &#39;status&#39;)] return(a) } else { cat(httpstats$category, httpstats$reason, httpstats$message) } } . # Return a data.frame object projectList &lt;- listProjects(baseURL, auth) projectList . idnamedescriptionstatus . B19DEDCC11D4E0EFC000EB9495D0F44F | MicroStrategy Tutorial | MicroStrategy Tutorial project and application set designed to illustrate the platform&#39;s rich functionality. The theme is an Electronics, Books, Movies and Music store. Employees, Inventory, Finance, Product Sales and Suppliers are analyzed. | 0 | . AF09B3E3458F78B4FBE4DEB68528BF7B | Human Resources Analysis Module | The Human Resources Analysis Module analyses workforce headcount, trends and profiles, employee attrition and recruitment, compensation and benefit costs and employee qualifications, performance and satisfaction. | 0 | . 4DD3B04B40D227471401609D630C76ED | Enterprise Manager | | 0 | . . Search Objects . Top . Implementation Notes (Source: MicroStrategy Documentation) Use the stored results of the Quick Search engine to return search results and display them as a list. The Quick Search engine periodically indexes the metadata and stores the results in memory, making Quick Search very fast but with results that may not be the most recent. You obtain the authorization token needed to execute the request using POST /auth/login. You identify the project by specifying the project ID in the request header; you obtain the project ID using GET /projects. You specify the search criteria using query parameters in the request; criteria can include the root folder ID, the search domain, the type of object, whether to return ancestors of the object, and a search pattern such as Begins With or Exactly. You use the offset and limit query parameters to control paging behavior. The offset parameter specifies where to start returning search results, and the limit parameter specifies how many results to return. . searchObjects &lt;- function(baseURL, auth, projectId, stype) { r &lt;- GET(paste(baseURL , &#39;searches/results?type=&#39;, stype, sep = &#39;&#39;), add_headers(&#39;X-MSTR-AuthToken&#39;=auth$authToken, &#39;X-MSTR-ProjectID&#39;=projectId, Accept = &#39;application/json&#39;, cookies=auth$sessionId)) httpstats &lt;- http_status(r) httpheader &lt;- headers(r) httpcookies &lt;- cookies(r) if (http_status(r)$category == &#39;Success&#39;) { tmp &lt;-content(r)$result df &lt;- as.data.frame(tmp[[1]]) for (i in 2:length(tmp)){ df &lt;- rbind(df, as.data.frame(tmp[[i]])) } return(df) } else { cat(httpstats$category, httpstats$reason, httpstats$message) } } . # Return a data.frame object mySearch &lt;- searchObjects(baseURL, auth, projectId, &#39;39&#39;) head(mySearch) . nameidtypesubtypeextTypedateCreateddateModifiedversionacgowner.nameowner.id . Search for all objects of type Grid | 87F09D2EBB9B462CAC4581ABCAD97BBD | 39 | 9984 | 0 | 2005-06-27T21:33:41.000+0000 | 2010-09-13T10:40:53.000+0000 | 08B3974B493CE1E84106EB825B71CB6A | 255 | Administrator | 54F3D26011D2896560009A8E67019608 | . Search for all objects of type Text Prompt | 8A7CAF697BB64191BA3E15FA10DEDA61 | 39 | 9984 | 0 | 2005-06-27T21:33:42.000+0000 | 2009-02-23T13:33:46.000+0000 | AC6316004E27925A85DDDF928D276A43 | 255 | Administrator | 54F3D26011D2896560009A8E67019608 | . MicroStrategy Web User Objects | 9F4A56074EDD734CBEFFC79A68BC36AF | 39 | 9984 | 0 | 2010-04-12T11:13:59.000+0000 | 2010-04-12T11:14:31.000+0000 | 5726EAF84C05E5B3854423A0E8BA1106 | 255 | Administrator | 54F3D26011D2896560009A8E67019608 | . Search for all objects of type Hierarchy | A1468ECD38754F90B56B611635AC550E | 39 | 9984 | 0 | 2005-06-27T21:33:39.000+0000 | 2009-02-23T13:33:43.000+0000 | 5E82734349853883096289A9CE83F9A2 | 255 | Administrator | 54F3D26011D2896560009A8E67019608 | . Search for all objects of type Column | 57048C8A11D437E2C000039187BD3A4F | 39 | 9984 | 0 | 2001-01-02T20:46:32.000+0000 | 2007-03-04T16:42:01.000+0000 | 9F27DD6B4FBED44E68CB869371E61BCA | 255 | Administrator | 54F3D26011D2896560009A8E67019608 | . Search for all objects of type Document | 57048CAE11D437E2C000039187BD3A4F | 39 | 9984 | 0 | 2001-01-02T20:46:30.000+0000 | 2008-01-21T16:10:31.000+0000 | 398B629141FCDB835E2CEA9D72D990B1 | 255 | Administrator | 54F3D26011D2896560009A8E67019608 | . . List Cube Objects . Top . (mplementation Notes (Source: MicroStrategy Documentation) Get the definition of a specific cube, including attributes and metrics. The cube can be either an Intelligent Cube or a Direct Data Access (DDA)/MDX cube. The in-memory cube definition provides information about all available objects without actually running any data query/report. The results can be used by other requests to help filter large datasets and retrieve values dynamically, helping with performance and scalability. You obtain the authorization token needed to execute the request using POST /auth/login; you pass the authorization token and the project ID in the request header. You specify the cube ID in the path of the request; this can be either an Intelligent cube ID or a DDA/MDX cube ID. . cubeObjects &lt;- function(baseURL, auth, projectId, cubeId){ r &lt;- GET(paste(baseURL , &#39;cubes/&#39;, cubeId, sep = &#39;&#39;), add_headers(&#39;X-MSTR-AuthToken&#39;=auth$authToken, &#39;X-MSTR-ProjectID&#39;=projectId, Accept = &#39;application/json&#39;, cookies=auth$sessionId)) httpstats &lt;- http_status(r) httpheader &lt;- headers(r) httpcookies &lt;- cookies(r) if (http_status(r)$category == &#39;Success&#39;) { tmp &lt;-content(r)$result mtrcs &lt;- tmp$definition$availableObjects$metrics attr &lt;- tmp$definition$availableObjects$attributes mna &lt;- rbind(do.call(&quot;rbind&quot;, attr)[, 1:3],do.call(&quot;rbind&quot;, mtrcs)) return(mna) } else { cat(httpstats$category, httpstats$reason, httpstats$message) } } . # Return a data.frame object cObjects &lt;- cubeObjects(baseURL, auth, projectId, &#39;BD23848347017FC2C0B4509AED1AF7B4&#39;) cObjects . nameidtype . Country | 8D679D3811D3E4981000E787EC6DE8A4 | Attribute | . Catalog | 8D679D3611D3E4981000E787EC6DE8A4 | Attribute | . Category | 8D679D3711D3E4981000E787EC6DE8A4 | Attribute | . Subcategory | 8D679D4F11D3E4981000E787EC6DE8A4 | Attribute | . Cost | 7FD5B69611D5AC76C000D98A4CC5F24F | Metric | . Gross Revenue | 150349F04560BBA2592D019726DF77DD | Metric | . Units Sold | 4C05190A11D3E877C000B3B2D86C964F | Metric | . . Log Out and end session . Top . logout &lt;- function(baseURL, auth){ r &lt;- GET(paste(base_url , &#39;auth/logout&#39;, sep = &#39;&#39;), add_headers(&#39;X-MSTR-AuthToken&#39;=auth$authToken, Accept = &#39;application/json&#39;, cookies=auth$sessionId)) httpstats &lt;- http_status(r) httpheader &lt;- headers(r) httpcookies &lt;- cookies(r) if (http_status(r)$category == &#39;Success&#39;) { print(&quot;Logged Out&quot;) } else { print(httpstats$category, httpstats$reason, httpstats$message) } } . logout(baseURL, auth) . [1] &quot;Logged Out&quot; .",
            "url": "http://tarekatwan.com/blog/python/microstrategy/api/2018/08/10/MicroStrategy-API-R.html",
            "relUrl": "/python/microstrategy/api/2018/08/10/MicroStrategy-API-R.html",
            "date": " • Aug 10, 2018"
        }
        
    
  
    
        ,"post4": {
            "title": "MicroStrategy API with Python",
            "content": "MicroStrategy-Python-REST-API . . MicroStrategy Reference Material: . MicroStrategy RESTful API Interactive (your Local Demo): http://yourmstrEnv.com/MicroStrategyLibrary/api-docs/ | MicroStrategy RESTful API Interactive (external demo) | MicroStrategy REST API Online Documentation | . Additional Resources/Inspirations: . MicroStrategy Sample API Python Example by Robert Prochowicz | Machine Learning with Python On-Demand Video with Scott Rigney | . Python Library References: . Python Requests | Python JSON | Python Pandas | . List of Code Examples : . login() . authToken, cookies = login(baseURL,username,password) . | sessionValidate() . sessionValiade(baseURL, authToken, cookies) . | userInfo() . user = userInfo(baseURL, authToken, cookies) . | listProjcets() . projectList = listProjects(baseURL, authToken, cookies) . | getLibrary() . libraryInfo = getLibrary(baseURL, authToken, cookies, &#39;FILTER_TOC&#39;) . | searchObjects() . mySearch = searchObjects(baseURL, authToken, &#39;39&#39;) . | cubeObjects() . cObjects = cubeObjects(baseURL, authToken, projectId, cookies, &#39;BD23848347017FC2C0B4509AED1AF7B4&#39;) . | Logout User() . | logout(baseURL, authToken) . ** Work In Progress ** . Cube Instance | Get Cube Data | Create Cube | Write/publish a Cube | More ….. | Import Python Libraries . import requests import json from pandas.io.json import json_normalize import pandas as pd import numpy as np . Set Parameters . Create the necessary varibales such as username, password, projectid and baseURL . ### Parameters ### username = &#39;Administrator&#39; password = &#39;&#39; iserver = &#39;10.254.113.99&#39; projectId = &#39;B19DEDCC11D4E0EFC000EB9495D0F44F&#39; projectName = &#39;MicroStrategy Tutorial&#39; baseURL = &quot;http://yourmstrEnv.com/MicroStrategyLibrary/api/&quot; #replace with your own URL for MicroStrategy Library API . . Authentication: Returns authToken &amp; SessionId . Top . Implementation Notes (source: MicroStrategy Documentation): Authenticate a user and create an HTTP session on the web server where the user’s MicroStrategy sessions are stored. This request returns an authorization token (X-MSTR-AuthToken) which will be submitted with subsequent requests. The body of the request contains the information needed to create the session. The loginMode parameter in the body specifies the authentication mode to use. You can authenticate with one of the following authentication modes: Standard (1), Anonymous (8), or LDAP (16). Authentication modes can be enabled through the System Administration REST APIs, if they are supported by the deployment. If you are not able to authenticate using any of the authentication modes, please contact your administrator to determine current support or currently enabled authentication modes. . def login(baseURL,username,password): &quot;&quot;&quot; Authenticate a user and create an HTTP session on the web server. Parameters: -- baseURL, username, password Returns: -- authToken and sessionId. Example: -- authToken, cookies = login(baseURL, username, password) &quot;&quot;&quot; header = {&#39;username&#39;: username, &#39;password&#39;: password, &#39;loginMode&#39;: 1} r = requests.post(baseURL + &#39;auth/login&#39;, data=header) if r.ok: authToken = r.headers[&#39;X-MSTR-AuthToken&#39;] cookies = dict(r.cookies) print(&quot;Token: &quot; + authToken) print(&quot;Session ID: {}&quot;.format(cookies)) return authToken, cookies else: print(&quot;HTTP {} - {}, Message {}&quot;.format(r.status_code, r.reason, r.text)) return [] . authToken, cookies = login(baseURL,username,password) . &gt;&gt; output Token: 5q4mb2nlcpk434ol4ors52sb5h Session ID: {&#39;JSESSIONID&#39;: &#39;3F23A282B4A7FAE9BB4E99C50EDA4321&#39;} . . Test Session . Top . Implementation Notes (source: MicroStrategy Documentation): Get information about a configuration session. You obtain the authorization token needed to execute the request using POST /auth/login; you pass the authorization token in the request header. Each time you call this endpoint, both the HTTP and Intelligence Server session timeouts are reset. This request returns information about the authenticated user, locale, timeout duration, maximum number of concurrent searches, and limit on number of instances kept in memory. . def sessionValiade(baseURL, authToken, cookies): &quot;&quot;&quot; Get information about a configuration session Parameters: - baseURL, authToken, cookies Returns: - None Example: -- sessionValiade(baseURL, authToken, cookies) &quot;&quot;&quot; print(&quot;Checking session...&quot;) header = {&#39;X-MSTR-AuthToken&#39;: authToken, &#39;Accept&#39;: &#39;application/json&#39;} r = requests.get(baseURL + &quot;sessions&quot;, headers=header, cookies=cookies) if r.ok: print(r.text) else: print(&quot;HTTP {} - {}, Message {}&quot;.format(r.status_code, r.reason, r.text)) return [] . sessionValiade(baseURL, authToken, cookies) . &gt;&gt; output Checking session... {&quot;locale&quot;:1033,&quot;maxSearch&quot;:3,&quot;workingSet&quot;:10,&quot;timeout&quot;:600,&quot;id&quot;:&quot;54F3D26011D2896560009A8E67019608&quot;,&quot;fullName&quot;:&quot;Administrator&quot;,&quot;initials&quot;:&quot;A&quot;} . . Get UserInfo . Top . def userInfo(baseURL, authToken, cookies): &quot;&quot;&quot; Returns: -- Pandas DataFrame id, fullName, initials Example: -- user = userInfo(baseURL, authToken, cookies) &quot;&quot;&quot; header = {&#39;X-MSTR-AuthToken&#39;: authToken, &#39;Accept&#39;: &#39;application/json&#39;} r = requests.get(baseURL + &quot;sessions/userInfo&quot;, headers=header, cookies=cookies) if r.ok: return json_normalize(json.loads(r.text)) else: print(&quot;HTTP {} - {}, Message {}&quot;.format(r.status_code, r.reason, r.text)) return [] . user = userInfo(baseURL, authToken, cookies) . &gt;&gt; output .   fullName id initials metadataUser . 0 | Administrator | 54F3D26011D2896560009A8E67019608 | A | True | . . Get Library for user . Top . Implementation Notes (source: MicroStrategy Documentation) Get the library for the authenticated user. You obtain the authorization token needed to execute the request using POST /auth/login; you pass the authorization token in the request header. . &quot;&quot;&quot; Get library for authenticated user. Parameteres: baseURL, authToken, cookies, flag. flag: &#39;DEFAULT&#39; or&#39;FILTER_TOC&#39; Returns: -- Pandas DataFrame (pandas.core.frame.DataFrame) id, name, description, projectId, active, lastViewedTime Example: -- getLibrary(baseURL, authToken, cookies, &#39;DEFAULT&#39;) &quot;&quot;&quot; header = {&#39;X-MSTR-AuthToken&#39;: authToken, &#39;Accept&#39;: &#39;application/json&#39;} r = requests.get(baseURL + &quot;library?outputFlag=&quot;+ flag, headers=header, cookies=cookies) if r.ok: a = pd.DataFrame(json.loads(r.text))[[&#39;id&#39;, &#39;name&#39;, &#39;projectId&#39;, &#39;active&#39;,&#39;lastViewedTime&#39;]] tmp = [] if (flag == &#39;DEFAULT&#39;): for i in json.loads(r.text): tmp.append(i[&#39;target&#39;][&#39;id&#39;]) a[&#39;target&#39;] = pd.DataFrame(tmp).astype(str) return a else: print(&quot;HTTP {} - {}, Message {}&quot;.format(r.status_code, r.reason, r.text)) return [] . libraryInfo = getLibrary(baseURL, authToken, cookies, &#39;FILTER_TOC&#39;) . &gt;&gt; output .   id name projectId active lastViewedTime . 0 | 21A521BA4DB47ADAEBE19E9E9F7EC7D9 | Executive Business User Data Dossier | B19DEDCC11D4E0EFC000EB9495D0F44F | True | 2018-08-08T16:57:48.000+0000 | . 1 | 21A521BA4DB47ADAEBE19E9E9F7EC7D9 | Category Breakdown Dossier | B19DEDCC11D4E0EFC000EB9495D0F44F | True | 2018-08-08T16:59:08.000+0000 | . . List of Projects . Top . Implementation Notes (Source: MicroStrategy Documentation) Get a list of projects which the authenticated user has access to. This returns the name, ID, description, alias, and status of each project; the status corresponds to values from EnumDSSXMLProjectStatus. You obtain the authorization token needed to execute the request using POST /auth/login; you pass the authorization token in the request header. . def listProjects(baseURL, authToken, cookies): &quot;&quot;&quot; Get a list of projects that can be accessed by the authenticated user Parameters: - baseURL, authToken, cookies Returns: - Pandas DataFrame Project Id, Name, Description and Status code Example: -- sessionValiade(baseURL, authToken, cookies) &quot;&quot;&quot; header = {&#39;X-MSTR-AuthToken&#39;: authToken, &#39;Accept&#39;: &#39;application/json&#39;} r = requests.get(baseURL + &#39;projects&#39;, headers=header, cookies=cookies) if r.ok: return pd.DataFrame(json.loads(r.text))[[&#39;id&#39;,&#39;name&#39;,&#39;description&#39;, &#39;status&#39;]] else: print(&quot;HTTP {} - {}, Message {}&quot;.format(r.status_code, r.reason, r.text)) return [] . projectList = listProjects(baseURL, authToken, cookies) . &gt;&gt; output .   id name description status . 0 | B19DEDCC11D4E0EFC000EB9495D0F44F | MicroStrategy Tutorial | MicroStrategy Tutorial project and application… | 0 | . 1 | AF09B3E3458F78B4FBE4DEB68528BF7B | Human Resources Analysis Module | The Human Resources Analysis Module analyses w… | 0 | . 2 | 4DD3B04B40D227471401609D630C76ED | Enterprise Manager |   | 0 | . . Search Objects . Top . Implementation Notes (Source: MicroStrategy Documentation) Use the stored results of the Quick Search engine to return search results and display them as a list. The Quick Search engine periodically indexes the metadata and stores the results in memory, making Quick Search very fast but with results that may not be the most recent. You obtain the authorization token needed to execute the request using POST /auth/login. You identify the project by specifying the project ID in the request header; you obtain the project ID using GET /projects. You specify the search criteria using query parameters in the request; criteria can include the root folder ID, the search domain, the type of object, whether to return ancestors of the object, and a search pattern such as Begins With or Exactly. You use the offset and limit query parameters to control paging behavior. The offset parameter specifies where to start returning search results, and the limit parameter specifies how many results to return. . def searchObjects(baseURL, authToken, stype): &quot;&quot;&quot; Search for meteadata Objects using EnumDSSObjectType. Parameters: -- baseURL, authToken, stype stype is based on EnumDSSObjectType values for example Folder is 8, Search is 39, Metric is 4 and Attribute is 12 for a lsit of EnumDSSObjectType values reference https://community.microstrategy.com/s/article/KB16048-List-of-all-object-types-and-object-descriptions-in Return: - Pandas DataFrame which contains object ID, name, type, owner and additional details Example: -- searchObjects(baseURL, authToken, &#39;8&#39;) &quot;&quot;&quot; header = {&#39;X-MSTR-AuthToken&#39;: authToken, &#39;X-MSTR-ProjectID&#39;: projectId, &#39;Accept&#39;: &#39;application/json&#39;} r = requests.get(baseURL + &#39;searches/results?type=&#39;+ stype, headers=header, cookies=cookies) if r.ok: return pd.DataFrame(json.loads(r.text)[&#39;result&#39;]) else: print(&quot;HTTP {} - {}, Message {}&quot;.format(r.status_code, r.reason, r.text)) return [] . mySearch = searchObjects(baseURL, authToken, &#39;39&#39;) . &gt;&gt; output .   acg dateCreated dateModified extType id name owner subtype type version . 0 | 255 | 2005-06-27T21:33:41.000+0000 | 2010-09-13T10:40:53.000+0000 | 0 | 87F09D2EBB9B462CAC4581ABCAD97BBD | Search for all objects of type Grid | {‘name’: ‘Administrator’, ‘id’: ‘54F3D26011D28… | 9984 | 39 | 08B3974B493CE1E84106EB825B71CB6A | . 1 | 255 | 2005-06-27T21:33:42.000+0000 | 2005-06-27T21:33:42.000+0000 | 0 | 8A7CAF697BB64191BA3E15FA10DEDA61 | Search for all objects of type Text Prompt | {‘name’: ‘Administrator’, ‘id’: ‘54F3D26011D28… | 9984 | 39 | AC6316004E27925A85DDDF928D276A43 | . 2 | 255 | 2010-04-12T11:13:59.000+0000 | 2010-04-12T11:13:59.000+0000 | 0 | 9F4A56074EDD734CBEFFC79A68BC36AF | MicroStrategy Web User Objects | {‘name’: ‘Administrator’, ‘id’: ‘54F3D26011D28… | 9984 | 39 | 5726EAF84C05E5B3854423A0E8BA1106 | . . List Cube Objects . Top . (mplementation Notes (Source: MicroStrategy Documentation) Get the definition of a specific cube, including attributes and metrics. The cube can be either an Intelligent Cube or a Direct Data Access (DDA)/MDX cube. The in-memory cube definition provides information about all available objects without actually running any data query/report. The results can be used by other requests to help filter large datasets and retrieve values dynamically, helping with performance and scalability. You obtain the authorization token needed to execute the request using POST /auth/login; you pass the authorization token and the project ID in the request header. You specify the cube ID in the path of the request; this can be either an Intelligent cube ID or a DDA/MDX cube ID. . def cubeObjects(baseURL, authToken, projectId, cookies, cubeId): &quot;&quot;&quot; Get definition of a specific cube with cubeId Parameters: -- baseURL, authToken, projectId, cookies, cubeId Return: - Pandas DataFrame which contains object ID, Object Name and Type (Attribute or Metrics) Example: -- cubeObjects(baseURL, authToken, projectId, cookies, &#39;BD23848347017FC2C0B4509AED1AF7B4&#39;) &quot;&quot;&quot; header = {&#39;X-MSTR-AuthToken&#39;: authToken, &#39;X-MSTR-ProjectID&#39;: projectId, &#39;Accept&#39;: &#39;application/json&#39;} r = requests.get(baseURL + &#39;cubes/&#39; + cubeId, headers=header, cookies=cookies) if r.ok: node = r.json() attr = pd.DataFrame(node[&#39;result&#39;][&#39;definition&#39;][&#39;availableObjects&#39;][&#39;attributes&#39;])[[&#39;id&#39;, &#39;name&#39;, &#39;type&#39;]] mtrcs = pd.DataFrame(node[&#39;result&#39;][&#39;definition&#39;][&#39;availableObjects&#39;][&#39;metrics&#39;])[[&#39;id&#39;, &#39;name&#39;, &#39;type&#39;]] return pd.concat([attr, mtrcs]) else: print(&quot;HTTP {} - {}, Message {}&quot;.format(r.status_code, r.reason, r.text)) return [] . cObjects = cubeObjects(baseURL, authToken, projectId, cookies, &#39;BD23848347017FC2C0B4509AED1AF7B4&#39;) . &gt;&gt; output .   id name type . 0 | 8D679D3811D3E4981000E787EC6DE8A4 | Country | Attribute | . 1 | 8D679D3611D3E4981000E787EC6DE8A4 | Catalog | Attribute | . 2 | 8D679D3711D3E4981000E787EC6DE8A4 | Gross Revenue | Metric | . . Log Out and end session . Top . def logout(baseURL,authToken): header = {&#39;X-MSTR-AuthToken&#39;: authToken, &#39;Accept&#39;: &#39;application/json&#39;} r = requests.post(baseURL + &#39;auth/logout&#39;,headers=header, cookies=cookies) if r.ok: print(&quot;Logged Out&quot;) else: print(&quot;HTTP {} - {}, Message {}&quot;.format(r.status_code, r.reason, r.text)) . logout(baseURL, authToken) . &gt;&gt; output Logged Out .",
            "url": "http://tarekatwan.com/blog/python/microstrategy/api/2018/08/10/MicroStrategy-API-Python.html",
            "relUrl": "/python/microstrategy/api/2018/08/10/MicroStrategy-API-Python.html",
            "date": " • Aug 10, 2018"
        }
        
    
  
    
        ,"post5": {
            "title": "Linear Separability",
            "content": "Linear vs Non-Linear Classification . Two subsets are said to be linearly separable if there exists a hyperplane that separates the elements of each set in a way that all elements of one set resides on the opposite side of the hyperplane from the other set. In 2D plotting, we can depict this through a separation line, and in 3D plotting through a hyperplane. . By definition Linear Separability is defined: . Two sets $H = { H^1, cdots,H^h } subseteq mathbb{R}^d$ and $M = { M^1, cdots,M^m } subseteq mathbb{R}^d$ are said to be linearly separable if $ exists a in mathbb{R}^n$, $b in mathbb{R} : H subseteq { x in mathbb{R}^n : a^T x &gt; b }$ and $M subseteq { x in mathbb{R}^n : a^Tx leq b }$ 1 . In simple words, the expression above states that H and M are linearly separable if there exists a hyperplane that completely separates the elements of [latex]H [/latex] and elements of $M$. . Image source from Sebastian Raschka 1 . In the figure above, (A) shows a linear classification problem and (B) shows a non-linear classification problem. In (A) our decision boundary is a linear one that completely separates the blue dots from the green dots. In this scenario several linear classifiers can be implemented. . In (B) our decision boundary is non-linear and we would be using non-linear kernel functions and other non-linear classification algorithms and techniques. . Generally speaking, in Machine Learning and before running any type of classifier, it is important to understand the data we are dealing with to determine which algorithm to start with, and which parameters we need to adjust that are suitable for the task. This brings us to the topic of linear separability and understanding if our problem is linear or non-linear. . As states above, there are several classification algorithms that are designed to separate the data by constructing a linear decision boundary (hyperplane) to divide the classes and with that comes the assumption: that the data is linearly separable. Now, in real world scenarios things are not that easy and data in many cases may not be linearly separable and thus non-linear techniques are applied. Without digging too deep, the decision of linear vs non-linear techniques is a decision the data scientist need to make based on what they know in terms of the end goal, what they are willing to accept in terms of error, the balance between model complexity and generalization, bias-variance tradeoff ..etc. . This post was inspired by research papers on the topic of linear separability including The Linear Separability Problem: Some Testing Method 2, 3 . My goal in this post is to apply and test few techniques in python and demonstrate how they can be implemented. Some of those techniques for testing linear separability are: . Domain Knowledge and Expertise | Data Visualization | Computational Geometry (Convex Hulls) | Linear Programming | Machine Learning: * Perceptron * Support Vector Machine | . Domain Knowledge/Expertise . It should be a no-brainer that the first step should always be to seek insight from analysts and other data scientists who are already dealing with the data and familiar with it. It is critical before embarking on any data discovery journey to always start by asking questions to better understand the purpose of the task (your goal) and gain early insight into the data from the domain experts (business data users , data/business analysts or data scientists) that are closer to the data and deal with it daily. . Getting our data . For the other four (4) approaches listed above, we will explore these concepts using the classic Iris data set and implement some of the theories behind testing for linear separability using Python. . Since this is a well known data set we know in advance which classes are linearly separable (domain knowledge/past experiences coming into play here).For our analysis we will use this knowledge to confirm our findings. . The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. . Let’s get things ready first by importing the necessary libraries and loading our data. . import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn import datasets data = datasets.load_iris() #create a DataFrame df = pd.DataFrame(data.data, columns=data.feature_names) df[&#39;Target&#39;] = pd.DataFrame(data.target) df.head() .   sepal Length (cm) sepal width (cm) petal length (cm) petal width (cm) Target . 0 | 5.1 | 3.5 | 1.4 | 0.2 | 0 | . 1 | 4.9 | 3.0 | 1.4 | 0.2 | 0 | . 2 | 4.7 | 3.2 | 1.3 | 0.2 | 0 | . 3 | 4.6 | 3.1 | 1.5 | 0.2 | 0 | . 4 | 5.0 | 3.6 | 1.4 | 0.2 | 0 | . Data Visiualization . The simplest and quickest method is to visualize the data. This approach may not be feasible or as straight forward if the number of features is large, making it hard to plot in 2D . In such a case, we can use a Pair Plot approach, and pandas gives us a great option to do so with scatter_matrix: . from pandas.tools.plotting import scatter_matrix scatter_matrix(df.iloc[:,0:4], figsize=(15,11)) . . The scatter matrix above is a pair-wise scatter plot for all features in the data set (we have four features so we get a 4x4 matrix). The scatter matrix provides insight into how these variables are correlated. Let’s expand upon this by creating a scatter plot for the Petal Length vs Petal Width from the scatter matrix. . plt.clf() plt.figure(figsize=(10,6)) plt.scatter(df.iloc[:,2], df.iloc[:,3]) plt.title(&#39;Petal Width vs Petal Length&#39;) plt.xlabel(data.feature_names[2]) plt.ylabel(data.feature_names[3]) plt.show() . . It’s still not that helpful. Let’s color each class and add a legend so we can understand what the plot is trying to convey in terms of data distribution per class and determine if the classes can be linearly separable visually. . Let’s update our code: . plt.clf() plt.figure(figsize = (10, 6)) names = data.target_names colors = [&#39;b&#39;,&#39;r&#39;,&#39;g&#39;] label = (data.target).astype(np.int) plt.title(&#39;Petal Width vs Petal Length&#39;) plt.xlabel(data.feature_names[2]) plt.ylabel(data.feature_names[3]) for i in range(len(names)): bucket = df[df[&#39;Target&#39;] == i] bucket = bucket.iloc[:,[2,3]].values plt.scatter(bucket[:, 0], bucket[:, 1], label=names[i]) plt.legend() plt.show() . . Much better. We just plotted the entire data set, all 150 points. There are 50 data points per class. And Yes, at first glance we can see that the blue dots (Setosa class) can be easily separated by drawing a line and segregate it from the rest of the classes. But what about the other two classes? . Let’s examine another approach to be more certain. . Computational Geometry . In this approach we will use a Convex Hull to check whether a particular class is linearly separable or not from the rest. In simplest terms, the convex hull represents the outer boundaries of a group of data points (classes) which is why sometimes it’s called the convex envelope. . The logic when using convex hulls when testing for linear separability is pretty straight forward which can be stated as: . Two classes X and Y are LS (Linearly Separable) if the intersection of the convex hulls of X and Y is empty, and NLS (Not Linearly Separable) with a non-empty intersection. . A quick way to see how this works is to visualize the data points with the convex hulls for each class. We will plot the hull boundaries to examine the intersections visually. We will be using the Scipy library to help us compute the convex hull. For more information please refer to Scipy documentation. . Let’s update the previous code to include convex hulls. . from scipy.spatial import ConvexHull plt.clf() plt.figure(figsize = (10, 6)) names = data.target_names label = (data.target).astype(np.int) colors = [&#39;b&#39;,&#39;r&#39;,&#39;g&#39;] plt.title(&#39;Petal Width vs Petal Length&#39;) plt.xlabel(data.feature_names[2]) plt.ylabel(data.feature_names[3]) for i in range(len(names)): bucket = df[df[&#39;Target&#39;] == i] bucket = bucket.iloc[:,[2,3]].values hull = ConvexHull(bucket) plt.scatter(bucket[:, 0], bucket[:, 1], label=names[i]) for j in hull.simplices: plt.plot(bucket[j,0], bucket[j,1], colors[i]) plt.legend() plt.show() . And our output should look like this: . . It is more obvious now, visually at least, that Setosa is a linearly separable class form the other two. In other words, we can easily draw a straight line to separate Setosa from non-Setosa (Setosas vs. everything else). Both Versicolor and Virginica classes are not linearly separable because we can see there is indeed an intersection. . Linear Programming . By definition Linear Separability is defined: . Two sets $H = { H^1, cdots,H^h } subseteq mathbb{R}^d$ and $M = { M^1, cdots,M^m } subseteq mathbb{R}^d$ are said to be linearly separable if $ exists a in mathbb{R}^n$, $b in mathbb{R} : H subseteq { x in mathbb{R}^n : a^T x gt; b }$ and $M subseteq { x in mathbb{R}^n : a^Tx leq b }$ 3 . In simple words, the expression above states that H and M are linearly separable if there exists a hyperplane that completely separates the elements of $H$ and elements of $M$. . $H$ and $M$ are linearly separable if the optimal value of Linear Program $(LP)$ is $0$ . Here is a great post that implements this in R which I followed as an inspiration for this section on linear programming with python: Testing for Linear Separability with LP in R 4. . Below is the code in python using scipy linprog(method=&#39;simplex&#39;) to solve our linear programming problem. If we examine the output, using LP (Linear Programming) method we can conclude that it is possible to have a hyperplane that linearly separates Setosa from the rest of the classes, which is the only linearly separable class from the rest. . If the problem is solvable, the Scipy output will provide us with additional information: . Returns   . success: bool | True or False (True if a solution was found) | . status: int | 0 : Optimization terminated successfully, 1 : Iteration limit reached, 2 : Problem appears to be infeasible, 3 : Problem appears to be unbounded | . message : str | Describing the status | . x: ndarray | The independent variable vector which optimizes the linear programming problem. | . slack: ndarray | The values of the slack variables. Each slack variable corresponds to an inequality constraint. If the slack is zero, then the corresponding constraint is active. | . nit : int | The number of iterations performed. | . fun : float | Value of the objective function | . For our example, I am only looking at the status/success to determine if a solution was found or not. . from scipy.optimize import linprog dic = {0: &#39;setosa&#39;, 1: &#39;versicolor&#39;, 2: &#39;verginica&#39;} for i in dic.keys(): df[&quot;newTarget&quot;] = np.where(df[&#39;Target&#39;] == i, 1 , -1) from sklearn.preprocessing import StandardScaler sc = StandardScaler() tmp = df.iloc[:,[2,3]].values tmp = sc.fit_transform(tmp) xx = np.array(df.newTarget.values.reshape(-1,1) * tmp) t = np.where(df[&#39;Target&#39;] == i, 1 , -1) #2-D array which, when matrix-multiplied by x, gives the values of #the upper-bound inequality constraints at x. A_ub = np.append(xx, t.reshape(-1,1), 1) #1-D array of values representing the upper-bound of each #inequality constraint (row) in A_ub. b_ub = np.repeat(-1, A_ub.shape[0]).reshape(-1,1) # Coefficients of the linear objective function to be minimized. c_obj = np.repeat(1, A_ub.shape[1]) res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, options={&quot;disp&quot;: False}) if res.success: print(&#39;There is linear separability between {} and the rest&#39;.format(dic[i])) else: print(&#39;No linear separability between {} and the rest&#39;.format(dic[i])) . &gt;&gt;&gt;output There is linear separability between setosa and the rest No linear separability between versicolor and the rest No linear separability between verginica and the rest . Machine Learning . In this section we will examine two classifiers for the purpose of testing for linear separability: the Perceptron (simplest form of Neural Networks) and Support Vector Machines (part of a class known as Kernel Methods) . Single Layer Perceptron . The perceptron is an algorithm used for binary classification and belongs to a class of linear classifiers. In binary classification, we are trying to separate data into two buckets: either you are in Buket A or Bucket B. This can be stated even simpler: either you are in Bucket A or not in Bucket A (assuming we have only two classes) and hence the name binary classification. {1if w . x + b&gt;00otherwise large begin{cases} displaystyle 1 &amp; text {if w . x + b} &gt; {0} 0 &amp; text {otherwise} end{cases}⎩⎪⎨⎪⎧​10​if w . x + b&gt;0otherwise​ . A single layer perceptron will only converge if the input vectors are linearly separable. In this state, all input vectors would be classified correctly indicating linear separability. It will not converge if they are not linearly separable. In other words, it will not classify correctly if the data set is not linearly separable. For our testing purpose, this is exactly what we need. . We will apply it on the entire data instead of splitting to test/train since our intent is to test for linear separability among the classes and not to build a model for future predictions. . We will use Scikit-Learn and pick the Perceptron as our linear model selection. Before that, let’s do some basic data preprocessing tasks: . # Data Preprocessing x = df.iloc[:, [2,3]].values # we are picking Setosa to be 1 and all other classes will be 0 y = (data.target == 0).astype(np.int) #Perform feature scaling from sklearn.preprocessing import StandardScaler sc= StandardScaler() x = sc.fit_transform(x) . Now, let’s build our classifier: . from sklearn.linear_model import Perceptron perceptron = Perceptron(random_state = 0) perceptron.fit(x, y) predicted = perceptron.predict(x) . To get a better intuition on the results we will plot the confusion matrix and decision boundary. . from sklearn.metrics import confusion_matrix cm = confusion_matrix(y, predicted) plt.clf() plt.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Wistia) classNames = [&#39;Negative&#39;,&#39;Positive&#39;] plt.title(&#39;Perceptron Confusion Matrix - Entire Data&#39;) plt.ylabel(&#39;True label&#39;) plt.xlabel(&#39;Predicted label&#39;) tick_marks = np.arange(len(classNames)) plt.xticks(tick_marks, classNames, rotation=45) plt.yticks(tick_marks, classNames) s = [[&#39;TN&#39;,&#39;FP&#39;], [&#39;FN&#39;, &#39;TP&#39;]] for i in range(2): for j in range(2): plt.text(j,i, str(s[i][j])+&quot; = &quot;+str(cm[i][j])) plt.show() . . Now, let’s draw our decision boundary: . from matplotlib.colors import ListedColormap plt.clf() X_set, y_set = x, y X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01)) plt.contourf(X1, X2, perceptron.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap((&#39;navajowhite&#39;, &#39;darkkhaki&#39;))) plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap((&#39;red&#39;, &#39;green&#39;))(i), label = j) plt.title(&#39;Perceptron Classifier (Decision boundary for Setosa vs the rest)&#39;) plt.xlabel(&#39;Petal Length&#39;) plt.ylabel(&#39;Petal Width&#39;) plt.legend() plt.show() . . We can see that our Perceptron did converge and was able to classify Setosa from Non-Setosa with perfect accuracy because indeed the data is linearly separable. This would not be the case if the data was not linearly separable. So, let’s try it on another class. . Outputs below are for Versicolor class: . . Support Vector Machines . Now, let’s examine another approach using Support Vector Machines (SVM) with a linear kernel. In order to test for Linear Separability we will pick a hard-margin (for maximum distance as opposed to soft-margin) SVM with a linear kernel. Now, if the intent was to train a model our choices would be completely different. But, since we are testing for linear separability, we want a rigid test that would fail (or produce erroneous results if not converging) to help us better assess the data at hand. . Image source Wikipedia: Maximum-margin hyperplane 5 . Now, let’s code: . from sklearn.svm import SVC svm = SVC(C=1.0, kernel=&#39;linear&#39;, random_state=0) svm.fit(x, y) predicted = svm.predict(x) cm = confusion_matrix(y, predicted) plt.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Wistia) classNames = [&#39;Negative&#39;,&#39;Positive&#39;] plt.title(&#39;SVM Linear Kernel Confusion Matrix - Setosa&#39;) plt.ylabel(&#39;True label&#39;) plt.xlabel(&#39;Predicted label&#39;) tick_marks = np.arange(len(classNames)) plt.xticks(tick_marks, classNames, rotation=45) plt.yticks(tick_marks, classNames) s = [[&#39;TN&#39;,&#39;FP&#39;], [&#39;FN&#39;, &#39;TP&#39;]] for i in range(2): for j in range(2): plt.text(j,i, str(s[i][j])+&quot; = &quot;+str(cm[i][j])) . Here are the plots for the confusion matrix and decision boundary: . . Perfect separartion/classification indicating a linear separability. . Now, let’s examin and rerun the test against Versicolor class and we get the plots below. Interesting enough, we don’t see a decision boundary and the confusion matrix indicates the classifier is not doing a good job at all. . . Now, for fun and to demonstrate how powerful SVMs can be let’s apply a non-linear kernel. In this case we will apply a Gaussian Radial Basis Function known as RBF Kernel. A slight change to the code above and we get completely different results: . x = df.iloc[:, [2,3]].values y = (data.target == 1).astype(np.int) # we are picking Versicolor to be 1 and all other classes will be 0 from sklearn.preprocessing import StandardScaler sc = StandardScaler() x = sc.fit_transform(x) from sklearn.svm import SVC svm = SVC(kernel=&#39;rbf&#39;, random_state=0) svm.fit(x, y) predicted = svm.predict(x) cm = confusion_matrix(y, predicted) plt.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Wistia) classNames = [&#39;Negative&#39;,&#39;Positive&#39;] plt.title(&#39;SVM RBF Confusion Matrix - Versicolor&#39;) plt.ylabel(&#39;True label&#39;) plt.xlabel(&#39;Predicted label&#39;) tick_marks = np.arange(len(classNames)) plt.xticks(tick_marks, classNames, rotation=45) plt.yticks(tick_marks, classNames) s = [[&#39;TN&#39;,&#39;FP&#39;], [&#39;FN&#39;, &#39;TP&#39;]] for i in range(2): for j in range(2): plt.text(j,i, str(s[i][j])+&quot; = &quot;+str(cm[i][j])) . . Hope this helps. . References: . The Linear Separability Problem: Some Testing Methods http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.6481&amp;rep=rep1&amp;type=pdf &#8617; . | A Simple Algorithm for Linear Separability Test http://mllab.csa.iisc.ernet.in/downloads/Labtalk/talk30_01_08/lin_sep_test.pdf &#8617; . | Convex Optimization, Linear Programming: http://www.stat.cmu.edu/~ryantibs/convexopt-F13/scribes/lec2.pdf &#8617; &#8617;2 . | Test for Linear Separability with Linear Programming in R https://www.joyofdata.de/blog/testing-linear-separability-linear-programming-r-glpk/ &#8617; . | Support Vector Machine https://en.wikipedia.org/wiki/Support_vector_machine &#8617; . |",
            "url": "http://tarekatwan.com/blog/python/2017/12/31/linear-separability.html",
            "relUrl": "/python/2017/12/31/linear-separability.html",
            "date": " • Dec 31, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This blog belongs to Tarek Atwan. I bring over 15 years of experience in Data Analytics, Business Intelligence, and Product Development. . I am passionate about Coding, Machine Learning, Artificial Intelligence, Emerging Technologies, Cloud Computing, Web Development and Mobile Development. I enjoy coding in Python, Julia, R, and JavaScript. .",
          "url": "http://tarekatwan.com/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "http://tarekatwan.com/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}