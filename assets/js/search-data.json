{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "Skeleton Code . The code below provides a skeleton for the model building &amp; training component of your project. You can add/remove/build on code however you see fit, this is meant as a starting point. . #collapse_shpw import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import os from glob import glob %matplotlib inline import matplotlib.pyplot as plt ##Import any other stats/DL/ML packages you may need here. E.g. Keras, scikit-learn, etc. ## General libraries import seaborn as sns from itertools import chain import pydicom from random import sample ## Scikit-Learn from skimage.io import imread, imshow from skimage import io from sklearn.model_selection import train_test_split from sklearn.metrics import f1_score, confusion_matrix, auc, roc_auc_score, roc_curve, accuracy_score, precision_recall_curve, average_precision_score ## Keras from keras.preprocessing.image import ImageDataGenerator from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D from keras.models import Sequential, Model, model_from_json from keras.optimizers import Adam from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau from keras.applications.vgg16 import VGG16 . Using TensorFlow backend. . Do some early processing of your metadata for easier model training: . ## Below is some helper code to read all of your full image filepaths into a dataframe for easier manipulation ## Load the NIH data to all_xray_df all_xray_df = pd.read_csv(&#39;/data/Data_Entry_2017.csv&#39;) all_image_paths = {os.path.basename(x): x for x in glob(os.path.join(&#39;/data&#39;,&#39;images*&#39;, &#39;*&#39;, &#39;*.png&#39;))} print(&#39;Scans found:&#39;, len(all_image_paths), &#39;, Total Headers&#39;, all_xray_df.shape[0]) all_xray_df[&#39;path&#39;] = all_xray_df[&#39;Image Index&#39;].map(all_image_paths.get) all_xray_df.sample(3) . Scans found: 112120 , Total Headers 112120 . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImage[Width Height] OriginalImagePixelSpacing[x y] Unnamed: 11 path . 43068 00011121_010.png | No Finding | 10 | 11121 | 49 | F | PA | 2750 | 2991 | 0.143 | 0.143 | NaN | /data/images_005/images/00011121_010.png | . 95937 00025250_001.png | Cardiomegaly | 1 | 25250 | 48 | F | PA | 2992 | 2991 | 0.143 | 0.143 | NaN | /data/images_011/images/00025250_001.png | . 40119 00010475_021.png | Effusion | 21 | 10475 | 64 | F | AP | 2500 | 2048 | 0.168 | 0.168 | NaN | /data/images_005/images/00010475_021.png | . all_xray_df.columns . Index([&#39;Image Index&#39;, &#39;Finding Labels&#39;, &#39;Follow-up #&#39;, &#39;Patient ID&#39;, &#39;Patient Age&#39;, &#39;Patient Gender&#39;, &#39;View Position&#39;, &#39;OriginalImage[Width&#39;, &#39;Height]&#39;, &#39;OriginalImagePixelSpacing[x&#39;, &#39;y]&#39;, &#39;Unnamed: 11&#39;, &#39;path&#39;], dtype=&#39;object&#39;) . ## Here you may want to create some extra columns in your table with binary indicators of certain diseases ## rather than working directly with the &#39;Finding Labels&#39; column # Todo all_labels = list(set(list(chain.from_iterable([i.split(&#39;|&#39;) for i in all_xray_df[&#39;Finding Labels&#39;]])))) for c_label in all_labels: all_xray_df[c_label] = all_xray_df[&#39;Finding Labels&#39;].map(lambda finding: 1.0 if c_label in finding else 0) all_xray_df.sample(3) . Image Index Finding Labels Follow-up # Patient ID Patient Age Patient Gender View Position OriginalImage[Width Height] OriginalImagePixelSpacing[x ... Emphysema Nodule Edema Effusion Pleural_Thickening Consolidation Mass Atelectasis No Finding Infiltration . 24116 00006332_005.png | No Finding | 5 | 6332 | 47 | F | PA | 2048 | 2500 | 0.171 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 70065 00017247_005.png | No Finding | 5 | 17247 | 55 | F | PA | 2578 | 2657 | 0.143 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 27807 00007239_001.png | No Finding | 1 | 7239 | 52 | F | AP | 2500 | 2048 | 0.171 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 3 rows × 28 columns . all_xray_df.columns . Index([&#39;Image Index&#39;, &#39;Finding Labels&#39;, &#39;Follow-up #&#39;, &#39;Patient ID&#39;, &#39;Patient Age&#39;, &#39;Patient Gender&#39;, &#39;View Position&#39;, &#39;OriginalImage[Width&#39;, &#39;Height]&#39;, &#39;OriginalImagePixelSpacing[x&#39;, &#39;y]&#39;, &#39;Unnamed: 11&#39;, &#39;path&#39;, &#39;Hernia&#39;, &#39;Cardiomegaly&#39;, &#39;Fibrosis&#39;, &#39;Pneumothorax&#39;, &#39;Pneumonia&#39;, &#39;Emphysema&#39;, &#39;Nodule&#39;, &#39;Edema&#39;, &#39;Effusion&#39;, &#39;Pleural_Thickening&#39;, &#39;Consolidation&#39;, &#39;Mass&#39;, &#39;Atelectasis&#39;, &#39;No Finding&#39;, &#39;Infiltration&#39;], dtype=&#39;object&#39;) . all_xray_df.hist(bins=50, figsize=(20,15)) plt.show() . /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:298: MatplotlibDeprecationWarning: The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead. layout[ax.rowNum, ax.colNum] = ax.get_visible() /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:298: MatplotlibDeprecationWarning: The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead. layout[ax.rowNum, ax.colNum] = ax.get_visible() /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:304: MatplotlibDeprecationWarning: The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead. if not layout[ax.rowNum + 1, ax.colNum]: /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:304: MatplotlibDeprecationWarning: The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead. if not layout[ax.rowNum + 1, ax.colNum]: . print(all_xray_df[&#39;Patient Gender&#39;].value_counts(normalize=True)) all_xray_df[&#39;Patient Gender&#39;].hist() plt.show() . M 0.56493 F 0.43507 Name: Patient Gender, dtype: float64 . all_xray_df.drop(columns=[&#39;Unnamed: 11&#39;], inplace=True) . ## Here we can create a new column called &#39;pneumonia_class&#39; that will allow us to look at ## images with or without pneumonia for binary classification # Todo # since we already have a column for Pneumonia (binary 0,1) we can repurpose it and just rename it all_xray_df = all_xray_df.rename(columns={&#39;Pneumonia&#39;: &#39;pneumonia_class&#39;}) . labels = all_xray_df.columns[13:] labels . Index([&#39;Cardiomegaly&#39;, &#39;Fibrosis&#39;, &#39;Pneumothorax&#39;, &#39;pneumonia_class&#39;, &#39;Emphysema&#39;, &#39;Nodule&#39;, &#39;Edema&#39;, &#39;Effusion&#39;, &#39;Pleural_Thickening&#39;, &#39;Consolidation&#39;, &#39;Mass&#39;, &#39;Atelectasis&#39;, &#39;No Finding&#39;, &#39;Infiltration&#39;], dtype=&#39;object&#39;) . plt.figure(figsize=(10,6)) vals = all_xray_df[labels].sum().nlargest(15).sort_values() colors = [&#39;#d62728&#39; if i ==&#39;pneumonia_class&#39; else &#39;#1f77b4&#39; for i in vals.index] ax = vals.plot(kind=&#39;barh&#39;, color=colors) ax.set(xlabel = &#39;Number of Images with Label&#39;) plt.show() . Create your training and testing data: . all_xray_df.shape . (112120, 27) . cols = [&#39;path&#39;, &#39;pneumonia_class&#39;, &#39;Patient Gender&#39;, &#39;Patient Age&#39;, &#39;View Position&#39;] dt = all_xray_df[cols] . def create_splits(data, test_size=0.2, strat=None): ## Either build your own or use a built-in library to split your original dataframe into two sets ## that can be used for training and testing your model ## It&#39;s important to consider here how balanced or imbalanced you want each of those sets to be ## for the presence of pneumonia # Todo train_data, val_data = train_test_split(data, test_size = test_size, stratify = data[strat], random_state=42) return train_data, val_data . train_set, val_set = create_splits(dt, 0.2, &#39;pneumonia_class&#39;) . Analysis on the Training and Validation Dataset to under data distribution . print(train_set[&#39;pneumonia_class&#39;].value_counts(normalize=True)) train_set[&#39;pneumonia_class&#39;].hist() plt.title(&#39;Training set class distribution&#39;) . 0.0 0.987235 1.0 0.012765 Name: pneumonia_class, dtype: float64 . Text(0.5, 1.0, &#39;Training set class distribution&#39;) . print(val_set[&#39;pneumonia_class&#39;].value_counts(normalize=True)) val_set[&#39;pneumonia_class&#39;].hist() plt.title(&#39;Validation set class distribution&#39;) . 0.0 0.987246 1.0 0.012754 Name: pneumonia_class, dtype: float64 . Text(0.5, 1.0, &#39;Validation set class distribution&#39;) . train_set[&#39;Patient Age&#39;].hist() plt.title(&#39;Traing set - Age Distribution&#39;) plt.show() . print(train_set[&#39;Patient Gender&#39;].value_counts(normalize=True)) train_set[&#39;Patient Gender&#39;].hist() plt.title(&#39;Traing set - Gender Distribution&#39;) plt.show() . M 0.564986 F 0.435014 Name: Patient Gender, dtype: float64 . val_set[&#39;Patient Age&#39;].hist() plt.title(&#39;Validation set - Age Distribution&#39;) plt.show() . print(val_set[&#39;Patient Gender&#39;].value_counts(normalize=True)) val_set[&#39;Patient Gender&#39;].hist() plt.title(&#39;Validation set - Gender Distribution&#39;) plt.show() . M 0.564707 F 0.435293 Name: Patient Gender, dtype: float64 . Research Papers and Articles regarding Imbalanced Classes in Deep Learning . Survey on deep learning with class imbalance - Springer | Solving Class Imbalance problem in CNN - Medium | Deep Over-sampling Framework for Classifying Imbalanced Data - Paper | SMOTE for Imbalanced Classification with Python | Note: From the research it seems a combination of undersampling and oversampling may produce the best results. This means undersampling the majority class which in our case is the Non-Penumonia and oversampling the minority class. Possibly in the future I will need to experiment further with these techniques. For now, I will just reduce the data from the majority class to bring them to a balance. . Handling Imbalance classes . Even though with Patient Gender there is a slight imbalance as well, I think it can be neglected for now. The current technique to balance Pneumonia and Non-Pneumonia classes will chunk out a lot of data already and I would like to preserve as much data as possible for training. . Training Data set . p_idx = train_set[train_set[&#39;pneumonia_class&#39;]==1].index.tolist() np_idx = train_set[train_set[&#39;pneumonia_class&#39;]==0].index.tolist() np_sample = sample(np_idx,len(p_idx)) train_df = train_set.loc[p_idx + np_sample] . train_df.shape . (2290, 5) . Validation Dataset . p_idx = val_set[val_set[&#39;pneumonia_class&#39;]==1].index.tolist() np_idx = val_set[val_set[&#39;pneumonia_class&#39;]==0].index.tolist() np_sample = sample(np_idx,len(p_idx)) val_df = val_set.loc[p_idx + np_sample] . Checking - analysis after reducing the majority non-pneumonia class . val_df.shape . (572, 5) . from collections import Counter . Counter(train_df.pneumonia_class) . Counter({1.0: 1145, 0.0: 1145}) . Counter(val_df.pneumonia_class) . Counter({1.0: 286, 0.0: 286}) . train_df[train_df.pneumonia_class == 1][&#39;Patient Gender&#39;].value_counts(normalize=True) . M 0.5869 F 0.4131 Name: Patient Gender, dtype: float64 . val_df[val_df.pneumonia_class == 1][&#39;Patient Gender&#39;].value_counts(normalize=True) . M 0.58042 F 0.41958 Name: Patient Gender, dtype: float64 . Library imblearn something to test in the future . # !pip install -U imbalanced-learn . # import imblearn # from imblearn.over_sampling import SMOTE # print(imblearn.__version__) . Now we can begin our model-building &amp; training . First suggestion: perform some image augmentation on your data . ## This is the image size that VGG16 takes as input IMG_SIZE = (224, 224) . def my_image_augmentation(horizontal_flip=False, vertical_flip=False, height_shift_range=0, width_shift_range=0, rotation_range=0, shear_range=0, zoom_range=0): ## recommendation here to implement a package like Keras&#39; ImageDataGenerator ## with some of the built-in augmentations ## keep an eye out for types of augmentation that are or are not appropriate for medical imaging data ## Also keep in mind what sort of augmentation is or is not appropriate for testing vs validation data ## STAND-OUT SUGGESTION: implement some of your own custom augmentation that&#39;s *not* ## built into something like a Keras package # Todo img_aug = ImageDataGenerator(rescale=1. / 255.0, horizontal_flip = horizontal_flip, vertical_flip = vertical_flip, height_shift_range= height_shift_range, width_shift_range=width_shift_range, rotation_range=rotation_range, shear_range = shear_range, zoom_range=zoom_range) return img_aug def make_train_gen(train_idg, train_df, x_col, y_col, target_size, batch_size): ## Create the actual generators using the output of my_image_augmentation for your training data ## Suggestion here to use the flow_from_dataframe library, e.g.: # my_train = my_image_augmentation(horizontal_flip = True, # vertical_flip = False, # height_shift_range= 0.1, # width_shift_range=0.1, # rotation_range=20, # shear_range = 0.1, # zoom_range=0.1) train_gen = train_idg.flow_from_dataframe(dataframe=train_df, directory=None, x_col = x_col, y_col = y_col, class_mode = &#39;binary&#39;, target_size = target_size, batch_size = batch_size ) # Todo return train_gen def make_val_gen(val_idg, val_df, x_col, y_col, target_size, batch_size): # my_val_idg = my_image_augmentation() val_gen = val_idg.flow_from_dataframe(dataframe = val_df, directory=None, x_col = x_col, y_col = y_col, class_mode = &#39;binary&#39;, target_size = target_size, batch_size = batch_size) # Todo return val_gen . Note: Due to error requiring that the classes should be string since the class_mode is set to binary . train_df[&#39;pneumonia_class&#39;] = train_df[&#39;pneumonia_class&#39;].astype(&#39;str&#39;) val_df[&#39;pneumonia_class&#39;] = val_df[&#39;pneumonia_class&#39;].astype(&#39;str&#39;) . train_idg = my_image_augmentation(True, False, 0.1, 0.1, 20, 0.1, 0.1) val_idg = my_image_augmentation() . train_gen = make_train_gen(train_idg=train_idg, train_df=train_df, x_col=&#39;path&#39;, y_col=&#39;pneumonia_class&#39;, target_size=IMG_SIZE, batch_size=22) val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;pneumonia_class&#39;, IMG_SIZE, 22) . Found 2290 validated image filenames belonging to 2 classes. Found 572 validated image filenames belonging to 2 classes. . ## May want to pull a single large batch of random validation data for testing after each epoch: valX, valY = val_gen.next() . ## May want to look at some examples of our augmented training data. ## This is helpful for understanding the extent to which data is being manipulated prior to training, ## and can be compared with how the raw data look prior to augmentation t_x, t_y = next(train_gen) fig, m_axs = plt.subplots(4, 4, figsize = (16, 16)) for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()): c_ax.imshow(c_x[:,:,0], cmap = &#39;bone&#39;) if c_y == 1: c_ax.set_title(&#39;Pneumonia&#39;) else: c_ax.set_title(&#39;No Pneumonia&#39;) c_ax.axis(&#39;off&#39;) . Build your model: . Recommendation here to use a pre-trained network downloaded from Keras for fine-tuning . model = VGG16(include_top=True, weights=&#39;imagenet&#39;) . Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5 553467904/553467096 [==============================] - 30s 0us/step . # model.summary() . def load_pretrained_model(): model = VGG16(include_top=True, weights=&#39;imagenet&#39;) transfer_layer = model.get_layer(&#39;block5_pool&#39;) vgg_model = Model(inputs = model.input, outputs = transfer_layer.output) # Todo for layer in vgg_model.layers[0:-2]: layer.trainable = False return vgg_model . vgg_model = load_pretrained_model() . vgg_model.summary() . Model: &#34;model_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) (None, 224, 224, 3) 0 _________________________________________________________________ block1_conv1 (Conv2D) (None, 224, 224, 64) 1792 _________________________________________________________________ block1_conv2 (Conv2D) (None, 224, 224, 64) 36928 _________________________________________________________________ block1_pool (MaxPooling2D) (None, 112, 112, 64) 0 _________________________________________________________________ block2_conv1 (Conv2D) (None, 112, 112, 128) 73856 _________________________________________________________________ block2_conv2 (Conv2D) (None, 112, 112, 128) 147584 _________________________________________________________________ block2_pool (MaxPooling2D) (None, 56, 56, 128) 0 _________________________________________________________________ block3_conv1 (Conv2D) (None, 56, 56, 256) 295168 _________________________________________________________________ block3_conv2 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_conv3 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_pool (MaxPooling2D) (None, 28, 28, 256) 0 _________________________________________________________________ block4_conv1 (Conv2D) (None, 28, 28, 512) 1180160 _________________________________________________________________ block4_conv2 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_conv3 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_pool (MaxPooling2D) (None, 14, 14, 512) 0 _________________________________________________________________ block5_conv1 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv2 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv3 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_pool (MaxPooling2D) (None, 7, 7, 512) 0 ================================================================= Total params: 14,714,688 Trainable params: 2,359,808 Non-trainable params: 12,354,880 _________________________________________________________________ . def build_my_model(pre_trained): my_model = Sequential() # Add the convolutional part of the VGG16 model from above. my_model.add(vgg_model) my_model.add(Flatten()) # Flatten the output of the VGG16 model because it is from a # convolutional layer. my_model.add(Dense(1024, activation=&#39;relu&#39;)) my_model.add(Dropout(0.5)) my_model.add(Dense(512, activation=&#39;relu&#39;)) my_model.add(Dropout(0.5)) my_model.add(Dense(256, activation=&#39;relu&#39;)) my_model.add(Dropout(0.5)) # Final output layer # Add a dense (aka. fully-connected) layer. # This is for combining features that the VGG16 model has # recognized in the image. my_model.add(Dense(1, activation=&#39;sigmoid&#39;)) ## Set our optimizer, loss function, and learning rate (you can change the learning rate here if you&#39;d like) ## but otherwise this cell can be run as is return my_model . model = build_my_model(vgg_model) . optimizer = Adam(lr=0.001) loss = &#39;binary_crossentropy&#39; metrics = [&#39;binary_accuracy&#39;] model.compile(optimizer=optimizer, loss=loss, metrics=metrics) . model.summary() . Model: &#34;sequential_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= model_2 (Model) (None, 7, 7, 512) 14714688 _________________________________________________________________ flatten_2 (Flatten) (None, 25088) 0 _________________________________________________________________ dense_5 (Dense) (None, 1024) 25691136 _________________________________________________________________ dropout_4 (Dropout) (None, 1024) 0 _________________________________________________________________ dense_6 (Dense) (None, 512) 524800 _________________________________________________________________ dropout_5 (Dropout) (None, 512) 0 _________________________________________________________________ dense_7 (Dense) (None, 256) 131328 _________________________________________________________________ dropout_6 (Dropout) (None, 256) 0 _________________________________________________________________ dense_8 (Dense) (None, 1) 257 ================================================================= Total params: 41,062,209 Trainable params: 28,707,329 Non-trainable params: 12,354,880 _________________________________________________________________ . ## Below is some helper code that will allow you to add checkpoints to your model, ## This will save the &#39;best&#39; version of your model by comparing it to previous epochs of training ## Note that you need to choose which metric to monitor for your model&#39;s &#39;best&#39; performance if using this code. ## The &#39;patience&#39; parameter is set to 10, meaning that your model will train for ten epochs without seeing ## improvement before quitting # Todo weight_path=&quot;{}_my_model.best.hdf5&quot;.format(&#39;xray_class&#39;) checkpoint = ModelCheckpoint(weight_path, monitor= &#39;val_loss&#39;, verbose=1, save_best_only=True, mode= &#39;min&#39;, save_weights_only = True) early = EarlyStopping(monitor= &#39;val_loss&#39;, mode= &#39;min&#39;, patience=10) callbacks_list = [checkpoint, early] . Start training! . history = model.fit_generator(train_gen, validation_data=[valX, valY], epochs=30, callbacks=callbacks_list ) . Epoch 1/30 105/105 [==============================] - 61s 583ms/step - loss: 0.7943 - binary_accuracy: 0.5288 - val_loss: 0.6789 - val_binary_accuracy: 0.5455 Epoch 00001: val_loss improved from inf to 0.67891, saving model to xray_class_my_model.best.hdf5 Epoch 2/30 105/105 [==============================] - 60s 574ms/step - loss: 0.6889 - binary_accuracy: 0.5520 - val_loss: 0.6646 - val_binary_accuracy: 0.5909 Epoch 00002: val_loss improved from 0.67891 to 0.66465, saving model to xray_class_my_model.best.hdf5 Epoch 3/30 105/105 [==============================] - 59s 565ms/step - loss: 0.6838 - binary_accuracy: 0.5699 - val_loss: 0.6628 - val_binary_accuracy: 0.5909 Epoch 00003: val_loss improved from 0.66465 to 0.66279, saving model to xray_class_my_model.best.hdf5 Epoch 4/30 105/105 [==============================] - 60s 568ms/step - loss: 0.6803 - binary_accuracy: 0.5952 - val_loss: 0.6143 - val_binary_accuracy: 0.7273 Epoch 00004: val_loss improved from 0.66279 to 0.61426, saving model to xray_class_my_model.best.hdf5 Epoch 5/30 105/105 [==============================] - 59s 563ms/step - loss: 0.6693 - binary_accuracy: 0.5873 - val_loss: 0.5985 - val_binary_accuracy: 0.7273 Epoch 00005: val_loss improved from 0.61426 to 0.59854, saving model to xray_class_my_model.best.hdf5 Epoch 6/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6665 - binary_accuracy: 0.6175 - val_loss: 0.6186 - val_binary_accuracy: 0.7273 Epoch 00006: val_loss did not improve from 0.59854 Epoch 7/30 105/105 [==============================] - 58s 556ms/step - loss: 0.6719 - binary_accuracy: 0.6140 - val_loss: 0.5687 - val_binary_accuracy: 0.7273 Epoch 00007: val_loss improved from 0.59854 to 0.56874, saving model to xray_class_my_model.best.hdf5 Epoch 8/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6708 - binary_accuracy: 0.6057 - val_loss: 0.6142 - val_binary_accuracy: 0.6818 Epoch 00008: val_loss did not improve from 0.56874 Epoch 9/30 105/105 [==============================] - 58s 551ms/step - loss: 0.6607 - binary_accuracy: 0.6258 - val_loss: 0.5588 - val_binary_accuracy: 0.7727 Epoch 00009: val_loss improved from 0.56874 to 0.55877, saving model to xray_class_my_model.best.hdf5 Epoch 10/30 105/105 [==============================] - 58s 549ms/step - loss: 0.6539 - binary_accuracy: 0.6240 - val_loss: 0.5495 - val_binary_accuracy: 0.7273 Epoch 00010: val_loss improved from 0.55877 to 0.54947, saving model to xray_class_my_model.best.hdf5 Epoch 11/30 105/105 [==============================] - 58s 554ms/step - loss: 0.6606 - binary_accuracy: 0.6236 - val_loss: 0.5813 - val_binary_accuracy: 0.7273 Epoch 00011: val_loss did not improve from 0.54947 Epoch 12/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6545 - binary_accuracy: 0.6166 - val_loss: 0.5925 - val_binary_accuracy: 0.6818 Epoch 00012: val_loss did not improve from 0.54947 Epoch 13/30 105/105 [==============================] - 58s 549ms/step - loss: 0.6539 - binary_accuracy: 0.6367 - val_loss: 0.5246 - val_binary_accuracy: 0.6818 Epoch 00013: val_loss improved from 0.54947 to 0.52456, saving model to xray_class_my_model.best.hdf5 Epoch 14/30 105/105 [==============================] - 57s 545ms/step - loss: 0.6495 - binary_accuracy: 0.6253 - val_loss: 0.6258 - val_binary_accuracy: 0.6818 Epoch 00014: val_loss did not improve from 0.52456 Epoch 15/30 105/105 [==============================] - 58s 554ms/step - loss: 0.6595 - binary_accuracy: 0.6349 - val_loss: 0.5774 - val_binary_accuracy: 0.7273 Epoch 00015: val_loss did not improve from 0.52456 Epoch 16/30 105/105 [==============================] - 59s 558ms/step - loss: 0.6533 - binary_accuracy: 0.6336 - val_loss: 0.5992 - val_binary_accuracy: 0.6818 Epoch 00016: val_loss did not improve from 0.52456 Epoch 17/30 105/105 [==============================] - 59s 559ms/step - loss: 0.6502 - binary_accuracy: 0.6367 - val_loss: 0.5655 - val_binary_accuracy: 0.8182 Epoch 00017: val_loss did not improve from 0.52456 Epoch 18/30 105/105 [==============================] - 59s 565ms/step - loss: 0.6403 - binary_accuracy: 0.6393 - val_loss: 0.5355 - val_binary_accuracy: 0.7727 Epoch 00018: val_loss did not improve from 0.52456 Epoch 19/30 105/105 [==============================] - 57s 540ms/step - loss: 0.6455 - binary_accuracy: 0.6362 - val_loss: 0.4997 - val_binary_accuracy: 0.7727 Epoch 00019: val_loss improved from 0.52456 to 0.49972, saving model to xray_class_my_model.best.hdf5 Epoch 20/30 105/105 [==============================] - 58s 550ms/step - loss: 0.6529 - binary_accuracy: 0.6393 - val_loss: 0.5674 - val_binary_accuracy: 0.8182 Epoch 00020: val_loss did not improve from 0.49972 Epoch 21/30 105/105 [==============================] - 58s 551ms/step - loss: 0.6495 - binary_accuracy: 0.6415 - val_loss: 0.5950 - val_binary_accuracy: 0.7727 Epoch 00021: val_loss did not improve from 0.49972 Epoch 22/30 105/105 [==============================] - 58s 550ms/step - loss: 0.6488 - binary_accuracy: 0.6332 - val_loss: 0.5701 - val_binary_accuracy: 0.7273 Epoch 00022: val_loss did not improve from 0.49972 Epoch 23/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6316 - binary_accuracy: 0.6594 - val_loss: 0.5483 - val_binary_accuracy: 0.7727 Epoch 00023: val_loss did not improve from 0.49972 Epoch 24/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6314 - binary_accuracy: 0.6524 - val_loss: 0.5416 - val_binary_accuracy: 0.7273 Epoch 00024: val_loss did not improve from 0.49972 Epoch 25/30 105/105 [==============================] - 58s 553ms/step - loss: 0.6361 - binary_accuracy: 0.6502 - val_loss: 0.5378 - val_binary_accuracy: 0.8182 Epoch 00025: val_loss did not improve from 0.49972 Epoch 26/30 105/105 [==============================] - 58s 551ms/step - loss: 0.6384 - binary_accuracy: 0.6498 - val_loss: 0.5757 - val_binary_accuracy: 0.7273 Epoch 00026: val_loss did not improve from 0.49972 Epoch 27/30 105/105 [==============================] - 58s 548ms/step - loss: 0.6410 - binary_accuracy: 0.6467 - val_loss: 0.5184 - val_binary_accuracy: 0.8182 Epoch 00027: val_loss did not improve from 0.49972 Epoch 28/30 105/105 [==============================] - 58s 552ms/step - loss: 0.6353 - binary_accuracy: 0.6520 - val_loss: 0.5618 - val_binary_accuracy: 0.6364 Epoch 00028: val_loss did not improve from 0.49972 Epoch 29/30 105/105 [==============================] - 58s 550ms/step - loss: 0.6420 - binary_accuracy: 0.6533 - val_loss: 0.5467 - val_binary_accuracy: 0.7727 Epoch 00029: val_loss did not improve from 0.49972 . history.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_binary_accuracy&#39;, &#39;loss&#39;, &#39;binary_accuracy&#39;]) . After training for some time, look at the performance of your model by plotting some performance statistics: . Note, these figures will come in handy for your FDA documentation later in the project . !ls . &#39;Build and train model.ipynb&#39; test2.dcm EDA.ipynb test3.dcm FDA_Submission_Template.md test4.dcm Inference.ipynb test5.dcm my_model.json test6.dcm sample_labels.csv xray_class_my_model.best.hdf5 test1.dcm . ## After training, make some predictions to assess your model&#39;s overall performance ## Note that detecting pneumonia is hard even for trained expert radiologists, ## so there is no need to make the model perfect. model.load_weights(weight_path) pred_Y = model.predict(valX, batch_size = 32, verbose = True) . Create a binary output instead of just probability using a standard 0.5 threshold for now . pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] . def plot_auc(t_y, p_y): ## Hint: can use scikit-learn&#39;s built in functions here like roc_curve # Todo fig, c_ax = plt.subplots(1,1, figsize = (9, 9)) fpr, tpr, thresholds = roc_curve(t_y, p_y) c_ax.plot(fpr, tpr, label = &#39;%s (AUC:%0.2f)&#39; % (&#39;Pneumonia&#39;, auc(fpr, tpr))) c_ax.legend() c_ax.set_xlabel(&#39;False Positive Rate&#39;) c_ax.set_ylabel(&#39;True Positive Rate&#39;) return ## what other performance statistics do you want to include here besides AUC? # def ... # Todo def plot_pr(t_y, p_y): fig, c_ax = plt.subplots(1,1, figsize = (9, 9)) precision, recall, thresholds = precision_recall_curve(t_y, p_y) c_ax.plot(precision, recall, label = &#39;%s (AP Score:%0.2f)&#39; % (&#39;Pneumonia&#39;, average_precision_score(t_y,p_y))) c_ax.legend() c_ax.set_xlabel(&#39;Recall&#39;) c_ax.set_ylabel(&#39;Precision&#39;) #Also consider plotting the history of your model training: def plot_history(history, kind): &#39;&#39;&#39; kind: either &quot;accuracy&quot; or &quot;loss&quot; &#39;&#39;&#39; plt.figure(figsize = (9, 9)) kind = &#39;binary_accuracy&#39; if kind == &#39;accuracy&#39; else kind plt.plot(history.history[f&#39;val_{kind}&#39;], label=f&#39;validation {kind}&#39;) plt.plot(history.history[f&#39;{kind}&#39;], label=f&#39;training {kind}&#39;) plt.title(f&#39;Validation/Training {kind}&#39;) plt.ylabel(&#39;EPOCHS&#39;) plt.legend() plt.show() return . plot_auc(valY, pred_Y) . ## plot figures plot_history(history, &#39;accuracy&#39;) # Todo . plot_history(history, &#39;loss&#39;) . Once you feel you are done training, you&#39;ll need to decide the proper classification threshold that optimizes your model&#39;s performance for a given metric (e.g. accuracy, F1, precision, etc. You decide) . confusion_matrix(pred_Y_binary, valY) . array([[10, 4], [ 1, 7]]) . tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() . accuracy_score(pred_Y_binary, valY) f1_score(pred_Y_binary, valY) sens = tp/(tp+fn) spec = tn/(tn+fp) spec . 0.7142857142857143 . precision, recall, thresholds = precision_recall_curve(valY, pred_Y) . ## Find the threshold that optimize your model&#39;s performance, ## and use that threshold to make binary classification. Make sure you take all your metrics into consideration. # Todo . val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;pneumonia_class&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() . Found 572 validated image filenames belonging to 2 classes. . pred_Y = model.predict(valX, batch_size = 32, verbose = True) . 100/100 [==============================] - 1s 10ms/step . ## Let&#39;s look at some examples of true vs. predicted with our best model: # Todo fig, m_axs = plt.subplots(10, 10, figsize = (16, 16)) i = 0 for (c_x, c_y, c_ax) in zip(valX[0:100], valY[0:100], m_axs.flatten()): c_ax.imshow(c_x[:,:,0], cmap = &#39;bone&#39;) if c_y == 1: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;1, 1&#39;) else: c_ax.set_title(&#39;1, 0&#39;, color=&#39;red&#39;) else: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;0, 1&#39;, color=&#39;red&#39;) else: c_ax.set_title(&#39;0, 0&#39;) c_ax.axis(&#39;off&#39;) i=i+1 . pred_Y_binary = pred_Y_binary = [1 if i[0] &gt; 0.5 else 0 for i in pred_Y] confusion_matrix(pred_Y_binary, valY) . array([[33, 17], [13, 37]]) . acc = accuracy_score(pred_Y_binary, valY) f1 = f1_score(pred_Y_binary, valY) sens = tp/(tp+fn) spec = tn/(tn+fp) spec . 0.7142857142857143 . plot_auc(valY, pred_Y) . plot_pr(valY, pred_Y) . ## Just save model architecture to a .json: model_json = model.to_json() with open(&quot;my_model.json&quot;, &quot;w&quot;) as json_file: json_file.write(model_json) . !ls . &#39;Build and train model.ipynb&#39; test2.dcm EDA.ipynb test3.dcm FDA_Submission_Template.md test4.dcm Inference.ipynb test5.dcm my_model.json test6.dcm sample_labels.csv xray_class_my_model.best.hdf5 test1.dcm . Using saved model for further analysis and testing . json_file = open(&#39;my_model.json&#39;, &#39;r&#39;) loaded_model_json = json_file.read() json_file.close() loaded_model = model_from_json(loaded_model_json) # load weights into new model loaded_model.load_weights(&quot;xray_class_my_model.best.hdf5&quot;) print(&quot;Loaded model from disk&quot;) . Loaded model from disk . loaded_model.summary() . Model: &#34;sequential_2&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= model_2 (Model) (None, 7, 7, 512) 14714688 _________________________________________________________________ flatten_2 (Flatten) (None, 25088) 0 _________________________________________________________________ dense_5 (Dense) (None, 1024) 25691136 _________________________________________________________________ dropout_4 (Dropout) (None, 1024) 0 _________________________________________________________________ dense_6 (Dense) (None, 512) 524800 _________________________________________________________________ dropout_5 (Dropout) (None, 512) 0 _________________________________________________________________ dense_7 (Dense) (None, 256) 131328 _________________________________________________________________ dropout_6 (Dropout) (None, 256) 0 _________________________________________________________________ dense_8 (Dense) (None, 1) 257 ================================================================= Total params: 41,062,209 Trainable params: 28,707,329 Non-trainable params: 12,354,880 _________________________________________________________________ . val_gen = make_val_gen(val_idg, val_df, &#39;path&#39;, &#39;pneumonia_class&#39;, IMG_SIZE, 100) valX, valY = val_gen.next() pred_Y = loaded_model.predict(valX, batch_size = 32, verbose = True) . Found 572 validated image filenames belonging to 2 classes. 100/100 [==============================] - 55s 553ms/step . fig, m_axs = plt.subplots(10, 10, figsize = (16, 16)) i = 0 for (c_x, c_y, c_ax) in zip(valX[0:100], valY[0:100], m_axs.flatten()): c_ax.imshow(c_x[:,:,0], cmap = &#39;bone&#39;) if c_y == 1: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;1, 1&#39;) else: c_ax.set_title(&#39;1, 0&#39;, color=&#39;red&#39;) else: if pred_Y[i] &gt; 0.5: c_ax.set_title(&#39;0, 1&#39;, color=&#39;red&#39;) else: c_ax.set_title(&#39;0, 0&#39;) c_ax.axis(&#39;off&#39;) i=i+1 . # Test for different threshold levels # using colors just to make it easir to read and spot numbers for t in [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] print(f&#39;when threshold at {t} CF:&#39;) print(confusion_matrix(pred_Y_binary, valY)) tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() print(f&#39; x1b[34maccuracy x1b[0m= x1b[31m{accuracy_score(pred_Y_binary, valY)} x1b[0m&#39;) print(f&#39;F1 Score = {f1_score(pred_Y_binary, valY)}&#39;) print(f&#39; x1b[34mSensitivity Score x1b[0m= x1b[31m{tp/(tp+fn)} x1b[0m&#39;) print(f&#39; x1b[34mSpecificity Score x1b[0m= x1b[31m{tn/(tn+fp)} x1b[0m&#39;) print(&#39;-&#39;) . when threshold at 0.4 CF: [[33 21] [21 25]] accuracy = 0.58 F1 Score = 0.5434782608695652 Sensitivity Score = 0.5434782608695652 Specificity Score = 0.6111111111111112 - when threshold at 0.5 CF: [[43 25] [11 21]] accuracy = 0.64 F1 Score = 0.5384615384615383 Sensitivity Score = 0.65625 Specificity Score = 0.6323529411764706 - when threshold at 0.6 CF: [[48 31] [ 6 15]] accuracy = 0.63 F1 Score = 0.4477611940298507 Sensitivity Score = 0.7142857142857143 Specificity Score = 0.6075949367088608 - when threshold at 0.7 CF: [[49 39] [ 5 7]] accuracy = 0.56 F1 Score = 0.2413793103448276 Sensitivity Score = 0.5833333333333334 Specificity Score = 0.5568181818181818 - when threshold at 0.8 CF: [[51 41] [ 3 5]] accuracy = 0.56 F1 Score = 0.18518518518518517 Sensitivity Score = 0.625 Specificity Score = 0.5543478260869565 - when threshold at 0.9 CF: [[52 43] [ 2 3]] accuracy = 0.55 F1 Score = 0.11764705882352941 Sensitivity Score = 0.6 Specificity Score = 0.5473684210526316 - . # Test for different threshold levels # using colors just to make it easir to read and spot numbers thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] sens = [] spec = [] for t in thresholds: pred_Y_binary = [1 if i[0] &gt; t else 0 for i in pred_Y] tn, fp, fn, tp = confusion_matrix(pred_Y_binary, valY).ravel() sens.append(tp/(tp+fn)) spec.append(tn/(tn+fp)) plt.figure(figsize=(10,6)) plt.plot(thresholds, sens, label=&#39;Sensitivity&#39;) plt.plot(thresholds, spec, label=&#39;Specificity&#39;) plt.xlabel(&#39;Threshold Value&#39;) plt.ylabel(&#39;Score&#39;) plt.legend() plt.show() . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars if __name__ == &#39;__main__&#39;: .",
            "url": "http://www.tarekatwan.com/blog/fastpages/jupyter/2020/06/01/Working-with-DICOM-in-healtcare-using-python.html",
            "relUrl": "/fastpages/jupyter/2020/06/01/Working-with-DICOM-in-healtcare-using-python.html",
            "date": " • Jun 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "http://www.tarekatwan.com/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "http://www.tarekatwan.com/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "http://www.tarekatwan.com/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "http://www.tarekatwan.com/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}